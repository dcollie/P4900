{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\LARGE Artificial \\ Neural \\ Network$ \n",
    "\n",
    "# Act 1 - Read Data\n",
    "#### Import the usual 4  packages!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the important packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating all models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# KNN and ANN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ANN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Test all models\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=pd.read_csv('../Data/Star_Formation/HiGAL_clump_catalogue_correct_formatting.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check head, and describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>GLON</th>\n",
       "      <th>GLAT</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>DESIGNATION_70</th>\n",
       "      <th>F70</th>\n",
       "      <th>DF70</th>\n",
       "      <th>F70_TOT</th>\n",
       "      <th>...</th>\n",
       "      <th>EVOL_FLAG</th>\n",
       "      <th>MASS</th>\n",
       "      <th>DMASS</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DTEMP</th>\n",
       "      <th>LAM_0_TK</th>\n",
       "      <th>L_BOL</th>\n",
       "      <th>LRATIO</th>\n",
       "      <th>T_BOL</th>\n",
       "      <th>SURF_DENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4454</td>\n",
       "      <td>HIGALBM9.2545+1.0842</td>\n",
       "      <td>9.254488</td>\n",
       "      <td>1.084173</td>\n",
       "      <td>270.54295</td>\n",
       "      <td>-20.408795</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.63</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>10.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>5.19</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4455</td>\n",
       "      <td>HIGALBM9.2569-0.2825</td>\n",
       "      <td>9.256889</td>\n",
       "      <td>-0.282502</td>\n",
       "      <td>271.81796</td>\n",
       "      <td>-21.076705</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-30.79</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>10.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>70.3</td>\n",
       "      <td>-3.38</td>\n",
       "      <td>4.31</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4456</td>\n",
       "      <td>HIGALBM9.2582-0.4725</td>\n",
       "      <td>9.258172</td>\n",
       "      <td>-0.472514</td>\n",
       "      <td>271.99662</td>\n",
       "      <td>-21.167985</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>12.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>7.70</td>\n",
       "      <td>19.08</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4457</td>\n",
       "      <td>HIGALBM9.2604-0.2253</td>\n",
       "      <td>9.260426</td>\n",
       "      <td>-0.225272</td>\n",
       "      <td>271.76624</td>\n",
       "      <td>-21.045749</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.06</td>\n",
       "      <td>-7.33</td>\n",
       "      <td>9.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>3.49</td>\n",
       "      <td>14.53</td>\n",
       "      <td>0.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4458</td>\n",
       "      <td>HIGALBM9.2626-0.1134</td>\n",
       "      <td>9.262623</td>\n",
       "      <td>-0.113445</td>\n",
       "      <td>271.66278</td>\n",
       "      <td>-20.989332</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-50.04</td>\n",
       "      <td>-18.92</td>\n",
       "      <td>9.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>55.3</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>3.51</td>\n",
       "      <td>14.56</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID           DESIGNATION      GLON      GLAT         ra        dec  \\\n",
       "0  4454  HIGALBM9.2545+1.0842  9.254488  1.084173  270.54295 -20.408795   \n",
       "1  4455  HIGALBM9.2569-0.2825  9.256889 -0.282502  271.81796 -21.076705   \n",
       "2  4456  HIGALBM9.2582-0.4725  9.258172 -0.472514  271.99662 -21.167985   \n",
       "3  4457  HIGALBM9.2604-0.2253  9.260426 -0.225272  271.76624 -21.045749   \n",
       "4  4458  HIGALBM9.2626-0.1134  9.262623 -0.113445  271.66278 -20.989332   \n",
       "\n",
       "  DESIGNATION_70  F70  DF70  F70_TOT  ...  EVOL_FLAG   MASS  DMASS   TEMP  \\\n",
       "0              -  0.0   0.0      0.0  ...        1.0  -7.63  -1.86  10.84   \n",
       "1              -  0.0   0.0      0.0  ...        1.0 -30.79  -6.40  10.31   \n",
       "2              -  0.0   0.0      0.0  ...        1.0 -10.36  -2.69  12.32   \n",
       "3              -  0.0   0.0      0.0  ...        1.0 -25.06  -7.33   9.47   \n",
       "4              -  0.0   0.0      0.0  ...        1.0 -50.04 -18.92   9.48   \n",
       "\n",
       "   DTEMP  LAM_0_TK L_BOL  LRATIO  T_BOL  SURF_DENS  \n",
       "0   0.48       0.0 -1.19    5.19  16.79      0.073  \n",
       "1   0.42      70.3 -3.38    4.31  15.70      0.551  \n",
       "2   0.66       0.0 -3.49    7.70  19.08      0.105  \n",
       "3   0.42      58.2 -1.69    3.49  14.53      0.377  \n",
       "4   0.42      55.3 -3.41    3.51  14.56      0.341  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>GLON</th>\n",
       "      <th>GLAT</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>DESIGNATION_70</th>\n",
       "      <th>F70</th>\n",
       "      <th>DF70</th>\n",
       "      <th>F70_TOT</th>\n",
       "      <th>...</th>\n",
       "      <th>EVOL_FLAG</th>\n",
       "      <th>MASS</th>\n",
       "      <th>DMASS</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DTEMP</th>\n",
       "      <th>LAM_0_TK</th>\n",
       "      <th>L_BOL</th>\n",
       "      <th>LRATIO</th>\n",
       "      <th>T_BOL</th>\n",
       "      <th>SURF_DENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4454</td>\n",
       "      <td>HIGALBM9.2545+1.0842</td>\n",
       "      <td>9.254488</td>\n",
       "      <td>1.084173</td>\n",
       "      <td>270.54295</td>\n",
       "      <td>-20.408795</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.63</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>10.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>5.19</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4455</td>\n",
       "      <td>HIGALBM9.2569-0.2825</td>\n",
       "      <td>9.256889</td>\n",
       "      <td>-0.282502</td>\n",
       "      <td>271.81796</td>\n",
       "      <td>-21.076705</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-30.79</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>10.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>70.3</td>\n",
       "      <td>-3.38</td>\n",
       "      <td>4.31</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4456</td>\n",
       "      <td>HIGALBM9.2582-0.4725</td>\n",
       "      <td>9.258172</td>\n",
       "      <td>-0.472514</td>\n",
       "      <td>271.99662</td>\n",
       "      <td>-21.167985</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>12.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>7.70</td>\n",
       "      <td>19.08</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4457</td>\n",
       "      <td>HIGALBM9.2604-0.2253</td>\n",
       "      <td>9.260426</td>\n",
       "      <td>-0.225272</td>\n",
       "      <td>271.76624</td>\n",
       "      <td>-21.045749</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.06</td>\n",
       "      <td>-7.33</td>\n",
       "      <td>9.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>3.49</td>\n",
       "      <td>14.53</td>\n",
       "      <td>0.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4458</td>\n",
       "      <td>HIGALBM9.2626-0.1134</td>\n",
       "      <td>9.262623</td>\n",
       "      <td>-0.113445</td>\n",
       "      <td>271.66278</td>\n",
       "      <td>-20.989332</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-50.04</td>\n",
       "      <td>-18.92</td>\n",
       "      <td>9.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>55.3</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>3.51</td>\n",
       "      <td>14.56</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID           DESIGNATION      GLON      GLAT         ra        dec  \\\n",
       "0  4454  HIGALBM9.2545+1.0842  9.254488  1.084173  270.54295 -20.408795   \n",
       "1  4455  HIGALBM9.2569-0.2825  9.256889 -0.282502  271.81796 -21.076705   \n",
       "2  4456  HIGALBM9.2582-0.4725  9.258172 -0.472514  271.99662 -21.167985   \n",
       "3  4457  HIGALBM9.2604-0.2253  9.260426 -0.225272  271.76624 -21.045749   \n",
       "4  4458  HIGALBM9.2626-0.1134  9.262623 -0.113445  271.66278 -20.989332   \n",
       "\n",
       "  DESIGNATION_70  F70  DF70  F70_TOT  ...  EVOL_FLAG   MASS  DMASS   TEMP  \\\n",
       "0              -  0.0   0.0      0.0  ...        1.0  -7.63  -1.86  10.84   \n",
       "1              -  0.0   0.0      0.0  ...        1.0 -30.79  -6.40  10.31   \n",
       "2              -  0.0   0.0      0.0  ...        1.0 -10.36  -2.69  12.32   \n",
       "3              -  0.0   0.0      0.0  ...        1.0 -25.06  -7.33   9.47   \n",
       "4              -  0.0   0.0      0.0  ...        1.0 -50.04 -18.92   9.48   \n",
       "\n",
       "   DTEMP  LAM_0_TK L_BOL  LRATIO  T_BOL  SURF_DENS  \n",
       "0   0.48       0.0 -1.19    5.19  16.79      0.073  \n",
       "1   0.42      70.3 -3.38    4.31  15.70      0.551  \n",
       "2   0.66       0.0 -3.49    7.70  19.08      0.105  \n",
       "3   0.42      58.2 -1.69    3.49  14.53      0.377  \n",
       "4   0.42      55.3 -3.41    3.51  14.56      0.341  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>10666.594111</td>\n",
       "      <td>5659.007313</td>\n",
       "      <td>4454.000000</td>\n",
       "      <td>4886.750000</td>\n",
       "      <td>15760.500000</td>\n",
       "      <td>16193.250000</td>\n",
       "      <td>16626.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLON</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>20.681977</td>\n",
       "      <td>10.301232</td>\n",
       "      <td>9.254488</td>\n",
       "      <td>10.152985</td>\n",
       "      <td>30.025016</td>\n",
       "      <td>30.745236</td>\n",
       "      <td>31.496995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLAT</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>-0.103156</td>\n",
       "      <td>0.501320</td>\n",
       "      <td>-1.277056</td>\n",
       "      <td>-0.453265</td>\n",
       "      <td>-0.108080</td>\n",
       "      <td>0.225755</td>\n",
       "      <td>1.242487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ra</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>277.147742</td>\n",
       "      <td>4.875525</td>\n",
       "      <td>270.542950</td>\n",
       "      <td>272.292923</td>\n",
       "      <td>281.041685</td>\n",
       "      <td>281.903080</td>\n",
       "      <td>283.019690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dec</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>-10.894404</td>\n",
       "      <td>9.148600</td>\n",
       "      <td>-21.484523</td>\n",
       "      <td>-20.205528</td>\n",
       "      <td>-2.864130</td>\n",
       "      <td>-1.963998</td>\n",
       "      <td>-0.764793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAM_0_TK</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>35.739319</td>\n",
       "      <td>47.893383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.325000</td>\n",
       "      <td>285.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L_BOL</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>2184.957927</td>\n",
       "      <td>14235.393590</td>\n",
       "      <td>-3325.660000</td>\n",
       "      <td>-6.842500</td>\n",
       "      <td>-2.090000</td>\n",
       "      <td>301.497500</td>\n",
       "      <td>270267.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRATIO</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>42.264983</td>\n",
       "      <td>240.913000</td>\n",
       "      <td>2.220000</td>\n",
       "      <td>6.515000</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>31.475000</td>\n",
       "      <td>7107.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_BOL</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>28.223967</td>\n",
       "      <td>14.194161</td>\n",
       "      <td>11.930000</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>22.870000</td>\n",
       "      <td>36.035000</td>\n",
       "      <td>154.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SURF_DENS</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>0.468671</td>\n",
       "      <td>0.745867</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>9.068000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            count          mean           std          min          25%  \\\n",
       "ID         1732.0  10666.594111   5659.007313  4454.000000  4886.750000   \n",
       "GLON       1732.0     20.681977     10.301232     9.254488    10.152985   \n",
       "GLAT       1732.0     -0.103156      0.501320    -1.277056    -0.453265   \n",
       "ra         1732.0    277.147742      4.875525   270.542950   272.292923   \n",
       "dec        1732.0    -10.894404      9.148600   -21.484523   -20.205528   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "LAM_0_TK   1732.0     35.739319     47.893383     0.000000     0.000000   \n",
       "L_BOL      1732.0   2184.957927  14235.393590 -3325.660000    -6.842500   \n",
       "LRATIO     1732.0     42.264983    240.913000     2.220000     6.515000   \n",
       "T_BOL      1732.0     28.223967     14.194161    11.930000    18.270000   \n",
       "SURF_DENS  1732.0      0.468671      0.745867     0.007000     0.090000   \n",
       "\n",
       "                    50%           75%            max  \n",
       "ID         15760.500000  16193.250000   16626.000000  \n",
       "GLON          30.025016     30.745236      31.496995  \n",
       "GLAT          -0.108080      0.225755       1.242487  \n",
       "ra           281.041685    281.903080     283.019690  \n",
       "dec           -2.864130     -1.963998      -0.764793  \n",
       "...                 ...           ...            ...  \n",
       "LAM_0_TK       0.000000     68.325000     285.300000  \n",
       "L_BOL         -2.090000    301.497500  270267.530000  \n",
       "LRATIO        11.530000     31.475000    7107.340000  \n",
       "T_BOL         22.870000     36.035000     154.830000  \n",
       "SURF_DENS      0.220500      0.521000       9.068000  \n",
       "\n",
       "[61 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>10666.594111</td>\n",
       "      <td>5659.007313</td>\n",
       "      <td>4454.000000</td>\n",
       "      <td>4886.750000</td>\n",
       "      <td>15760.500000</td>\n",
       "      <td>16193.250000</td>\n",
       "      <td>16626.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLON</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>20.681977</td>\n",
       "      <td>10.301232</td>\n",
       "      <td>9.254488</td>\n",
       "      <td>10.152985</td>\n",
       "      <td>30.025016</td>\n",
       "      <td>30.745236</td>\n",
       "      <td>31.496995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLAT</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>-0.103156</td>\n",
       "      <td>0.501320</td>\n",
       "      <td>-1.277056</td>\n",
       "      <td>-0.453265</td>\n",
       "      <td>-0.108080</td>\n",
       "      <td>0.225755</td>\n",
       "      <td>1.242487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ra</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>277.147742</td>\n",
       "      <td>4.875525</td>\n",
       "      <td>270.542950</td>\n",
       "      <td>272.292923</td>\n",
       "      <td>281.041685</td>\n",
       "      <td>281.903080</td>\n",
       "      <td>283.019690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dec</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>-10.894404</td>\n",
       "      <td>9.148600</td>\n",
       "      <td>-21.484523</td>\n",
       "      <td>-20.205528</td>\n",
       "      <td>-2.864130</td>\n",
       "      <td>-1.963998</td>\n",
       "      <td>-0.764793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAM_0_TK</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>35.739319</td>\n",
       "      <td>47.893383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.325000</td>\n",
       "      <td>285.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L_BOL</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>2184.957927</td>\n",
       "      <td>14235.393590</td>\n",
       "      <td>-3325.660000</td>\n",
       "      <td>-6.842500</td>\n",
       "      <td>-2.090000</td>\n",
       "      <td>301.497500</td>\n",
       "      <td>270267.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRATIO</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>42.264983</td>\n",
       "      <td>240.913000</td>\n",
       "      <td>2.220000</td>\n",
       "      <td>6.515000</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>31.475000</td>\n",
       "      <td>7107.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_BOL</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>28.223967</td>\n",
       "      <td>14.194161</td>\n",
       "      <td>11.930000</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>22.870000</td>\n",
       "      <td>36.035000</td>\n",
       "      <td>154.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SURF_DENS</th>\n",
       "      <td>1732.0</td>\n",
       "      <td>0.468671</td>\n",
       "      <td>0.745867</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>9.068000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            count          mean           std          min          25%  \\\n",
       "ID         1732.0  10666.594111   5659.007313  4454.000000  4886.750000   \n",
       "GLON       1732.0     20.681977     10.301232     9.254488    10.152985   \n",
       "GLAT       1732.0     -0.103156      0.501320    -1.277056    -0.453265   \n",
       "ra         1732.0    277.147742      4.875525   270.542950   272.292923   \n",
       "dec        1732.0    -10.894404      9.148600   -21.484523   -20.205528   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "LAM_0_TK   1732.0     35.739319     47.893383     0.000000     0.000000   \n",
       "L_BOL      1732.0   2184.957927  14235.393590 -3325.660000    -6.842500   \n",
       "LRATIO     1732.0     42.264983    240.913000     2.220000     6.515000   \n",
       "T_BOL      1732.0     28.223967     14.194161    11.930000    18.270000   \n",
       "SURF_DENS  1732.0      0.468671      0.745867     0.007000     0.090000   \n",
       "\n",
       "                    50%           75%            max  \n",
       "ID         15760.500000  16193.250000   16626.000000  \n",
       "GLON          30.025016     30.745236      31.496995  \n",
       "GLAT          -0.108080      0.225755       1.242487  \n",
       "ra           281.041685    281.903080     283.019690  \n",
       "dec           -2.864130     -1.963998      -0.764793  \n",
       "...                 ...           ...            ...  \n",
       "LAM_0_TK       0.000000     68.325000     285.300000  \n",
       "L_BOL         -2.090000    301.497500  270267.530000  \n",
       "LRATIO        11.530000     31.475000    7107.340000  \n",
       "T_BOL         22.870000     36.035000     154.830000  \n",
       "SURF_DENS      0.220500      0.521000       9.068000  \n",
       "\n",
       "[61 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'DESIGNATION', 'GLON', 'GLAT', 'ra', 'dec', 'DESIGNATION_70',\n",
       "       'F70', 'DF70', 'F70_TOT', 'DF70_TOT', 'F70_ADD', 'DF70_ADD',\n",
       "       'F70_ADD_TOT', 'DF70_ADD_TOT', 'ULIM_70', 'DESIGNATION_160', 'F160',\n",
       "       'DF160', 'F160_ADD', 'DF160_ADD', 'ULIM_160', 'DESIGNATION_250', 'F250',\n",
       "       'DF250', 'DESIGNATION_350', 'F350', 'DF350', 'FSC350', 'DFSC350',\n",
       "       'DESIGNATION_500', 'F500', 'DF500', 'FSC500', 'DFSC500',\n",
       "       'DESIGNATION_21', 'F21', 'DF21', 'F21_TOT', 'DF21_TOT',\n",
       "       'DESIGNATION_22', 'F22', 'DF22', 'F22_TOT', 'DF22_TOT',\n",
       "       'DESIGNATION_24', 'F24', 'DF24', 'F24_TOT', 'DF24_TOT',\n",
       "       'DESIGNATION_870', 'F870', 'DF870', 'DESIGNATION_1100', 'F1100',\n",
       "       'DF1100', 'DFWHM250', 'DIST', 'NEAR_DIST', 'FAR_DIST', 'DIST_FLAG',\n",
       "       'DIAM', 'M_LARS', 'FIT_TYPE', 'EVOL_FLAG', 'MASS', 'DMASS', 'TEMP',\n",
       "       'DTEMP', 'LAM_0_TK', 'L_BOL', 'LRATIO', 'T_BOL', 'SURF_DENS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'DESIGNATION', 'GLON', 'GLAT', 'ra', 'dec', 'DESIGNATION_70',\n",
       "       'F70', 'DF70', 'F70_TOT', 'DF70_TOT', 'F70_ADD', 'DF70_ADD',\n",
       "       'F70_ADD_TOT', 'DF70_ADD_TOT', 'ULIM_70', 'DESIGNATION_160', 'F160',\n",
       "       'DF160', 'F160_ADD', 'DF160_ADD', 'ULIM_160', 'DESIGNATION_250', 'F250',\n",
       "       'DF250', 'DESIGNATION_350', 'F350', 'DF350', 'FSC350', 'DFSC350',\n",
       "       'DESIGNATION_500', 'F500', 'DF500', 'FSC500', 'DFSC500',\n",
       "       'DESIGNATION_21', 'F21', 'DF21', 'F21_TOT', 'DF21_TOT',\n",
       "       'DESIGNATION_22', 'F22', 'DF22', 'F22_TOT', 'DF22_TOT',\n",
       "       'DESIGNATION_24', 'F24', 'DF24', 'F24_TOT', 'DF24_TOT',\n",
       "       'DESIGNATION_870', 'F870', 'DF870', 'DESIGNATION_1100', 'F1100',\n",
       "       'DF1100', 'DFWHM250', 'DIST', 'NEAR_DIST', 'FAR_DIST', 'DIST_FLAG',\n",
       "       'DIAM', 'M_LARS', 'FIT_TYPE', 'EVOL_FLAG', 'MASS', 'DMASS', 'TEMP',\n",
       "       'DTEMP', 'LAM_0_TK', 'L_BOL', 'LRATIO', 'T_BOL', 'SURF_DENS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Act 2 - Data Prepration\n",
    "#### 2.1 Train Test Split\n",
    "- Get rid of those EVOL_FLAG == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>GLON</th>\n",
       "      <th>GLAT</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>DESIGNATION_70</th>\n",
       "      <th>F70</th>\n",
       "      <th>DF70</th>\n",
       "      <th>F70_TOT</th>\n",
       "      <th>...</th>\n",
       "      <th>EVOL_FLAG</th>\n",
       "      <th>MASS</th>\n",
       "      <th>DMASS</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DTEMP</th>\n",
       "      <th>LAM_0_TK</th>\n",
       "      <th>L_BOL</th>\n",
       "      <th>LRATIO</th>\n",
       "      <th>T_BOL</th>\n",
       "      <th>SURF_DENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4454</td>\n",
       "      <td>HIGALBM9.2545+1.0842</td>\n",
       "      <td>9.254488</td>\n",
       "      <td>1.084173</td>\n",
       "      <td>270.54295</td>\n",
       "      <td>-20.408795</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.63</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>10.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>5.19</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4455</td>\n",
       "      <td>HIGALBM9.2569-0.2825</td>\n",
       "      <td>9.256889</td>\n",
       "      <td>-0.282502</td>\n",
       "      <td>271.81796</td>\n",
       "      <td>-21.076705</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-30.79</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>10.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>70.3</td>\n",
       "      <td>-3.38</td>\n",
       "      <td>4.31</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4456</td>\n",
       "      <td>HIGALBM9.2582-0.4725</td>\n",
       "      <td>9.258172</td>\n",
       "      <td>-0.472514</td>\n",
       "      <td>271.99662</td>\n",
       "      <td>-21.167985</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>12.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>7.70</td>\n",
       "      <td>19.08</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4457</td>\n",
       "      <td>HIGALBM9.2604-0.2253</td>\n",
       "      <td>9.260426</td>\n",
       "      <td>-0.225272</td>\n",
       "      <td>271.76624</td>\n",
       "      <td>-21.045749</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.06</td>\n",
       "      <td>-7.33</td>\n",
       "      <td>9.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>3.49</td>\n",
       "      <td>14.53</td>\n",
       "      <td>0.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4458</td>\n",
       "      <td>HIGALBM9.2626-0.1134</td>\n",
       "      <td>9.262623</td>\n",
       "      <td>-0.113445</td>\n",
       "      <td>271.66278</td>\n",
       "      <td>-20.989332</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-50.04</td>\n",
       "      <td>-18.92</td>\n",
       "      <td>9.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>55.3</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>3.51</td>\n",
       "      <td>14.56</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>16621</td>\n",
       "      <td>HIGALBM31.4881+0.4038</td>\n",
       "      <td>31.488148</td>\n",
       "      <td>0.403803</td>\n",
       "      <td>281.84174</td>\n",
       "      <td>-1.100717</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.35</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>13.58</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>10.49</td>\n",
       "      <td>21.03</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>16623</td>\n",
       "      <td>HIGALBM31.4908+0.4419</td>\n",
       "      <td>31.490754</td>\n",
       "      <td>0.441868</td>\n",
       "      <td>281.80905</td>\n",
       "      <td>-1.081032</td>\n",
       "      <td>HIGALPB031.4908+0.4418</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.494</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>191.49</td>\n",
       "      <td>188.77</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.25</td>\n",
       "      <td>17.09</td>\n",
       "      <td>31.68</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>16624</td>\n",
       "      <td>HIGALBM31.4946-0.0244</td>\n",
       "      <td>31.494575</td>\n",
       "      <td>-0.024419</td>\n",
       "      <td>282.22583</td>\n",
       "      <td>-1.290333</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.84</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>15.64</td>\n",
       "      <td>23.58</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>16625</td>\n",
       "      <td>HIGALBM31.4962+0.1774</td>\n",
       "      <td>31.496159</td>\n",
       "      <td>0.177432</td>\n",
       "      <td>282.04688</td>\n",
       "      <td>-1.196855</td>\n",
       "      <td>HIGALPB031.4962+0.1773</td>\n",
       "      <td>17.853</td>\n",
       "      <td>0.919</td>\n",
       "      <td>17.853</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-12.70</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>16.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>105.3</td>\n",
       "      <td>-52.16</td>\n",
       "      <td>47.50</td>\n",
       "      <td>46.17</td>\n",
       "      <td>1.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>16626</td>\n",
       "      <td>HIGALBM31.4970-0.3651</td>\n",
       "      <td>31.496995</td>\n",
       "      <td>-0.365096</td>\n",
       "      <td>282.53021</td>\n",
       "      <td>-1.443540</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-17.44</td>\n",
       "      <td>-5.47</td>\n",
       "      <td>12.09</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.24</td>\n",
       "      <td>7.07</td>\n",
       "      <td>18.73</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1640 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID            DESIGNATION       GLON      GLAT         ra        dec  \\\n",
       "0      4454   HIGALBM9.2545+1.0842   9.254488  1.084173  270.54295 -20.408795   \n",
       "1      4455   HIGALBM9.2569-0.2825   9.256889 -0.282502  271.81796 -21.076705   \n",
       "2      4456   HIGALBM9.2582-0.4725   9.258172 -0.472514  271.99662 -21.167985   \n",
       "3      4457   HIGALBM9.2604-0.2253   9.260426 -0.225272  271.76624 -21.045749   \n",
       "4      4458   HIGALBM9.2626-0.1134   9.262623 -0.113445  271.66278 -20.989332   \n",
       "...     ...                    ...        ...       ...        ...        ...   \n",
       "1726  16621  HIGALBM31.4881+0.4038  31.488148  0.403803  281.84174  -1.100717   \n",
       "1728  16623  HIGALBM31.4908+0.4419  31.490754  0.441868  281.80905  -1.081032   \n",
       "1729  16624  HIGALBM31.4946-0.0244  31.494575 -0.024419  282.22583  -1.290333   \n",
       "1730  16625  HIGALBM31.4962+0.1774  31.496159  0.177432  282.04688  -1.196855   \n",
       "1731  16626  HIGALBM31.4970-0.3651  31.496995 -0.365096  282.53021  -1.443540   \n",
       "\n",
       "              DESIGNATION_70     F70   DF70  F70_TOT  ...  EVOL_FLAG    MASS  \\\n",
       "0                          -   0.000  0.000    0.000  ...        1.0   -7.63   \n",
       "1                          -   0.000  0.000    0.000  ...        1.0  -30.79   \n",
       "2                          -   0.000  0.000    0.000  ...        1.0  -10.36   \n",
       "3                          -   0.000  0.000    0.000  ...        1.0  -25.06   \n",
       "4                          -   0.000  0.000    0.000  ...        1.0  -50.04   \n",
       "...                      ...     ...    ...      ...  ...        ...     ...   \n",
       "1726                       -   0.000  0.000    0.000  ...        1.0  -11.35   \n",
       "1728  HIGALPB031.4908+0.4418   0.494  0.050    0.494  ...        2.0  191.49   \n",
       "1729                       -   0.000  0.000    0.000  ...        1.0   -3.84   \n",
       "1730  HIGALPB031.4962+0.1773  17.853  0.919   17.853  ...        2.0  -12.70   \n",
       "1731                       -   0.000  0.000    0.000  ...        1.0  -17.44   \n",
       "\n",
       "       DMASS   TEMP  DTEMP  LAM_0_TK   L_BOL  LRATIO  T_BOL  SURF_DENS  \n",
       "0      -1.86  10.84   0.48       0.0   -1.19    5.19  16.79      0.073  \n",
       "1      -6.40  10.31   0.42      70.3   -3.38    4.31  15.70      0.551  \n",
       "2      -2.69  12.32   0.66       0.0   -3.49    7.70  19.08      0.105  \n",
       "3      -7.33   9.47   0.42      58.2   -1.69    3.49  14.53      0.377  \n",
       "4     -18.92   9.48   0.42      55.3   -3.41    3.51  14.56      0.341  \n",
       "...      ...    ...    ...       ...     ...     ...    ...        ...  \n",
       "1726   -2.15  13.58   0.90       0.0   -6.85   10.49  21.03      0.125  \n",
       "1728  188.77  12.76   0.21       0.0  159.25   17.09  31.68      0.180  \n",
       "1729   -1.01  15.23   1.03       0.0   -4.61   15.64  23.58      0.065  \n",
       "1730   -0.24  16.18   0.12     105.3  -52.16   47.50  46.17      1.235  \n",
       "1731   -5.47  12.09   0.78       0.0   -5.24    7.07  18.73      0.181  \n",
       "\n",
       "[1640 rows x 74 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1 = cat[cat['EVOL_FLAG'] != 0]\n",
    "cat1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Prepare X\n",
    "Set your X:\n",
    "- X=cat where ['F70', 'F160', 'F250', 'F350', 'F500', 'F21', 'F22', 'F24', 'F870', 'F1100', 'DFWHM250']\n",
    "\n",
    "Set your y:\n",
    "\n",
    "Use get_dummies to add a new column to your data! You want 0.0 for 'Flag_1' and 1.0 for 'Flag_2'\n",
    "- Make sure this new column has the format of integer!\n",
    "- Maybe call this new column 'Evolution_Falg_dummies'\n",
    "- Hint: Use this: drop_first=True, why?\n",
    "- Check this out: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
    "\n",
    "- y=cat['Evolution_Falg_dummies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F70</th>\n",
       "      <th>F160</th>\n",
       "      <th>F250</th>\n",
       "      <th>F350</th>\n",
       "      <th>F500</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F24</th>\n",
       "      <th>F870</th>\n",
       "      <th>F1100</th>\n",
       "      <th>DFWHM250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.852</td>\n",
       "      <td>3.755</td>\n",
       "      <td>1.703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>3.454</td>\n",
       "      <td>11.413</td>\n",
       "      <td>6.738</td>\n",
       "      <td>10.814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.697</td>\n",
       "      <td>6.108</td>\n",
       "      <td>2.948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.229</td>\n",
       "      <td>8.061</td>\n",
       "      <td>4.141</td>\n",
       "      <td>5.217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>30.386</td>\n",
       "      <td>10.795</td>\n",
       "      <td>5.831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.327</td>\n",
       "      <td>15.921</td>\n",
       "      <td>8.838</td>\n",
       "      <td>3.416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>0.494</td>\n",
       "      <td>1.732</td>\n",
       "      <td>2.816</td>\n",
       "      <td>2.499</td>\n",
       "      <td>2.009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.936</td>\n",
       "      <td>8.044</td>\n",
       "      <td>4.126</td>\n",
       "      <td>2.537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>17.853</td>\n",
       "      <td>27.037</td>\n",
       "      <td>38.971</td>\n",
       "      <td>21.206</td>\n",
       "      <td>10.956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.763</td>\n",
       "      <td>1.604</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.925</td>\n",
       "      <td>15.190</td>\n",
       "      <td>11.845</td>\n",
       "      <td>4.672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1640 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         F70    F160    F250    F350    F500  F21    F22    F24  F870  F1100  \\\n",
       "0      0.000   0.000   4.852   3.755   1.703  0.0  0.000  0.000  0.00    0.0   \n",
       "1      0.000   3.454  11.413   6.738  10.814  0.0  0.000  0.000  0.00    0.0   \n",
       "2      0.000   0.000   9.697   6.108   2.948  0.0  0.000  0.000  0.00    0.0   \n",
       "3      0.000   1.229   8.061   4.141   5.217  0.0  0.000  0.000  0.00    0.0   \n",
       "4      0.000   0.000  30.386  10.795   5.831  0.0  0.000  0.000  0.00    0.0   \n",
       "...      ...     ...     ...     ...     ...  ...    ...    ...   ...    ...   \n",
       "1726   0.000   6.327  15.921   8.838   3.416  0.0  0.000  0.000  0.00    0.0   \n",
       "1728   0.494   1.732   2.816   2.499   2.009  0.0  0.000  0.003  0.15    0.0   \n",
       "1729   0.000   6.936   8.044   4.126   2.537  0.0  0.000  0.000  0.00    0.0   \n",
       "1730  17.853  27.037  38.971  21.206  10.956  0.0  1.763  1.604  0.86    0.0   \n",
       "1731   0.000   5.925  15.190  11.845   4.672  0.0  0.050  0.000  0.00    0.0   \n",
       "\n",
       "      DFWHM250  \n",
       "0        34.38  \n",
       "1        25.14  \n",
       "2        33.38  \n",
       "3        27.42  \n",
       "4        40.76  \n",
       "...        ...  \n",
       "1726     32.12  \n",
       "1728     13.16  \n",
       "1729     25.95  \n",
       "1730     10.79  \n",
       "1731     32.99  \n",
       "\n",
       "[1640 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cat1[['F70', 'F160', 'F250', 'F350', 'F500', 'F21', 'F22', 'F24', 'F870', 'F1100', 'DFWHM250']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>GLON</th>\n",
       "      <th>GLAT</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>DESIGNATION_70</th>\n",
       "      <th>F70</th>\n",
       "      <th>DF70</th>\n",
       "      <th>F70_TOT</th>\n",
       "      <th>...</th>\n",
       "      <th>MASS</th>\n",
       "      <th>DMASS</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DTEMP</th>\n",
       "      <th>LAM_0_TK</th>\n",
       "      <th>L_BOL</th>\n",
       "      <th>LRATIO</th>\n",
       "      <th>T_BOL</th>\n",
       "      <th>SURF_DENS</th>\n",
       "      <th>Evol_Flag_Dummies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4454</td>\n",
       "      <td>HIGALBM9.2545+1.0842</td>\n",
       "      <td>9.254488</td>\n",
       "      <td>1.084173</td>\n",
       "      <td>270.54295</td>\n",
       "      <td>-20.408795</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.63</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>10.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>5.19</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4455</td>\n",
       "      <td>HIGALBM9.2569-0.2825</td>\n",
       "      <td>9.256889</td>\n",
       "      <td>-0.282502</td>\n",
       "      <td>271.81796</td>\n",
       "      <td>-21.076705</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.79</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>10.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>70.3</td>\n",
       "      <td>-3.38</td>\n",
       "      <td>4.31</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4456</td>\n",
       "      <td>HIGALBM9.2582-0.4725</td>\n",
       "      <td>9.258172</td>\n",
       "      <td>-0.472514</td>\n",
       "      <td>271.99662</td>\n",
       "      <td>-21.167985</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>12.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>7.70</td>\n",
       "      <td>19.08</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4457</td>\n",
       "      <td>HIGALBM9.2604-0.2253</td>\n",
       "      <td>9.260426</td>\n",
       "      <td>-0.225272</td>\n",
       "      <td>271.76624</td>\n",
       "      <td>-21.045749</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.06</td>\n",
       "      <td>-7.33</td>\n",
       "      <td>9.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>3.49</td>\n",
       "      <td>14.53</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4458</td>\n",
       "      <td>HIGALBM9.2626-0.1134</td>\n",
       "      <td>9.262623</td>\n",
       "      <td>-0.113445</td>\n",
       "      <td>271.66278</td>\n",
       "      <td>-20.989332</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.04</td>\n",
       "      <td>-18.92</td>\n",
       "      <td>9.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>55.3</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>3.51</td>\n",
       "      <td>14.56</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>16622</td>\n",
       "      <td>HIGALBM31.4906+0.8712</td>\n",
       "      <td>31.490578</td>\n",
       "      <td>0.871197</td>\n",
       "      <td>281.42688</td>\n",
       "      <td>-0.885295</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.10</td>\n",
       "      <td>28.89</td>\n",
       "      <td>13.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.60</td>\n",
       "      <td>10.23</td>\n",
       "      <td>20.92</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>16623</td>\n",
       "      <td>HIGALBM31.4908+0.4419</td>\n",
       "      <td>31.490754</td>\n",
       "      <td>0.441868</td>\n",
       "      <td>281.80905</td>\n",
       "      <td>-1.081032</td>\n",
       "      <td>HIGALPB031.4908+0.4418</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.494</td>\n",
       "      <td>...</td>\n",
       "      <td>191.49</td>\n",
       "      <td>188.77</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.25</td>\n",
       "      <td>17.09</td>\n",
       "      <td>31.68</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>16624</td>\n",
       "      <td>HIGALBM31.4946-0.0244</td>\n",
       "      <td>31.494575</td>\n",
       "      <td>-0.024419</td>\n",
       "      <td>282.22583</td>\n",
       "      <td>-1.290333</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.84</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>15.64</td>\n",
       "      <td>23.58</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>16625</td>\n",
       "      <td>HIGALBM31.4962+0.1774</td>\n",
       "      <td>31.496159</td>\n",
       "      <td>0.177432</td>\n",
       "      <td>282.04688</td>\n",
       "      <td>-1.196855</td>\n",
       "      <td>HIGALPB031.4962+0.1773</td>\n",
       "      <td>17.853</td>\n",
       "      <td>0.919</td>\n",
       "      <td>17.853</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.70</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>16.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>105.3</td>\n",
       "      <td>-52.16</td>\n",
       "      <td>47.50</td>\n",
       "      <td>46.17</td>\n",
       "      <td>1.235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>16626</td>\n",
       "      <td>HIGALBM31.4970-0.3651</td>\n",
       "      <td>31.496995</td>\n",
       "      <td>-0.365096</td>\n",
       "      <td>282.53021</td>\n",
       "      <td>-1.443540</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.44</td>\n",
       "      <td>-5.47</td>\n",
       "      <td>12.09</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.24</td>\n",
       "      <td>7.07</td>\n",
       "      <td>18.73</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1732 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID            DESIGNATION       GLON      GLAT         ra        dec  \\\n",
       "0      4454   HIGALBM9.2545+1.0842   9.254488  1.084173  270.54295 -20.408795   \n",
       "1      4455   HIGALBM9.2569-0.2825   9.256889 -0.282502  271.81796 -21.076705   \n",
       "2      4456   HIGALBM9.2582-0.4725   9.258172 -0.472514  271.99662 -21.167985   \n",
       "3      4457   HIGALBM9.2604-0.2253   9.260426 -0.225272  271.76624 -21.045749   \n",
       "4      4458   HIGALBM9.2626-0.1134   9.262623 -0.113445  271.66278 -20.989332   \n",
       "...     ...                    ...        ...       ...        ...        ...   \n",
       "1727  16622  HIGALBM31.4906+0.8712  31.490578  0.871197  281.42688  -0.885295   \n",
       "1728  16623  HIGALBM31.4908+0.4419  31.490754  0.441868  281.80905  -1.081032   \n",
       "1729  16624  HIGALBM31.4946-0.0244  31.494575 -0.024419  282.22583  -1.290333   \n",
       "1730  16625  HIGALBM31.4962+0.1774  31.496159  0.177432  282.04688  -1.196855   \n",
       "1731  16626  HIGALBM31.4970-0.3651  31.496995 -0.365096  282.53021  -1.443540   \n",
       "\n",
       "              DESIGNATION_70     F70   DF70  F70_TOT  ...    MASS   DMASS  \\\n",
       "0                          -   0.000  0.000    0.000  ...   -7.63   -1.86   \n",
       "1                          -   0.000  0.000    0.000  ...  -30.79   -6.40   \n",
       "2                          -   0.000  0.000    0.000  ...  -10.36   -2.69   \n",
       "3                          -   0.000  0.000    0.000  ...  -25.06   -7.33   \n",
       "4                          -   0.000  0.000    0.000  ...  -50.04  -18.92   \n",
       "...                      ...     ...    ...      ...  ...     ...     ...   \n",
       "1727                       -   0.000  0.000    0.000  ...   30.10   28.89   \n",
       "1728  HIGALPB031.4908+0.4418   0.494  0.050    0.494  ...  191.49  188.77   \n",
       "1729                       -   0.000  0.000    0.000  ...   -3.84   -1.01   \n",
       "1730  HIGALPB031.4962+0.1773  17.853  0.919   17.853  ...  -12.70   -0.24   \n",
       "1731                       -   0.000  0.000    0.000  ...  -17.44   -5.47   \n",
       "\n",
       "       TEMP  DTEMP  LAM_0_TK   L_BOL LRATIO  T_BOL  SURF_DENS  \\\n",
       "0     10.84   0.48       0.0   -1.19   5.19  16.79      0.073   \n",
       "1     10.31   0.42      70.3   -3.38   4.31  15.70      0.551   \n",
       "2     12.32   0.66       0.0   -3.49   7.70  19.08      0.105   \n",
       "3      9.47   0.42      58.2   -1.69   3.49  14.53      0.377   \n",
       "4      9.48   0.42      55.3   -3.41   3.51  14.56      0.341   \n",
       "...     ...    ...       ...     ...    ...    ...        ...   \n",
       "1727  13.51   0.78       0.0   17.60  10.23  20.92      0.028   \n",
       "1728  12.76   0.21       0.0  159.25  17.09  31.68      0.180   \n",
       "1729  15.23   1.03       0.0   -4.61  15.64  23.58      0.065   \n",
       "1730  16.18   0.12     105.3  -52.16  47.50  46.17      1.235   \n",
       "1731  12.09   0.78       0.0   -5.24   7.07  18.73      0.181   \n",
       "\n",
       "      Evol_Flag_Dummies  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "1727                  0  \n",
       "1728                  0  \n",
       "1729                  0  \n",
       "1730                  0  \n",
       "1731                  0  \n",
       "\n",
       "[1732 rows x 75 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-102b4025ed67>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat1['Evol_Flag_Dummies'] = pd.get_dummies(s, drop_first = True, dtype = int)\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(data=cat1['EVOL_FLAG'])\n",
    "cat1['Evol_Flag_Dummies'] = pd.get_dummies(s, drop_first = True, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>GLON</th>\n",
       "      <th>GLAT</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>DESIGNATION_70</th>\n",
       "      <th>F70</th>\n",
       "      <th>DF70</th>\n",
       "      <th>F70_TOT</th>\n",
       "      <th>...</th>\n",
       "      <th>MASS</th>\n",
       "      <th>DMASS</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DTEMP</th>\n",
       "      <th>LAM_0_TK</th>\n",
       "      <th>L_BOL</th>\n",
       "      <th>LRATIO</th>\n",
       "      <th>T_BOL</th>\n",
       "      <th>SURF_DENS</th>\n",
       "      <th>Evol_Flag_Dummies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4454</td>\n",
       "      <td>HIGALBM9.2545+1.0842</td>\n",
       "      <td>9.254488</td>\n",
       "      <td>1.084173</td>\n",
       "      <td>270.54295</td>\n",
       "      <td>-20.408795</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.63</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>10.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>5.19</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4455</td>\n",
       "      <td>HIGALBM9.2569-0.2825</td>\n",
       "      <td>9.256889</td>\n",
       "      <td>-0.282502</td>\n",
       "      <td>271.81796</td>\n",
       "      <td>-21.076705</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.79</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>10.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>70.3</td>\n",
       "      <td>-3.38</td>\n",
       "      <td>4.31</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4456</td>\n",
       "      <td>HIGALBM9.2582-0.4725</td>\n",
       "      <td>9.258172</td>\n",
       "      <td>-0.472514</td>\n",
       "      <td>271.99662</td>\n",
       "      <td>-21.167985</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>12.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>7.70</td>\n",
       "      <td>19.08</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4457</td>\n",
       "      <td>HIGALBM9.2604-0.2253</td>\n",
       "      <td>9.260426</td>\n",
       "      <td>-0.225272</td>\n",
       "      <td>271.76624</td>\n",
       "      <td>-21.045749</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.06</td>\n",
       "      <td>-7.33</td>\n",
       "      <td>9.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>3.49</td>\n",
       "      <td>14.53</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4458</td>\n",
       "      <td>HIGALBM9.2626-0.1134</td>\n",
       "      <td>9.262623</td>\n",
       "      <td>-0.113445</td>\n",
       "      <td>271.66278</td>\n",
       "      <td>-20.989332</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.04</td>\n",
       "      <td>-18.92</td>\n",
       "      <td>9.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>55.3</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>3.51</td>\n",
       "      <td>14.56</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>16621</td>\n",
       "      <td>HIGALBM31.4881+0.4038</td>\n",
       "      <td>31.488148</td>\n",
       "      <td>0.403803</td>\n",
       "      <td>281.84174</td>\n",
       "      <td>-1.100717</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.35</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>13.58</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>10.49</td>\n",
       "      <td>21.03</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>16623</td>\n",
       "      <td>HIGALBM31.4908+0.4419</td>\n",
       "      <td>31.490754</td>\n",
       "      <td>0.441868</td>\n",
       "      <td>281.80905</td>\n",
       "      <td>-1.081032</td>\n",
       "      <td>HIGALPB031.4908+0.4418</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.494</td>\n",
       "      <td>...</td>\n",
       "      <td>191.49</td>\n",
       "      <td>188.77</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.25</td>\n",
       "      <td>17.09</td>\n",
       "      <td>31.68</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>16624</td>\n",
       "      <td>HIGALBM31.4946-0.0244</td>\n",
       "      <td>31.494575</td>\n",
       "      <td>-0.024419</td>\n",
       "      <td>282.22583</td>\n",
       "      <td>-1.290333</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.84</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>15.64</td>\n",
       "      <td>23.58</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>16625</td>\n",
       "      <td>HIGALBM31.4962+0.1774</td>\n",
       "      <td>31.496159</td>\n",
       "      <td>0.177432</td>\n",
       "      <td>282.04688</td>\n",
       "      <td>-1.196855</td>\n",
       "      <td>HIGALPB031.4962+0.1773</td>\n",
       "      <td>17.853</td>\n",
       "      <td>0.919</td>\n",
       "      <td>17.853</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.70</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>16.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>105.3</td>\n",
       "      <td>-52.16</td>\n",
       "      <td>47.50</td>\n",
       "      <td>46.17</td>\n",
       "      <td>1.235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>16626</td>\n",
       "      <td>HIGALBM31.4970-0.3651</td>\n",
       "      <td>31.496995</td>\n",
       "      <td>-0.365096</td>\n",
       "      <td>282.53021</td>\n",
       "      <td>-1.443540</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.44</td>\n",
       "      <td>-5.47</td>\n",
       "      <td>12.09</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.24</td>\n",
       "      <td>7.07</td>\n",
       "      <td>18.73</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1640 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID            DESIGNATION       GLON      GLAT         ra        dec  \\\n",
       "0      4454   HIGALBM9.2545+1.0842   9.254488  1.084173  270.54295 -20.408795   \n",
       "1      4455   HIGALBM9.2569-0.2825   9.256889 -0.282502  271.81796 -21.076705   \n",
       "2      4456   HIGALBM9.2582-0.4725   9.258172 -0.472514  271.99662 -21.167985   \n",
       "3      4457   HIGALBM9.2604-0.2253   9.260426 -0.225272  271.76624 -21.045749   \n",
       "4      4458   HIGALBM9.2626-0.1134   9.262623 -0.113445  271.66278 -20.989332   \n",
       "...     ...                    ...        ...       ...        ...        ...   \n",
       "1726  16621  HIGALBM31.4881+0.4038  31.488148  0.403803  281.84174  -1.100717   \n",
       "1728  16623  HIGALBM31.4908+0.4419  31.490754  0.441868  281.80905  -1.081032   \n",
       "1729  16624  HIGALBM31.4946-0.0244  31.494575 -0.024419  282.22583  -1.290333   \n",
       "1730  16625  HIGALBM31.4962+0.1774  31.496159  0.177432  282.04688  -1.196855   \n",
       "1731  16626  HIGALBM31.4970-0.3651  31.496995 -0.365096  282.53021  -1.443540   \n",
       "\n",
       "              DESIGNATION_70     F70   DF70  F70_TOT  ...    MASS   DMASS  \\\n",
       "0                          -   0.000  0.000    0.000  ...   -7.63   -1.86   \n",
       "1                          -   0.000  0.000    0.000  ...  -30.79   -6.40   \n",
       "2                          -   0.000  0.000    0.000  ...  -10.36   -2.69   \n",
       "3                          -   0.000  0.000    0.000  ...  -25.06   -7.33   \n",
       "4                          -   0.000  0.000    0.000  ...  -50.04  -18.92   \n",
       "...                      ...     ...    ...      ...  ...     ...     ...   \n",
       "1726                       -   0.000  0.000    0.000  ...  -11.35   -2.15   \n",
       "1728  HIGALPB031.4908+0.4418   0.494  0.050    0.494  ...  191.49  188.77   \n",
       "1729                       -   0.000  0.000    0.000  ...   -3.84   -1.01   \n",
       "1730  HIGALPB031.4962+0.1773  17.853  0.919   17.853  ...  -12.70   -0.24   \n",
       "1731                       -   0.000  0.000    0.000  ...  -17.44   -5.47   \n",
       "\n",
       "       TEMP  DTEMP  LAM_0_TK   L_BOL LRATIO  T_BOL  SURF_DENS  \\\n",
       "0     10.84   0.48       0.0   -1.19   5.19  16.79      0.073   \n",
       "1     10.31   0.42      70.3   -3.38   4.31  15.70      0.551   \n",
       "2     12.32   0.66       0.0   -3.49   7.70  19.08      0.105   \n",
       "3      9.47   0.42      58.2   -1.69   3.49  14.53      0.377   \n",
       "4      9.48   0.42      55.3   -3.41   3.51  14.56      0.341   \n",
       "...     ...    ...       ...     ...    ...    ...        ...   \n",
       "1726  13.58   0.90       0.0   -6.85  10.49  21.03      0.125   \n",
       "1728  12.76   0.21       0.0  159.25  17.09  31.68      0.180   \n",
       "1729  15.23   1.03       0.0   -4.61  15.64  23.58      0.065   \n",
       "1730  16.18   0.12     105.3  -52.16  47.50  46.17      1.235   \n",
       "1731  12.09   0.78       0.0   -5.24   7.07  18.73      0.181   \n",
       "\n",
       "      Evol_Flag_Dummies  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "1726                  0  \n",
       "1728                  1  \n",
       "1729                  0  \n",
       "1730                  1  \n",
       "1731                  0  \n",
       "\n",
       "[1640 rows x 75 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4e4fe533aa97>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['Evolution_Falg_dummies'] = pd.get_dummies(cat['EVOL_FLAG'], drop_first=True).astype('int')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = cat1['Evol_Flag_Dummies']\n",
    "X_train, X_new, y_train, y_new = train_test_split(X,Y, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 perform your train test split\n",
    "However, do it twice to create train 70%, validation 15%, & test set 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation, X_test, y_validation, y_test = train_test_split(X_new,y_new, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1640, 11), (1148, 11), (246, 11), (246, 11))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_train.shape, X_validation.shape, X_test.shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Now perform the scaling on your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scal = StandardScaler()\n",
    "scld_X_train = scal.fit_transform(X_train)\n",
    "scld_X_validation = scal.transform(X_validation)\n",
    "scld_X_test = scal.transform(X_test)\n",
    "scaled_X_train = pd.DataFrame(scld_X_train, columns=X.columns)\n",
    "scaled_X_validation = pd.DataFrame(scld_X_validation, columns=X.columns)\n",
    "scaled_X_test = pd.DataFrame(scld_X_test, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Act 3 - Perform the ANN\n",
    "\n",
    "#### 3.1 Create your model \n",
    "It should contain:\n",
    "- 3 hidden layers of 18-10-10\n",
    "- 1 output\n",
    "- Add activations apprpriately!\n",
    "\n",
    "- **make sure to compile it with appropriate optimizer and loss!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note:\n",
    "#### For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "             )\n",
    "\n",
    "#### For a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              )\n",
    "\n",
    "#### For a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "              \n",
    "### You may want to change optimizer to ADAM though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Let's add more to your model! \n",
    "After each layer add 50% dropout (this should exculde the last one, why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(18, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 We don't want our code to overfit, so import the early stopping and add the parameters appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model with no early stopping!\n",
    "#### 3.4 Fit your model\n",
    "- Make sure to use epochs, verbose, and validation_data\n",
    "- **Howver, for the sake of this exrsice exclude the batch_size and callbacks**\n",
    "- I used epoche=1000 you may choose smaller number if you want the code to run faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "38/38 [==============================] - 2s 10ms/step - loss: 0.7181 - val_loss: 0.6798\n",
      "Epoch 2/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.7188 - val_loss: 0.6791\n",
      "Epoch 3/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6917 - val_loss: 0.6767\n",
      "Epoch 4/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6818 - val_loss: 0.6723\n",
      "Epoch 5/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6935 - val_loss: 0.6713\n",
      "Epoch 6/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6815 - val_loss: 0.6693\n",
      "Epoch 7/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6839 - val_loss: 0.6679\n",
      "Epoch 8/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6811 - val_loss: 0.6666\n",
      "Epoch 9/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6847 - val_loss: 0.6644\n",
      "Epoch 10/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6734 - val_loss: 0.6614\n",
      "Epoch 11/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6728 - val_loss: 0.6594\n",
      "Epoch 12/600\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.6824 - val_loss: 0.6567\n",
      "Epoch 13/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6770 - val_loss: 0.6574\n",
      "Epoch 14/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6673 - val_loss: 0.6546\n",
      "Epoch 15/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6691 - val_loss: 0.6487\n",
      "Epoch 16/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6680 - val_loss: 0.6456\n",
      "Epoch 17/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6612 - val_loss: 0.6417\n",
      "Epoch 18/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6554 - val_loss: 0.6379\n",
      "Epoch 19/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6609 - val_loss: 0.6374\n",
      "Epoch 20/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6645 - val_loss: 0.6354\n",
      "Epoch 21/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6727 - val_loss: 0.6374\n",
      "Epoch 22/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6402 - val_loss: 0.6333\n",
      "Epoch 23/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6440 - val_loss: 0.6286\n",
      "Epoch 24/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6416 - val_loss: 0.6256\n",
      "Epoch 25/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6381 - val_loss: 0.6181\n",
      "Epoch 26/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6154\n",
      "Epoch 27/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6454 - val_loss: 0.6175\n",
      "Epoch 28/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6338 - val_loss: 0.6134\n",
      "Epoch 29/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6554 - val_loss: 0.6108\n",
      "Epoch 30/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6128\n",
      "Epoch 31/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6367 - val_loss: 0.6052\n",
      "Epoch 32/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6415 - val_loss: 0.6032\n",
      "Epoch 33/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6011\n",
      "Epoch 34/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6168 - val_loss: 0.5955\n",
      "Epoch 35/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6294 - val_loss: 0.5939\n",
      "Epoch 36/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6300 - val_loss: 0.5897\n",
      "Epoch 37/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6280 - val_loss: 0.5849\n",
      "Epoch 38/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6316 - val_loss: 0.5838\n",
      "Epoch 39/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6301 - val_loss: 0.5823\n",
      "Epoch 40/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6196 - val_loss: 0.5784\n",
      "Epoch 41/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6103 - val_loss: 0.5743\n",
      "Epoch 42/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5974 - val_loss: 0.5625\n",
      "Epoch 43/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5952 - val_loss: 0.5594\n",
      "Epoch 44/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6148 - val_loss: 0.5546\n",
      "Epoch 45/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6066 - val_loss: 0.5504\n",
      "Epoch 46/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6085 - val_loss: 0.5443\n",
      "Epoch 47/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6133 - val_loss: 0.5434\n",
      "Epoch 48/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6008 - val_loss: 0.5376\n",
      "Epoch 49/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5953 - val_loss: 0.5265\n",
      "Epoch 50/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5975 - val_loss: 0.5288\n",
      "Epoch 51/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5879 - val_loss: 0.5160\n",
      "Epoch 52/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5780 - val_loss: 0.5058\n",
      "Epoch 53/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5854 - val_loss: 0.5021\n",
      "Epoch 54/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6134 - val_loss: 0.5010\n",
      "Epoch 55/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5792 - val_loss: 0.4957\n",
      "Epoch 56/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.5012\n",
      "Epoch 57/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5685 - val_loss: 0.4897\n",
      "Epoch 58/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5655 - val_loss: 0.4803\n",
      "Epoch 59/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5857 - val_loss: 0.4782\n",
      "Epoch 60/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5561 - val_loss: 0.4799\n",
      "Epoch 61/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5414 - val_loss: 0.4633\n",
      "Epoch 62/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5517 - val_loss: 0.4587\n",
      "Epoch 63/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5672 - val_loss: 0.4547\n",
      "Epoch 64/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5389 - val_loss: 0.4422\n",
      "Epoch 65/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5443 - val_loss: 0.4406\n",
      "Epoch 66/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5438 - val_loss: 0.4393\n",
      "Epoch 67/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5402 - val_loss: 0.4341\n",
      "Epoch 68/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5540 - val_loss: 0.4322\n",
      "Epoch 69/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5401 - val_loss: 0.4314\n",
      "Epoch 70/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5453 - val_loss: 0.4314\n",
      "Epoch 71/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5360 - val_loss: 0.4273\n",
      "Epoch 72/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5291 - val_loss: 0.4226\n",
      "Epoch 73/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5331 - val_loss: 0.4198\n",
      "Epoch 74/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5298 - val_loss: 0.4176\n",
      "Epoch 75/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5387 - val_loss: 0.4114\n",
      "Epoch 76/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5371 - val_loss: 0.4133\n",
      "Epoch 77/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5290 - val_loss: 0.4105\n",
      "Epoch 78/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5365 - val_loss: 0.4072\n",
      "Epoch 79/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5589 - val_loss: 0.4068\n",
      "Epoch 80/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5166 - val_loss: 0.4080\n",
      "Epoch 81/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5341 - val_loss: 0.4041\n",
      "Epoch 82/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5430 - val_loss: 0.4065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5207 - val_loss: 0.4006\n",
      "Epoch 84/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5203 - val_loss: 0.3991\n",
      "Epoch 85/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5276 - val_loss: 0.3951\n",
      "Epoch 86/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5122 - val_loss: 0.3919\n",
      "Epoch 87/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5034 - val_loss: 0.3885\n",
      "Epoch 88/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5062 - val_loss: 0.3950\n",
      "Epoch 89/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5353 - val_loss: 0.3950\n",
      "Epoch 90/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5170 - val_loss: 0.3905\n",
      "Epoch 91/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5007 - val_loss: 0.3858\n",
      "Epoch 92/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4944 - val_loss: 0.3793\n",
      "Epoch 93/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5014 - val_loss: 0.3764\n",
      "Epoch 94/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5044 - val_loss: 0.3752\n",
      "Epoch 95/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5152 - val_loss: 0.3705\n",
      "Epoch 96/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4918 - val_loss: 0.3660\n",
      "Epoch 97/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4971 - val_loss: 0.3648\n",
      "Epoch 98/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5061 - val_loss: 0.3638\n",
      "Epoch 99/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5025 - val_loss: 0.3664\n",
      "Epoch 100/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4854 - val_loss: 0.3659\n",
      "Epoch 101/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5198 - val_loss: 0.3683\n",
      "Epoch 102/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4785 - val_loss: 0.3600\n",
      "Epoch 103/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5023 - val_loss: 0.3610\n",
      "Epoch 104/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4907 - val_loss: 0.3578\n",
      "Epoch 105/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5014 - val_loss: 0.3527\n",
      "Epoch 106/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4772 - val_loss: 0.3508\n",
      "Epoch 107/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4944 - val_loss: 0.3502\n",
      "Epoch 108/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5069 - val_loss: 0.3504\n",
      "Epoch 109/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4800 - val_loss: 0.3470\n",
      "Epoch 110/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4966 - val_loss: 0.3484\n",
      "Epoch 111/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4800 - val_loss: 0.3450\n",
      "Epoch 112/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4929 - val_loss: 0.3495\n",
      "Epoch 113/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4884 - val_loss: 0.3447\n",
      "Epoch 114/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4660 - val_loss: 0.3528\n",
      "Epoch 115/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4870 - val_loss: 0.3579\n",
      "Epoch 116/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4837 - val_loss: 0.3510\n",
      "Epoch 117/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4665 - val_loss: 0.3477\n",
      "Epoch 118/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4742 - val_loss: 0.3436\n",
      "Epoch 119/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4711 - val_loss: 0.3379\n",
      "Epoch 120/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4627 - val_loss: 0.3360\n",
      "Epoch 121/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4778 - val_loss: 0.3320\n",
      "Epoch 122/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4831 - val_loss: 0.3334\n",
      "Epoch 123/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4674 - val_loss: 0.3308\n",
      "Epoch 124/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4993 - val_loss: 0.3359\n",
      "Epoch 125/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4772 - val_loss: 0.3361\n",
      "Epoch 126/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4760 - val_loss: 0.3392\n",
      "Epoch 127/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4967 - val_loss: 0.3351\n",
      "Epoch 128/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4727 - val_loss: 0.3329\n",
      "Epoch 129/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4691 - val_loss: 0.3340\n",
      "Epoch 130/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4706 - val_loss: 0.3272\n",
      "Epoch 131/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4573 - val_loss: 0.3277\n",
      "Epoch 132/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4400 - val_loss: 0.3204\n",
      "Epoch 133/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4621 - val_loss: 0.3178\n",
      "Epoch 134/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4690 - val_loss: 0.3213\n",
      "Epoch 135/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4606 - val_loss: 0.3216\n",
      "Epoch 136/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4586 - val_loss: 0.3239\n",
      "Epoch 137/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4566 - val_loss: 0.3202\n",
      "Epoch 138/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4653 - val_loss: 0.3241\n",
      "Epoch 139/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4504 - val_loss: 0.3233\n",
      "Epoch 140/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4596 - val_loss: 0.3166\n",
      "Epoch 141/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4701 - val_loss: 0.3180\n",
      "Epoch 142/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4472 - val_loss: 0.3162\n",
      "Epoch 143/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4631 - val_loss: 0.3194\n",
      "Epoch 144/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4411 - val_loss: 0.3194\n",
      "Epoch 145/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4525 - val_loss: 0.3138\n",
      "Epoch 146/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4617 - val_loss: 0.3173\n",
      "Epoch 147/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4500 - val_loss: 0.3091\n",
      "Epoch 148/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4516 - val_loss: 0.3108\n",
      "Epoch 149/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4506 - val_loss: 0.3066\n",
      "Epoch 150/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4422 - val_loss: 0.3067\n",
      "Epoch 151/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4359 - val_loss: 0.3063\n",
      "Epoch 152/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4482 - val_loss: 0.3200\n",
      "Epoch 153/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4703 - val_loss: 0.3135\n",
      "Epoch 154/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4387 - val_loss: 0.3071\n",
      "Epoch 155/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4665 - val_loss: 0.3110\n",
      "Epoch 156/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4394 - val_loss: 0.3053\n",
      "Epoch 157/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4538 - val_loss: 0.3021\n",
      "Epoch 158/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4404 - val_loss: 0.3053\n",
      "Epoch 159/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4412 - val_loss: 0.3081\n",
      "Epoch 160/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4580 - val_loss: 0.3026\n",
      "Epoch 161/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4353 - val_loss: 0.3074\n",
      "Epoch 162/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4450 - val_loss: 0.3010\n",
      "Epoch 163/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4438 - val_loss: 0.2970\n",
      "Epoch 164/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4470 - val_loss: 0.2971\n",
      "Epoch 165/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4265 - val_loss: 0.2951\n",
      "Epoch 166/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4410 - val_loss: 0.2942\n",
      "Epoch 167/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4265 - val_loss: 0.2968\n",
      "Epoch 168/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4272 - val_loss: 0.3012\n",
      "Epoch 169/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4269 - val_loss: 0.2916\n",
      "Epoch 170/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4498 - val_loss: 0.2991\n",
      "Epoch 171/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4403 - val_loss: 0.3009\n",
      "Epoch 172/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4345 - val_loss: 0.3021\n",
      "Epoch 173/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4393 - val_loss: 0.3027\n",
      "Epoch 174/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4384 - val_loss: 0.2973\n",
      "Epoch 175/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4141 - val_loss: 0.2924\n",
      "Epoch 176/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4376 - val_loss: 0.2930\n",
      "Epoch 177/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4520 - val_loss: 0.2948\n",
      "Epoch 178/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4269 - val_loss: 0.2918\n",
      "Epoch 179/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4406 - val_loss: 0.2925\n",
      "Epoch 180/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4292 - val_loss: 0.2904\n",
      "Epoch 181/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4431 - val_loss: 0.2979\n",
      "Epoch 182/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4182 - val_loss: 0.2968\n",
      "Epoch 183/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4457 - val_loss: 0.2924\n",
      "Epoch 184/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4411 - val_loss: 0.2963\n",
      "Epoch 185/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4475 - val_loss: 0.2971\n",
      "Epoch 186/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4328 - val_loss: 0.2925\n",
      "Epoch 187/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4362 - val_loss: 0.2990\n",
      "Epoch 188/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4305 - val_loss: 0.2915\n",
      "Epoch 189/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4380 - val_loss: 0.2929\n",
      "Epoch 190/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4026 - val_loss: 0.2882\n",
      "Epoch 191/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4336 - val_loss: 0.2828\n",
      "Epoch 192/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4120 - val_loss: 0.2825\n",
      "Epoch 193/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4179 - val_loss: 0.2799\n",
      "Epoch 194/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4046 - val_loss: 0.2803\n",
      "Epoch 195/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4158 - val_loss: 0.2793\n",
      "Epoch 196/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3928 - val_loss: 0.2835\n",
      "Epoch 197/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4195 - val_loss: 0.2891\n",
      "Epoch 198/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4262 - val_loss: 0.2823\n",
      "Epoch 199/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4148 - val_loss: 0.2844\n",
      "Epoch 200/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4317 - val_loss: 0.2840\n",
      "Epoch 201/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4091 - val_loss: 0.2779\n",
      "Epoch 202/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4162 - val_loss: 0.2760\n",
      "Epoch 203/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4246 - val_loss: 0.2825\n",
      "Epoch 204/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4209 - val_loss: 0.2811\n",
      "Epoch 205/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4291 - val_loss: 0.2863\n",
      "Epoch 206/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4182 - val_loss: 0.2796\n",
      "Epoch 207/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4114 - val_loss: 0.2762\n",
      "Epoch 208/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4196 - val_loss: 0.2813\n",
      "Epoch 209/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4155 - val_loss: 0.2734\n",
      "Epoch 210/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4062 - val_loss: 0.2745\n",
      "Epoch 211/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4292 - val_loss: 0.2766\n",
      "Epoch 212/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4052 - val_loss: 0.2770\n",
      "Epoch 213/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4199 - val_loss: 0.2755\n",
      "Epoch 214/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4047 - val_loss: 0.2804\n",
      "Epoch 215/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4110 - val_loss: 0.2784\n",
      "Epoch 216/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4127 - val_loss: 0.2736\n",
      "Epoch 217/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4312 - val_loss: 0.2762\n",
      "Epoch 218/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4063 - val_loss: 0.2751\n",
      "Epoch 219/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4033 - val_loss: 0.2760\n",
      "Epoch 220/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4121 - val_loss: 0.2750\n",
      "Epoch 221/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3962 - val_loss: 0.2683\n",
      "Epoch 222/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4153 - val_loss: 0.2657\n",
      "Epoch 223/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4249 - val_loss: 0.2689\n",
      "Epoch 224/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3816 - val_loss: 0.2641\n",
      "Epoch 225/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3940 - val_loss: 0.2686\n",
      "Epoch 226/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4120 - val_loss: 0.2692\n",
      "Epoch 227/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4119 - val_loss: 0.2661\n",
      "Epoch 228/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4044 - val_loss: 0.2730\n",
      "Epoch 229/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3981 - val_loss: 0.2702\n",
      "Epoch 230/600\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4190 - val_loss: 0.2675\n",
      "Epoch 231/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4084 - val_loss: 0.2675\n",
      "Epoch 232/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4048 - val_loss: 0.2656\n",
      "Epoch 233/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3936 - val_loss: 0.2610\n",
      "Epoch 234/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4007 - val_loss: 0.2579\n",
      "Epoch 235/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3880 - val_loss: 0.2596\n",
      "Epoch 236/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4141 - val_loss: 0.2643\n",
      "Epoch 237/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.3981 - val_loss: 0.2601\n",
      "Epoch 238/600\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.4001 - val_loss: 0.2563\n",
      "Epoch 239/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3800 - val_loss: 0.2566\n",
      "Epoch 240/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4046 - val_loss: 0.2581\n",
      "Epoch 241/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3960 - val_loss: 0.2567\n",
      "Epoch 242/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3964 - val_loss: 0.2572\n",
      "Epoch 243/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4076 - val_loss: 0.2603\n",
      "Epoch 244/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.3919 - val_loss: 0.2614\n",
      "Epoch 245/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 12ms/step - loss: 0.4097 - val_loss: 0.2581\n",
      "Epoch 246/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3987 - val_loss: 0.2541\n",
      "Epoch 247/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.4009 - val_loss: 0.2533\n",
      "Epoch 248/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4030 - val_loss: 0.2522\n",
      "Epoch 249/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.3840 - val_loss: 0.2543\n",
      "Epoch 250/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4039 - val_loss: 0.2520\n",
      "Epoch 251/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3766 - val_loss: 0.2544\n",
      "Epoch 252/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3859 - val_loss: 0.2537\n",
      "Epoch 253/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3728 - val_loss: 0.2453\n",
      "Epoch 254/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3833 - val_loss: 0.2522\n",
      "Epoch 255/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4104 - val_loss: 0.2576\n",
      "Epoch 256/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3981 - val_loss: 0.2510\n",
      "Epoch 257/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3983 - val_loss: 0.2603\n",
      "Epoch 258/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3619 - val_loss: 0.2471\n",
      "Epoch 259/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3747 - val_loss: 0.2427\n",
      "Epoch 260/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3723 - val_loss: 0.2399\n",
      "Epoch 261/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3955 - val_loss: 0.2552\n",
      "Epoch 262/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3778 - val_loss: 0.2443\n",
      "Epoch 263/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3854 - val_loss: 0.2469\n",
      "Epoch 264/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4045 - val_loss: 0.2525\n",
      "Epoch 265/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3844 - val_loss: 0.2435\n",
      "Epoch 266/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3896 - val_loss: 0.2490\n",
      "Epoch 267/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3786 - val_loss: 0.2478\n",
      "Epoch 268/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3701 - val_loss: 0.2425\n",
      "Epoch 269/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3804 - val_loss: 0.2399\n",
      "Epoch 270/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3752 - val_loss: 0.2319\n",
      "Epoch 271/600\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.3585 - val_loss: 0.2317\n",
      "Epoch 272/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3677 - val_loss: 0.2369\n",
      "Epoch 273/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3776 - val_loss: 0.2369\n",
      "Epoch 274/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3557 - val_loss: 0.2343\n",
      "Epoch 275/600\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.3663 - val_loss: 0.2308\n",
      "Epoch 276/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3656 - val_loss: 0.2240\n",
      "Epoch 277/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4117 - val_loss: 0.2541\n",
      "Epoch 278/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3954 - val_loss: 0.2423\n",
      "Epoch 279/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3762 - val_loss: 0.2428\n",
      "Epoch 280/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3636 - val_loss: 0.2342\n",
      "Epoch 281/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3721 - val_loss: 0.2333\n",
      "Epoch 282/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3630 - val_loss: 0.2177\n",
      "Epoch 283/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3626 - val_loss: 0.2145\n",
      "Epoch 284/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3695 - val_loss: 0.2126\n",
      "Epoch 285/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3482 - val_loss: 0.2158\n",
      "Epoch 286/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3363 - val_loss: 0.2137\n",
      "Epoch 287/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3347 - val_loss: 0.2080\n",
      "Epoch 288/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3234 - val_loss: 0.2037\n",
      "Epoch 289/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3372 - val_loss: 0.2118\n",
      "Epoch 290/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3461 - val_loss: 0.2107\n",
      "Epoch 291/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3256 - val_loss: 0.1978\n",
      "Epoch 292/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3599 - val_loss: 0.1992\n",
      "Epoch 293/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3454 - val_loss: 0.2070\n",
      "Epoch 294/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3477 - val_loss: 0.2065\n",
      "Epoch 295/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3288 - val_loss: 0.1989\n",
      "Epoch 296/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3447 - val_loss: 0.2005\n",
      "Epoch 297/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3344 - val_loss: 0.2060\n",
      "Epoch 298/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3437 - val_loss: 0.1997\n",
      "Epoch 299/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3470 - val_loss: 0.2061\n",
      "Epoch 300/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3362 - val_loss: 0.2070\n",
      "Epoch 301/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3219 - val_loss: 0.1979\n",
      "Epoch 302/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.3400 - val_loss: 0.1970\n",
      "Epoch 303/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3123 - val_loss: 0.1997\n",
      "Epoch 304/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3336 - val_loss: 0.1962\n",
      "Epoch 305/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3287 - val_loss: 0.2019\n",
      "Epoch 306/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3224 - val_loss: 0.1913\n",
      "Epoch 307/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3452 - val_loss: 0.2016\n",
      "Epoch 308/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3253 - val_loss: 0.1944\n",
      "Epoch 309/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3279 - val_loss: 0.1929\n",
      "Epoch 310/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3423 - val_loss: 0.1957\n",
      "Epoch 311/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3442 - val_loss: 0.2008\n",
      "Epoch 312/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3485 - val_loss: 0.2100\n",
      "Epoch 313/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3260 - val_loss: 0.1916\n",
      "Epoch 314/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3455 - val_loss: 0.1871\n",
      "Epoch 315/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3301 - val_loss: 0.1807\n",
      "Epoch 316/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3280 - val_loss: 0.1897\n",
      "Epoch 317/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3078 - val_loss: 0.1804\n",
      "Epoch 318/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2996 - val_loss: 0.1840\n",
      "Epoch 319/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2993 - val_loss: 0.1848\n",
      "Epoch 320/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3480 - val_loss: 0.1948\n",
      "Epoch 321/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3459 - val_loss: 0.1920\n",
      "Epoch 322/600\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.3041 - val_loss: 0.1818\n",
      "Epoch 323/600\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3148 - val_loss: 0.1751\n",
      "Epoch 324/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2974 - val_loss: 0.1760\n",
      "Epoch 325/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3264 - val_loss: 0.1769\n",
      "Epoch 326/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3168 - val_loss: 0.1676\n",
      "Epoch 327/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2888 - val_loss: 0.1802\n",
      "Epoch 328/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3700 - val_loss: 0.2172\n",
      "Epoch 329/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3380 - val_loss: 0.2031\n",
      "Epoch 330/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3066 - val_loss: 0.1971\n",
      "Epoch 331/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4075 - val_loss: 0.2145\n",
      "Epoch 332/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3253 - val_loss: 0.2011\n",
      "Epoch 333/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3375 - val_loss: 0.2035\n",
      "Epoch 334/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3035 - val_loss: 0.1907\n",
      "Epoch 335/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3156 - val_loss: 0.1879\n",
      "Epoch 336/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2892 - val_loss: 0.1772\n",
      "Epoch 337/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3155 - val_loss: 0.1797\n",
      "Epoch 338/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3240 - val_loss: 0.1800\n",
      "Epoch 339/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3049 - val_loss: 0.1703\n",
      "Epoch 340/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3049 - val_loss: 0.1735\n",
      "Epoch 341/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2869 - val_loss: 0.1825\n",
      "Epoch 342/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2892 - val_loss: 0.1604\n",
      "Epoch 343/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3155 - val_loss: 0.1666\n",
      "Epoch 344/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2984 - val_loss: 0.1684\n",
      "Epoch 345/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2900 - val_loss: 0.1689\n",
      "Epoch 346/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3062 - val_loss: 0.1826\n",
      "Epoch 347/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3100 - val_loss: 0.1763\n",
      "Epoch 348/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2905 - val_loss: 0.1835\n",
      "Epoch 349/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3208 - val_loss: 0.1885\n",
      "Epoch 350/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3144 - val_loss: 0.1634\n",
      "Epoch 351/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2770 - val_loss: 0.1792\n",
      "Epoch 352/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3183 - val_loss: 0.1778\n",
      "Epoch 353/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2978 - val_loss: 0.1770\n",
      "Epoch 354/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2984 - val_loss: 0.1693\n",
      "Epoch 355/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3066 - val_loss: 0.1657\n",
      "Epoch 356/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2968 - val_loss: 0.1820\n",
      "Epoch 357/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2925 - val_loss: 0.1565\n",
      "Epoch 358/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.3011 - val_loss: 0.1617\n",
      "Epoch 359/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2937 - val_loss: 0.1655\n",
      "Epoch 360/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.3295 - val_loss: 0.1677\n",
      "Epoch 361/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3138 - val_loss: 0.1667\n",
      "Epoch 362/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3027 - val_loss: 0.1658\n",
      "Epoch 363/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.3234 - val_loss: 0.1638\n",
      "Epoch 364/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3186 - val_loss: 0.1697\n",
      "Epoch 365/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2987 - val_loss: 0.1699\n",
      "Epoch 366/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.3022 - val_loss: 0.1501\n",
      "Epoch 367/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3090 - val_loss: 0.1658\n",
      "Epoch 368/600\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.2904 - val_loss: 0.1543\n",
      "Epoch 369/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.2926 - val_loss: 0.1482\n",
      "Epoch 370/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3169 - val_loss: 0.1987\n",
      "Epoch 371/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2973 - val_loss: 0.1685\n",
      "Epoch 372/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2875 - val_loss: 0.1659\n",
      "Epoch 373/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2760 - val_loss: 0.1545\n",
      "Epoch 374/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3070 - val_loss: 0.1736\n",
      "Epoch 375/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2800 - val_loss: 0.1708\n",
      "Epoch 376/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3063 - val_loss: 0.1533\n",
      "Epoch 377/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2952 - val_loss: 0.1517\n",
      "Epoch 378/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2801 - val_loss: 0.1475\n",
      "Epoch 379/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2803 - val_loss: 0.1498\n",
      "Epoch 380/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2909 - val_loss: 0.1608\n",
      "Epoch 381/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2877 - val_loss: 0.1428\n",
      "Epoch 382/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2686 - val_loss: 0.1564\n",
      "Epoch 383/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3206 - val_loss: 0.1828\n",
      "Epoch 384/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3011 - val_loss: 0.1584\n",
      "Epoch 385/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2807 - val_loss: 0.1630\n",
      "Epoch 386/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2818 - val_loss: 0.1569\n",
      "Epoch 387/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2943 - val_loss: 0.1701\n",
      "Epoch 388/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2814 - val_loss: 0.1621\n",
      "Epoch 389/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2865 - val_loss: 0.1565\n",
      "Epoch 390/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2850 - val_loss: 0.1623\n",
      "Epoch 391/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2669 - val_loss: 0.1583\n",
      "Epoch 392/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2857 - val_loss: 0.1463\n",
      "Epoch 393/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2730 - val_loss: 0.1434\n",
      "Epoch 394/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2716 - val_loss: 0.1405\n",
      "Epoch 395/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2714 - val_loss: 0.1496\n",
      "Epoch 396/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3029 - val_loss: 0.1602\n",
      "Epoch 397/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2616 - val_loss: 0.1546\n",
      "Epoch 398/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2986 - val_loss: 0.1482\n",
      "Epoch 399/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3046 - val_loss: 0.1451\n",
      "Epoch 400/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2801 - val_loss: 0.1420\n",
      "Epoch 401/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2994 - val_loss: 0.1550\n",
      "Epoch 402/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2833 - val_loss: 0.1743\n",
      "Epoch 403/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2881 - val_loss: 0.1506\n",
      "Epoch 404/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3268 - val_loss: 0.1621\n",
      "Epoch 405/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3291 - val_loss: 0.1790\n",
      "Epoch 406/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3080 - val_loss: 0.1827\n",
      "Epoch 407/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3033 - val_loss: 0.1669\n",
      "Epoch 408/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2748 - val_loss: 0.1602\n",
      "Epoch 409/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2999 - val_loss: 0.1550\n",
      "Epoch 410/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2573 - val_loss: 0.1440\n",
      "Epoch 411/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2869 - val_loss: 0.1438\n",
      "Epoch 412/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2925 - val_loss: 0.1613\n",
      "Epoch 413/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2736 - val_loss: 0.1507\n",
      "Epoch 414/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2825 - val_loss: 0.1639\n",
      "Epoch 415/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2722 - val_loss: 0.1542\n",
      "Epoch 416/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2859 - val_loss: 0.1482\n",
      "Epoch 417/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2989 - val_loss: 0.1538\n",
      "Epoch 418/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2817 - val_loss: 0.1620\n",
      "Epoch 419/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2864 - val_loss: 0.1529\n",
      "Epoch 420/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3151 - val_loss: 0.1596\n",
      "Epoch 421/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2905 - val_loss: 0.1545\n",
      "Epoch 422/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2948 - val_loss: 0.1612\n",
      "Epoch 423/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2766 - val_loss: 0.1500\n",
      "Epoch 424/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2793 - val_loss: 0.1631\n",
      "Epoch 425/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2458 - val_loss: 0.1420\n",
      "Epoch 426/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2539 - val_loss: 0.1333\n",
      "Epoch 427/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2804 - val_loss: 0.1440\n",
      "Epoch 428/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2453 - val_loss: 0.1380\n",
      "Epoch 429/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2846 - val_loss: 0.1514\n",
      "Epoch 430/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2657 - val_loss: 0.1501\n",
      "Epoch 431/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2962 - val_loss: 0.1443\n",
      "Epoch 432/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2858 - val_loss: 0.1632\n",
      "Epoch 433/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2849 - val_loss: 0.1613\n",
      "Epoch 434/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3206 - val_loss: 0.1687\n",
      "Epoch 435/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2639 - val_loss: 0.1614\n",
      "Epoch 436/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2964 - val_loss: 0.1615\n",
      "Epoch 437/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2534 - val_loss: 0.1392\n",
      "Epoch 438/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2790 - val_loss: 0.1439\n",
      "Epoch 439/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2677 - val_loss: 0.1480\n",
      "Epoch 440/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2854 - val_loss: 0.1437\n",
      "Epoch 441/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2775 - val_loss: 0.1473\n",
      "Epoch 442/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2747 - val_loss: 0.1385\n",
      "Epoch 443/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2418 - val_loss: 0.1321\n",
      "Epoch 444/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2560 - val_loss: 0.1338\n",
      "Epoch 445/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2551 - val_loss: 0.1348\n",
      "Epoch 446/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2728 - val_loss: 0.1593\n",
      "Epoch 447/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2842 - val_loss: 0.1422\n",
      "Epoch 448/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2716 - val_loss: 0.1564\n",
      "Epoch 449/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2914 - val_loss: 0.1416\n",
      "Epoch 450/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2583 - val_loss: 0.1374\n",
      "Epoch 451/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2805 - val_loss: 0.1405\n",
      "Epoch 452/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2954 - val_loss: 0.1577\n",
      "Epoch 453/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2921 - val_loss: 0.1531\n",
      "Epoch 454/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2897 - val_loss: 0.1505\n",
      "Epoch 455/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2915 - val_loss: 0.1700\n",
      "Epoch 456/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3291 - val_loss: 0.1763\n",
      "Epoch 457/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2994 - val_loss: 0.1761\n",
      "Epoch 458/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2906 - val_loss: 0.1633\n",
      "Epoch 459/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3110 - val_loss: 0.1790\n",
      "Epoch 460/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3088 - val_loss: 0.1840\n",
      "Epoch 461/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3145 - val_loss: 0.1691\n",
      "Epoch 462/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2925 - val_loss: 0.1549\n",
      "Epoch 463/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2826 - val_loss: 0.1619\n",
      "Epoch 464/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2625 - val_loss: 0.1387\n",
      "Epoch 465/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2609 - val_loss: 0.1416\n",
      "Epoch 466/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2578 - val_loss: 0.1561\n",
      "Epoch 467/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2995 - val_loss: 0.1487\n",
      "Epoch 468/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2860 - val_loss: 0.1485\n",
      "Epoch 469/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2761 - val_loss: 0.1427\n",
      "Epoch 470/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2750 - val_loss: 0.1404\n",
      "Epoch 471/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2560 - val_loss: 0.1452\n",
      "Epoch 472/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2584 - val_loss: 0.1375\n",
      "Epoch 473/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2614 - val_loss: 0.1438\n",
      "Epoch 474/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2996 - val_loss: 0.1444\n",
      "Epoch 475/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2543 - val_loss: 0.1328\n",
      "Epoch 476/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3052 - val_loss: 0.1344\n",
      "Epoch 477/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2718 - val_loss: 0.1500\n",
      "Epoch 478/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2878 - val_loss: 0.1574\n",
      "Epoch 479/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2931 - val_loss: 0.1628\n",
      "Epoch 480/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2785 - val_loss: 0.1474\n",
      "Epoch 481/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2839 - val_loss: 0.1657\n",
      "Epoch 482/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2976 - val_loss: 0.1555\n",
      "Epoch 483/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3081 - val_loss: 0.1744\n",
      "Epoch 484/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2777 - val_loss: 0.1498\n",
      "Epoch 485/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2718 - val_loss: 0.1459\n",
      "Epoch 486/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2816 - val_loss: 0.1538\n",
      "Epoch 487/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2850 - val_loss: 0.1616\n",
      "Epoch 488/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2902 - val_loss: 0.1829\n",
      "Epoch 489/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3039 - val_loss: 0.1705\n",
      "Epoch 490/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2896 - val_loss: 0.1439\n",
      "Epoch 491/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2424 - val_loss: 0.1514\n",
      "Epoch 492/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3202 - val_loss: 0.1596\n",
      "Epoch 493/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2856 - val_loss: 0.1511\n",
      "Epoch 494/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2755 - val_loss: 0.1350\n",
      "Epoch 495/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2562 - val_loss: 0.1583\n",
      "Epoch 496/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2668 - val_loss: 0.1361\n",
      "Epoch 497/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2703 - val_loss: 0.1403\n",
      "Epoch 498/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2558 - val_loss: 0.1486\n",
      "Epoch 499/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2533 - val_loss: 0.1375\n",
      "Epoch 500/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2535 - val_loss: 0.1335\n",
      "Epoch 501/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2708 - val_loss: 0.1355\n",
      "Epoch 502/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2591 - val_loss: 0.1353\n",
      "Epoch 503/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2356 - val_loss: 0.1466\n",
      "Epoch 504/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2510 - val_loss: 0.1281\n",
      "Epoch 505/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2662 - val_loss: 0.1333\n",
      "Epoch 506/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2606 - val_loss: 0.1389\n",
      "Epoch 507/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2911 - val_loss: 0.1575\n",
      "Epoch 508/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3022 - val_loss: 0.1796\n",
      "Epoch 509/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2849 - val_loss: 0.1605\n",
      "Epoch 510/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2937 - val_loss: 0.1541\n",
      "Epoch 511/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2711 - val_loss: 0.1588\n",
      "Epoch 512/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2766 - val_loss: 0.1461\n",
      "Epoch 513/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2884 - val_loss: 0.1464\n",
      "Epoch 514/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2894 - val_loss: 0.1543\n",
      "Epoch 515/600\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.2816 - val_loss: 0.1538\n",
      "Epoch 516/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2709 - val_loss: 0.1424\n",
      "Epoch 517/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.3051 - val_loss: 0.1616\n",
      "Epoch 518/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2939 - val_loss: 0.1562\n",
      "Epoch 519/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2823 - val_loss: 0.1543\n",
      "Epoch 520/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2845 - val_loss: 0.1454\n",
      "Epoch 521/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2766 - val_loss: 0.1334\n",
      "Epoch 522/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2341 - val_loss: 0.1533\n",
      "Epoch 523/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2719 - val_loss: 0.1355\n",
      "Epoch 524/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2951 - val_loss: 0.1811\n",
      "Epoch 525/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2750 - val_loss: 0.1488\n",
      "Epoch 526/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2549 - val_loss: 0.1422\n",
      "Epoch 527/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2598 - val_loss: 0.1423\n",
      "Epoch 528/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2725 - val_loss: 0.1437\n",
      "Epoch 529/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2723 - val_loss: 0.1391\n",
      "Epoch 530/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2862 - val_loss: 0.1429\n",
      "Epoch 531/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2653 - val_loss: 0.1429\n",
      "Epoch 532/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.2475 - val_loss: 0.1333\n",
      "Epoch 533/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2576 - val_loss: 0.1529\n",
      "Epoch 534/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2952 - val_loss: 0.1416\n",
      "Epoch 535/600\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.2807 - val_loss: 0.1425\n",
      "Epoch 536/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2604 - val_loss: 0.1472\n",
      "Epoch 537/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2778 - val_loss: 0.1401\n",
      "Epoch 538/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2659 - val_loss: 0.1378\n",
      "Epoch 539/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2704 - val_loss: 0.1577\n",
      "Epoch 540/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.2800 - val_loss: 0.1583\n",
      "Epoch 541/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.3126 - val_loss: 0.1577\n",
      "Epoch 542/600\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.2938 - val_loss: 0.1741\n",
      "Epoch 543/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3343 - val_loss: 0.1929\n",
      "Epoch 544/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3335 - val_loss: 0.2050\n",
      "Epoch 545/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3092 - val_loss: 0.2004\n",
      "Epoch 546/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.3303 - val_loss: 0.2023\n",
      "Epoch 547/600\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.3152 - val_loss: 0.1922\n",
      "Epoch 548/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2917 - val_loss: 0.1844\n",
      "Epoch 549/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3100 - val_loss: 0.1815\n",
      "Epoch 550/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3298 - val_loss: 0.1978\n",
      "Epoch 551/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3135 - val_loss: 0.1884\n",
      "Epoch 552/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2865 - val_loss: 0.1800\n",
      "Epoch 553/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3286 - val_loss: 0.1892\n",
      "Epoch 554/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3193 - val_loss: 0.1882\n",
      "Epoch 555/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2964 - val_loss: 0.1809\n",
      "Epoch 556/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2934 - val_loss: 0.1747\n",
      "Epoch 557/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2745 - val_loss: 0.1740\n",
      "Epoch 558/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2922 - val_loss: 0.1588\n",
      "Epoch 559/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2811 - val_loss: 0.1678\n",
      "Epoch 560/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2819 - val_loss: 0.1596\n",
      "Epoch 561/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2949 - val_loss: 0.1547\n",
      "Epoch 562/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3008 - val_loss: 0.1729\n",
      "Epoch 563/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2803 - val_loss: 0.1669\n",
      "Epoch 564/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2772 - val_loss: 0.1478\n",
      "Epoch 565/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2595 - val_loss: 0.1441\n",
      "Epoch 566/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2900 - val_loss: 0.1487\n",
      "Epoch 567/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3149 - val_loss: 0.1544\n",
      "Epoch 568/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2715 - val_loss: 0.1571\n",
      "Epoch 569/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2557 - val_loss: 0.1544\n",
      "Epoch 570/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2520 - val_loss: 0.1393\n",
      "Epoch 571/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2480 - val_loss: 0.1612\n",
      "Epoch 572/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2854 - val_loss: 0.1546\n",
      "Epoch 573/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2698 - val_loss: 0.1463\n",
      "Epoch 574/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2534 - val_loss: 0.1354\n",
      "Epoch 575/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2820 - val_loss: 0.1374\n",
      "Epoch 576/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2779 - val_loss: 0.1404\n",
      "Epoch 577/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2685 - val_loss: 0.1440\n",
      "Epoch 578/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2760 - val_loss: 0.1627\n",
      "Epoch 579/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2770 - val_loss: 0.1598\n",
      "Epoch 580/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2939 - val_loss: 0.1461\n",
      "Epoch 581/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2820 - val_loss: 0.1446\n",
      "Epoch 582/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2583 - val_loss: 0.1364\n",
      "Epoch 583/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2578 - val_loss: 0.1311\n",
      "Epoch 584/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2639 - val_loss: 0.1440\n",
      "Epoch 585/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2550 - val_loss: 0.1503\n",
      "Epoch 586/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2382 - val_loss: 0.1397\n",
      "Epoch 587/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2664 - val_loss: 0.1673\n",
      "Epoch 588/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2919 - val_loss: 0.1528\n",
      "Epoch 589/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2860 - val_loss: 0.1483\n",
      "Epoch 590/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2894 - val_loss: 0.1463\n",
      "Epoch 591/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2862 - val_loss: 0.1509\n",
      "Epoch 592/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2825 - val_loss: 0.1563\n",
      "Epoch 593/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2991 - val_loss: 0.1484\n",
      "Epoch 594/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2669 - val_loss: 0.1369\n",
      "Epoch 595/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2824 - val_loss: 0.1862\n",
      "Epoch 596/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2786 - val_loss: 0.1525\n",
      "Epoch 597/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2998 - val_loss: 0.1738\n",
      "Epoch 598/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3145 - val_loss: 0.1631\n",
      "Epoch 599/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2985 - val_loss: 0.1738\n",
      "Epoch 600/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2655 - val_loss: 0.1544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93e37060a0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scld_X_train, y=y_train, \n",
    "          epochs = 600, \n",
    "          verbose=1, \n",
    "          batch_size = 31,\n",
    "          validation_data=(scld_X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.7301 - val_loss: 0.6894\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7136 - val_loss: 0.6853\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6813 - val_loss: 0.6802\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6999 - val_loss: 0.6762\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6760 - val_loss: 0.6712\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6859 - val_loss: 0.6686\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6834 - val_loss: 0.6655\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6682 - val_loss: 0.6641\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6629 - val_loss: 0.6579\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6586 - val_loss: 0.6519\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6477 - val_loss: 0.6460\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6563 - val_loss: 0.6405\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6358 - val_loss: 0.6328\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6393 - val_loss: 0.6299\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6213 - val_loss: 0.6232\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6191\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6158 - val_loss: 0.6116\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6401 - val_loss: 0.6113\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6184 - val_loss: 0.6056\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.5975\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6221 - val_loss: 0.5928\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5943 - val_loss: 0.5878\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.5828\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5894 - val_loss: 0.5811\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5879 - val_loss: 0.5788\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5661 - val_loss: 0.5735\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5967 - val_loss: 0.5716\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5846 - val_loss: 0.5648\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5912 - val_loss: 0.5609\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5724 - val_loss: 0.5572\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.5546\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5744 - val_loss: 0.5496\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5622 - val_loss: 0.5446\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5603 - val_loss: 0.5414\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5756 - val_loss: 0.5394\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5627 - val_loss: 0.5389\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5593 - val_loss: 0.5357\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5565 - val_loss: 0.5314\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5635 - val_loss: 0.5295\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5619 - val_loss: 0.5252\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5595 - val_loss: 0.5232\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5508 - val_loss: 0.5200\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5501 - val_loss: 0.5122\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5594 - val_loss: 0.5109\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5351 - val_loss: 0.5106\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5348 - val_loss: 0.5078\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5314 - val_loss: 0.5050\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5501 - val_loss: 0.5002\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5326 - val_loss: 0.4976\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 987us/step - loss: 0.5326 - val_loss: 0.4921\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5350 - val_loss: 0.4921\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5393 - val_loss: 0.4953\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.4857\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5268 - val_loss: 0.4842\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5368 - val_loss: 0.4858\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 0.4764\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 0.4749\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.4745\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.4734\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.4713\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.4656\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5393 - val_loss: 0.4656\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5161 - val_loss: 0.4637\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5117 - val_loss: 0.4643\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4958 - val_loss: 0.4589\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4896 - val_loss: 0.4545\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4937 - val_loss: 0.4510\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4982 - val_loss: 0.4467\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 931us/step - loss: 0.4903 - val_loss: 0.4507\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 932us/step - loss: 0.4740 - val_loss: 0.4445\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5129 - val_loss: 0.4440\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4961 - val_loss: 0.4443\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4859 - val_loss: 0.4383\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4852 - val_loss: 0.4348\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4864 - val_loss: 0.4351\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4966 - val_loss: 0.4384\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4796 - val_loss: 0.4345\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4884 - val_loss: 0.4287\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4930 - val_loss: 0.4307\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.4338\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4866 - val_loss: 0.4300\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.4203\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4726 - val_loss: 0.4208\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4177\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.4137\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4799 - val_loss: 0.4194\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4894 - val_loss: 0.4154\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4662 - val_loss: 0.4220\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4551 - val_loss: 0.4113\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4533 - val_loss: 0.4168\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4017\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4626 - val_loss: 0.4069\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4518 - val_loss: 0.4074\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.3966\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.4100\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4502 - val_loss: 0.4062\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4055\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4549 - val_loss: 0.3974\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4623 - val_loss: 0.4030\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4004\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.3987\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4004\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4009\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.3925\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.3825\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4661 - val_loss: 0.3904\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.3949\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.3861\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.3813\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.3836\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.3816\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4437 - val_loss: 0.3788\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.3762\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4190 - val_loss: 0.3757\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4240 - val_loss: 0.3763\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4292 - val_loss: 0.3779\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.3792\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.3784\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4165 - val_loss: 0.3719\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.3677\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.3718\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.3735\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.3659\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4130 - val_loss: 0.3653\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.3646\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.3662\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.3607\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4454 - val_loss: 0.3672\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.3637\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4396 - val_loss: 0.3627\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.3628\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4153 - val_loss: 0.3567\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.3512\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.3571\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4205 - val_loss: 0.3548\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.3498\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.3509\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.3499\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.3537\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.3500\n",
      "Epoch 141/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3481\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.3453\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.3444\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.3442\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.3452\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.3399\n",
      "Epoch 147/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3373\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4345 - val_loss: 0.3412\n",
      "Epoch 149/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.3401\n",
      "Epoch 150/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.3351\n",
      "Epoch 151/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3362\n",
      "Epoch 152/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.3380\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.3307\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3363\n",
      "Epoch 155/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3343\n",
      "Epoch 156/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3329\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3305\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3280\n",
      "Epoch 159/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3215\n",
      "Epoch 160/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3234\n",
      "Epoch 161/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3337\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3207\n",
      "Epoch 163/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.3268\n",
      "Epoch 164/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.3394\n",
      "Epoch 165/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3194\n",
      "Epoch 166/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3214\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3229\n",
      "Epoch 168/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3186\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.3323\n",
      "Epoch 170/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3259\n",
      "Epoch 171/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.3265\n",
      "Epoch 172/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3178\n",
      "Epoch 173/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3131\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3228\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3077\n",
      "Epoch 176/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3728 - val_loss: 0.3126\n",
      "Epoch 177/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3137\n",
      "Epoch 178/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3129\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.3141\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3168\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.3171\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3166\n",
      "Epoch 183/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3042\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3021\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.3054\n",
      "Epoch 186/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.3091\n",
      "Epoch 187/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.2977\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3037\n",
      "Epoch 189/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.2995\n",
      "Epoch 190/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.2963\n",
      "Epoch 191/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.2965\n",
      "Epoch 192/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.2945\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.2953\n",
      "Epoch 194/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3544 - val_loss: 0.2848\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.2865\n",
      "Epoch 196/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.2796\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.2896\n",
      "Epoch 198/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.2885\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.2915\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.2967\n",
      "Epoch 201/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.2882\n",
      "Epoch 202/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.2932\n",
      "Epoch 203/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.2841\n",
      "Epoch 204/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.2887\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.2772\n",
      "Epoch 206/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.2802\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.2823\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.2791\n",
      "Epoch 209/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.2848\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.2764\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.2874\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 0.2724\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.2723\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.2708\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.2798\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.2744\n",
      "Epoch 217/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3403 - val_loss: 0.2878\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.2745\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.2622\n",
      "Epoch 220/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.2778\n",
      "Epoch 221/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.2671\n",
      "Epoch 222/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.2644\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.2634\n",
      "Epoch 224/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3216 - val_loss: 0.2877\n",
      "Epoch 225/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.2615\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.2741\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.2734\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.2685\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.2598\n",
      "Epoch 230/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3191 - val_loss: 0.2663\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.2588\n",
      "Epoch 232/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.2673\n",
      "Epoch 233/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.2479\n",
      "Epoch 234/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.2354\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.2639\n",
      "Epoch 236/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3159 - val_loss: 0.2522\n",
      "Epoch 237/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.2545\n",
      "Epoch 238/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.2480\n",
      "Epoch 239/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.2484\n",
      "Epoch 240/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.2552\n",
      "Epoch 241/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.2697\n",
      "Epoch 242/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.2563\n",
      "Epoch 243/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.2640\n",
      "Epoch 244/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.2638\n",
      "Epoch 245/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.2549\n",
      "Epoch 246/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.2400\n",
      "Epoch 247/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 0.2413\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.2510\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3110 - val_loss: 0.2581\n",
      "Epoch 250/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.2506\n",
      "Epoch 251/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.2457\n",
      "Epoch 252/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.2289\n",
      "Epoch 253/1000\n",
      "37/37 [==============================] - 0s 956us/step - loss: 0.2951 - val_loss: 0.2316\n",
      "Epoch 254/1000\n",
      "37/37 [==============================] - 0s 818us/step - loss: 0.2956 - val_loss: 0.2446\n",
      "Epoch 255/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.2328\n",
      "Epoch 256/1000\n",
      "37/37 [==============================] - 0s 919us/step - loss: 0.3075 - val_loss: 0.2421\n",
      "Epoch 257/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.2306\n",
      "Epoch 258/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.2244\n",
      "Epoch 259/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.2285\n",
      "Epoch 260/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2960 - val_loss: 0.2575\n",
      "Epoch 261/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.2499\n",
      "Epoch 262/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2983 - val_loss: 0.2362\n",
      "Epoch 263/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.2241\n",
      "Epoch 264/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2759 - val_loss: 0.2191\n",
      "Epoch 265/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2754 - val_loss: 0.2092\n",
      "Epoch 266/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2600 - val_loss: 0.2245\n",
      "Epoch 267/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.2157\n",
      "Epoch 268/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2779 - val_loss: 0.2290\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.2180\n",
      "Epoch 270/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2765 - val_loss: 0.2075\n",
      "Epoch 271/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.2124\n",
      "Epoch 272/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2582 - val_loss: 0.2237\n",
      "Epoch 273/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 0.2169\n",
      "Epoch 274/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 0.2019\n",
      "Epoch 275/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2717 - val_loss: 0.2092\n",
      "Epoch 276/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2683 - val_loss: 0.2229\n",
      "Epoch 277/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.2323\n",
      "Epoch 278/1000\n",
      "37/37 [==============================] - 0s 987us/step - loss: 0.2808 - val_loss: 0.2175\n",
      "Epoch 279/1000\n",
      "37/37 [==============================] - 0s 897us/step - loss: 0.2625 - val_loss: 0.2063\n",
      "Epoch 280/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2707 - val_loss: 0.2250\n",
      "Epoch 281/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2692 - val_loss: 0.2104\n",
      "Epoch 282/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2551 - val_loss: 0.1968\n",
      "Epoch 283/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2665 - val_loss: 0.1953\n",
      "Epoch 284/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2633 - val_loss: 0.1947\n",
      "Epoch 285/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2613 - val_loss: 0.2077\n",
      "Epoch 286/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2618 - val_loss: 0.2021\n",
      "Epoch 287/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2603 - val_loss: 0.2106\n",
      "Epoch 288/1000\n",
      "37/37 [==============================] - 0s 932us/step - loss: 0.2467 - val_loss: 0.2209\n",
      "Epoch 289/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2608 - val_loss: 0.1973\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2557 - val_loss: 0.1949\n",
      "Epoch 291/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2477 - val_loss: 0.2015\n",
      "Epoch 292/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2583 - val_loss: 0.2025\n",
      "Epoch 293/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2958 - val_loss: 0.2232\n",
      "Epoch 294/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2699 - val_loss: 0.2099\n",
      "Epoch 295/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2805 - val_loss: 0.2170\n",
      "Epoch 296/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2648 - val_loss: 0.2181\n",
      "Epoch 297/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.2031\n",
      "Epoch 298/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2641 - val_loss: 0.2158\n",
      "Epoch 299/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2433 - val_loss: 0.1920\n",
      "Epoch 300/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2671 - val_loss: 0.2086\n",
      "Epoch 301/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2464 - val_loss: 0.1917\n",
      "Epoch 302/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2645 - val_loss: 0.2036\n",
      "Epoch 303/1000\n",
      "37/37 [==============================] - 0s 956us/step - loss: 0.2556 - val_loss: 0.2123\n",
      "Epoch 304/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2545 - val_loss: 0.1905\n",
      "Epoch 305/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2593 - val_loss: 0.2045\n",
      "Epoch 306/1000\n",
      "37/37 [==============================] - 0s 856us/step - loss: 0.2343 - val_loss: 0.1918\n",
      "Epoch 307/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2391 - val_loss: 0.1892\n",
      "Epoch 308/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2507 - val_loss: 0.2050\n",
      "Epoch 309/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.1886\n",
      "Epoch 310/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2498 - val_loss: 0.1834\n",
      "Epoch 311/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2348 - val_loss: 0.2188\n",
      "Epoch 312/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2680 - val_loss: 0.1962\n",
      "Epoch 313/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.1922\n",
      "Epoch 314/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2562 - val_loss: 0.1953\n",
      "Epoch 315/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2537 - val_loss: 0.1931\n",
      "Epoch 316/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.2165\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2762 - val_loss: 0.2114\n",
      "Epoch 318/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2511 - val_loss: 0.1998\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2527 - val_loss: 0.1958\n",
      "Epoch 320/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2632 - val_loss: 0.2163\n",
      "Epoch 321/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.1887\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 727us/step - loss: 0.2337 - val_loss: 0.1866\n",
      "Epoch 323/1000\n",
      "37/37 [==============================] - 0s 983us/step - loss: 0.2437 - val_loss: 0.1865\n",
      "Epoch 324/1000\n",
      "37/37 [==============================] - 0s 883us/step - loss: 0.2268 - val_loss: 0.1921\n",
      "Epoch 325/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2312 - val_loss: 0.2021\n",
      "Epoch 326/1000\n",
      "37/37 [==============================] - 0s 785us/step - loss: 0.2744 - val_loss: 0.1984\n",
      "Epoch 327/1000\n",
      "37/37 [==============================] - 0s 875us/step - loss: 0.2474 - val_loss: 0.1692\n",
      "Epoch 328/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2377 - val_loss: 0.1888\n",
      "Epoch 329/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2483 - val_loss: 0.1839\n",
      "Epoch 330/1000\n",
      "37/37 [==============================] - 0s 822us/step - loss: 0.2345 - val_loss: 0.1858\n",
      "Epoch 331/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2229 - val_loss: 0.1697\n",
      "Epoch 332/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2308 - val_loss: 0.1759\n",
      "Epoch 333/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2328 - val_loss: 0.1748\n",
      "Epoch 334/1000\n",
      "37/37 [==============================] - 0s 858us/step - loss: 0.2371 - val_loss: 0.1734\n",
      "Epoch 335/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.2045\n",
      "Epoch 336/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.1960\n",
      "Epoch 337/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2582 - val_loss: 0.2059\n",
      "Epoch 338/1000\n",
      "37/37 [==============================] - 0s 833us/step - loss: 0.2721 - val_loss: 0.1982\n",
      "Epoch 339/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2476 - val_loss: 0.1999\n",
      "Epoch 340/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2415 - val_loss: 0.2186\n",
      "Epoch 341/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2751 - val_loss: 0.2097\n",
      "Epoch 342/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2759 - val_loss: 0.2127\n",
      "Epoch 343/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2735 - val_loss: 0.2120\n",
      "Epoch 344/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2760 - val_loss: 0.2015\n",
      "Epoch 345/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2566 - val_loss: 0.1992\n",
      "Epoch 346/1000\n",
      "37/37 [==============================] - 0s 744us/step - loss: 0.2492 - val_loss: 0.2180\n",
      "Epoch 347/1000\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.2493 - val_loss: 0.2045\n",
      "Epoch 348/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2526 - val_loss: 0.1992\n",
      "Epoch 349/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2462 - val_loss: 0.2024\n",
      "Epoch 350/1000\n",
      "37/37 [==============================] - 0s 912us/step - loss: 0.2412 - val_loss: 0.1922\n",
      "Epoch 351/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2416 - val_loss: 0.1743\n",
      "Epoch 352/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2389 - val_loss: 0.1814\n",
      "Epoch 353/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2361 - val_loss: 0.1898\n",
      "Epoch 354/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2287 - val_loss: 0.1640\n",
      "Epoch 355/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2399 - val_loss: 0.1909\n",
      "Epoch 356/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2325 - val_loss: 0.1710\n",
      "Epoch 357/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2537 - val_loss: 0.1814\n",
      "Epoch 358/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2431 - val_loss: 0.1732\n",
      "Epoch 359/1000\n",
      "37/37 [==============================] - 0s 889us/step - loss: 0.2363 - val_loss: 0.1666\n",
      "Epoch 360/1000\n",
      "37/37 [==============================] - 0s 772us/step - loss: 0.2617 - val_loss: 0.1937\n",
      "Epoch 361/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.1937\n",
      "Epoch 362/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2566 - val_loss: 0.2016\n",
      "Epoch 363/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2576 - val_loss: 0.1878\n",
      "Epoch 364/1000\n",
      "37/37 [==============================] - 0s 954us/step - loss: 0.2388 - val_loss: 0.1728\n",
      "Epoch 365/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2306 - val_loss: 0.1729\n",
      "Epoch 366/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2463 - val_loss: 0.1820\n",
      "Epoch 367/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2298 - val_loss: 0.1792\n",
      "Epoch 368/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2059 - val_loss: 0.1730\n",
      "Epoch 369/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2500 - val_loss: 0.1838\n",
      "Epoch 370/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2452 - val_loss: 0.1913\n",
      "Epoch 371/1000\n",
      "37/37 [==============================] - 0s 956us/step - loss: 0.2219 - val_loss: 0.1727\n",
      "Epoch 372/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2194 - val_loss: 0.1778\n",
      "Epoch 373/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2370 - val_loss: 0.1713\n",
      "Epoch 374/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2342 - val_loss: 0.1635\n",
      "Epoch 375/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2211 - val_loss: 0.1757\n",
      "Epoch 376/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2228 - val_loss: 0.1731\n",
      "Epoch 377/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2083 - val_loss: 0.1608\n",
      "Epoch 378/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2225 - val_loss: 0.1604\n",
      "Epoch 379/1000\n",
      "37/37 [==============================] - 0s 958us/step - loss: 0.2152 - val_loss: 0.1713\n",
      "Epoch 380/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.1822\n",
      "Epoch 381/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2349 - val_loss: 0.1788\n",
      "Epoch 382/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2586 - val_loss: 0.1849\n",
      "Epoch 383/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2454 - val_loss: 0.1946\n",
      "Epoch 384/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2365 - val_loss: 0.1706\n",
      "Epoch 385/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2215 - val_loss: 0.1623\n",
      "Epoch 386/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2253 - val_loss: 0.1917\n",
      "Epoch 387/1000\n",
      "37/37 [==============================] - 0s 903us/step - loss: 0.2315 - val_loss: 0.1600\n",
      "Epoch 388/1000\n",
      "37/37 [==============================] - 0s 924us/step - loss: 0.2390 - val_loss: 0.1616\n",
      "Epoch 389/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2119 - val_loss: 0.1772\n",
      "Epoch 390/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2297 - val_loss: 0.1697\n",
      "Epoch 391/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2448 - val_loss: 0.1728\n",
      "Epoch 392/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2331 - val_loss: 0.1746\n",
      "Epoch 393/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2445 - val_loss: 0.1627\n",
      "Epoch 394/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2151 - val_loss: 0.1655\n",
      "Epoch 395/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2287 - val_loss: 0.1813\n",
      "Epoch 396/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2536 - val_loss: 0.1907\n",
      "Epoch 397/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2260 - val_loss: 0.1756\n",
      "Epoch 398/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2257 - val_loss: 0.1623\n",
      "Epoch 399/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2273 - val_loss: 0.1646\n",
      "Epoch 400/1000\n",
      "37/37 [==============================] - 0s 926us/step - loss: 0.2268 - val_loss: 0.1706\n",
      "Epoch 401/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2012 - val_loss: 0.1661\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2433 - val_loss: 0.1670\n",
      "Epoch 403/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2161 - val_loss: 0.1596\n",
      "Epoch 404/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2190 - val_loss: 0.1788\n",
      "Epoch 405/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2231 - val_loss: 0.1644\n",
      "Epoch 406/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2335 - val_loss: 0.1807\n",
      "Epoch 407/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2502 - val_loss: 0.1674\n",
      "Epoch 408/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2354 - val_loss: 0.1811\n",
      "Epoch 409/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2338 - val_loss: 0.1699\n",
      "Epoch 410/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2183 - val_loss: 0.1673\n",
      "Epoch 411/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2005 - val_loss: 0.1656\n",
      "Epoch 412/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2304 - val_loss: 0.1634\n",
      "Epoch 413/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2158 - val_loss: 0.1726\n",
      "Epoch 414/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2217 - val_loss: 0.2007\n",
      "Epoch 415/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2262 - val_loss: 0.1850\n",
      "Epoch 416/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2200 - val_loss: 0.1876\n",
      "Epoch 417/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2204 - val_loss: 0.1887\n",
      "Epoch 418/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2070 - val_loss: 0.1714\n",
      "Epoch 419/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2091 - val_loss: 0.1665\n",
      "Epoch 420/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2285 - val_loss: 0.1635\n",
      "Epoch 421/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2247 - val_loss: 0.1709\n",
      "Epoch 422/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2210 - val_loss: 0.1703\n",
      "Epoch 423/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.1880\n",
      "Epoch 424/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2593 - val_loss: 0.1901\n",
      "Epoch 425/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2249 - val_loss: 0.1991\n",
      "Epoch 426/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2568 - val_loss: 0.1744\n",
      "Epoch 427/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2558 - val_loss: 0.1936\n",
      "Epoch 428/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2463 - val_loss: 0.1957\n",
      "Epoch 429/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2477 - val_loss: 0.2081\n",
      "Epoch 430/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2499 - val_loss: 0.1771\n",
      "Epoch 431/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2469 - val_loss: 0.1792\n",
      "Epoch 432/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2242 - val_loss: 0.1784\n",
      "Epoch 433/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2055 - val_loss: 0.1687\n",
      "Epoch 434/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2126 - val_loss: 0.1620\n",
      "Epoch 435/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2062 - val_loss: 0.1665\n",
      "Epoch 436/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2123 - val_loss: 0.1640\n",
      "Epoch 437/1000\n",
      "37/37 [==============================] - 0s 916us/step - loss: 0.2255 - val_loss: 0.1617\n",
      "Epoch 438/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2177 - val_loss: 0.1642\n",
      "Epoch 439/1000\n",
      "37/37 [==============================] - 0s 935us/step - loss: 0.2144 - val_loss: 0.1691\n",
      "Epoch 440/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2128 - val_loss: 0.1661\n",
      "Epoch 441/1000\n",
      "37/37 [==============================] - 0s 873us/step - loss: 0.2144 - val_loss: 0.1630\n",
      "Epoch 442/1000\n",
      "37/37 [==============================] - 0s 997us/step - loss: 0.2070 - val_loss: 0.1617\n",
      "Epoch 443/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2144 - val_loss: 0.1689\n",
      "Epoch 444/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2322 - val_loss: 0.1883\n",
      "Epoch 445/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2169 - val_loss: 0.1808\n",
      "Epoch 446/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2350 - val_loss: 0.1813\n",
      "Epoch 447/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2751 - val_loss: 0.1956\n",
      "Epoch 448/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2535 - val_loss: 0.1804\n",
      "Epoch 449/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2373 - val_loss: 0.2081\n",
      "Epoch 450/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2277 - val_loss: 0.1674\n",
      "Epoch 451/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2203 - val_loss: 0.1690\n",
      "Epoch 452/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2139 - val_loss: 0.1613\n",
      "Epoch 453/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2410 - val_loss: 0.1856\n",
      "Epoch 454/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2196 - val_loss: 0.1689\n",
      "Epoch 455/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2191 - val_loss: 0.1623\n",
      "Epoch 456/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1947 - val_loss: 0.1593\n",
      "Epoch 457/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2611 - val_loss: 0.1759\n",
      "Epoch 458/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2321 - val_loss: 0.1840\n",
      "Epoch 459/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2326 - val_loss: 0.1857\n",
      "Epoch 460/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2391 - val_loss: 0.1650\n",
      "Epoch 461/1000\n",
      "37/37 [==============================] - 0s 873us/step - loss: 0.2253 - val_loss: 0.1745\n",
      "Epoch 462/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2434 - val_loss: 0.1784\n",
      "Epoch 463/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2363 - val_loss: 0.1652\n",
      "Epoch 464/1000\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.2260 - val_loss: 0.1929\n",
      "Epoch 465/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2538 - val_loss: 0.1863\n",
      "Epoch 466/1000\n",
      "37/37 [==============================] - 0s 813us/step - loss: 0.2650 - val_loss: 0.2088\n",
      "Epoch 467/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2417 - val_loss: 0.1897\n",
      "Epoch 468/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2094 - val_loss: 0.1731\n",
      "Epoch 469/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2318 - val_loss: 0.1594\n",
      "Epoch 470/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2259 - val_loss: 0.1632\n",
      "Epoch 471/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2164 - val_loss: 0.1534\n",
      "Epoch 472/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2012 - val_loss: 0.1505\n",
      "Epoch 473/1000\n",
      "37/37 [==============================] - 0s 906us/step - loss: 0.2644 - val_loss: 0.2095\n",
      "Epoch 474/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2369 - val_loss: 0.1796\n",
      "Epoch 475/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2435 - val_loss: 0.1810\n",
      "Epoch 476/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2312 - val_loss: 0.1869\n",
      "Epoch 477/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2171 - val_loss: 0.1920\n",
      "Epoch 478/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2259 - val_loss: 0.1900\n",
      "Epoch 479/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2105 - val_loss: 0.1698\n",
      "Epoch 480/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2404 - val_loss: 0.1789\n",
      "Epoch 481/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2220 - val_loss: 0.1804\n",
      "Epoch 482/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2263 - val_loss: 0.1734\n",
      "Epoch 483/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2060 - val_loss: 0.1663\n",
      "Epoch 484/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2326 - val_loss: 0.1615\n",
      "Epoch 485/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2116 - val_loss: 0.1786\n",
      "Epoch 486/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1892 - val_loss: 0.1725\n",
      "Epoch 487/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2534 - val_loss: 0.2052\n",
      "Epoch 488/1000\n",
      "37/37 [==============================] - 0s 977us/step - loss: 0.2610 - val_loss: 0.1722\n",
      "Epoch 489/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2382 - val_loss: 0.1956\n",
      "Epoch 490/1000\n",
      "37/37 [==============================] - 0s 943us/step - loss: 0.2553 - val_loss: 0.1694\n",
      "Epoch 491/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2357 - val_loss: 0.1737\n",
      "Epoch 492/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2237 - val_loss: 0.1727\n",
      "Epoch 493/1000\n",
      "37/37 [==============================] - 0s 822us/step - loss: 0.2235 - val_loss: 0.1627\n",
      "Epoch 494/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2142 - val_loss: 0.1570\n",
      "Epoch 495/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2064 - val_loss: 0.1749\n",
      "Epoch 496/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2299 - val_loss: 0.1571\n",
      "Epoch 497/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2060 - val_loss: 0.1549\n",
      "Epoch 498/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2078 - val_loss: 0.1441\n",
      "Epoch 499/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2056 - val_loss: 0.1735\n",
      "Epoch 500/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2237 - val_loss: 0.1662\n",
      "Epoch 501/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2076 - val_loss: 0.1730\n",
      "Epoch 502/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2155 - val_loss: 0.1815\n",
      "Epoch 503/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2654 - val_loss: 0.1815\n",
      "Epoch 504/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2423 - val_loss: 0.1776\n",
      "Epoch 505/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2612 - val_loss: 0.1858\n",
      "Epoch 506/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2297 - val_loss: 0.1651\n",
      "Epoch 507/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2358 - val_loss: 0.1763\n",
      "Epoch 508/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2198 - val_loss: 0.1664\n",
      "Epoch 509/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2056 - val_loss: 0.1506\n",
      "Epoch 510/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2192 - val_loss: 0.1586\n",
      "Epoch 511/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2165 - val_loss: 0.1730\n",
      "Epoch 512/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2275 - val_loss: 0.1572\n",
      "Epoch 513/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2498 - val_loss: 0.1738\n",
      "Epoch 514/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2409 - val_loss: 0.1621\n",
      "Epoch 515/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2210 - val_loss: 0.1646\n",
      "Epoch 516/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2154 - val_loss: 0.1687\n",
      "Epoch 517/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2146 - val_loss: 0.1645\n",
      "Epoch 518/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2291 - val_loss: 0.1565\n",
      "Epoch 519/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1999 - val_loss: 0.1567\n",
      "Epoch 520/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2284 - val_loss: 0.1854\n",
      "Epoch 521/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2316 - val_loss: 0.1751\n",
      "Epoch 522/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2238 - val_loss: 0.1580\n",
      "Epoch 523/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2022 - val_loss: 0.1462\n",
      "Epoch 524/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2001 - val_loss: 0.1520\n",
      "Epoch 525/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2019 - val_loss: 0.1736\n",
      "Epoch 526/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2334 - val_loss: 0.1587\n",
      "Epoch 527/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2302 - val_loss: 0.2020\n",
      "Epoch 528/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2329 - val_loss: 0.1877\n",
      "Epoch 529/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2592 - val_loss: 0.1602\n",
      "Epoch 530/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2145 - val_loss: 0.1924\n",
      "Epoch 531/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2210 - val_loss: 0.1734\n",
      "Epoch 532/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2136 - val_loss: 0.1744\n",
      "Epoch 533/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2062 - val_loss: 0.1625\n",
      "Epoch 534/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2214 - val_loss: 0.1955\n",
      "Epoch 535/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2224 - val_loss: 0.1822\n",
      "Epoch 536/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2362 - val_loss: 0.1839\n",
      "Epoch 537/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2145 - val_loss: 0.1846\n",
      "Epoch 538/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2310 - val_loss: 0.1718\n",
      "Epoch 539/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1957 - val_loss: 0.1636\n",
      "Epoch 540/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2116 - val_loss: 0.1718\n",
      "Epoch 541/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1891 - val_loss: 0.1653\n",
      "Epoch 542/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1972 - val_loss: 0.1607\n",
      "Epoch 543/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1988 - val_loss: 0.1516\n",
      "Epoch 544/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2176 - val_loss: 0.1577\n",
      "Epoch 545/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2316 - val_loss: 0.1672\n",
      "Epoch 546/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2130 - val_loss: 0.1838\n",
      "Epoch 547/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2143 - val_loss: 0.1800\n",
      "Epoch 548/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2231 - val_loss: 0.1673\n",
      "Epoch 549/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2175 - val_loss: 0.1943\n",
      "Epoch 550/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2277 - val_loss: 0.1729\n",
      "Epoch 551/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1935 - val_loss: 0.1698\n",
      "Epoch 552/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2114 - val_loss: 0.1623\n",
      "Epoch 553/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2164 - val_loss: 0.1754\n",
      "Epoch 554/1000\n",
      "37/37 [==============================] - 0s 964us/step - loss: 0.2137 - val_loss: 0.1671\n",
      "Epoch 555/1000\n",
      "37/37 [==============================] - 0s 680us/step - loss: 0.2102 - val_loss: 0.1511\n",
      "Epoch 556/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1971 - val_loss: 0.1519\n",
      "Epoch 557/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2042 - val_loss: 0.1584\n",
      "Epoch 558/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2069 - val_loss: 0.1557\n",
      "Epoch 559/1000\n",
      "37/37 [==============================] - 0s 998us/step - loss: 0.1937 - val_loss: 0.1607\n",
      "Epoch 560/1000\n",
      "37/37 [==============================] - 0s 960us/step - loss: 0.1743 - val_loss: 0.1506\n",
      "Epoch 561/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1897 - val_loss: 0.1452\n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 787us/step - loss: 0.2374 - val_loss: 0.1866\n",
      "Epoch 563/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2301 - val_loss: 0.1676\n",
      "Epoch 564/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2200 - val_loss: 0.1577\n",
      "Epoch 565/1000\n",
      "37/37 [==============================] - 0s 992us/step - loss: 0.2298 - val_loss: 0.1747\n",
      "Epoch 566/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2112 - val_loss: 0.1739\n",
      "Epoch 567/1000\n",
      "37/37 [==============================] - 0s 998us/step - loss: 0.2163 - val_loss: 0.1938\n",
      "Epoch 568/1000\n",
      "37/37 [==============================] - 0s 698us/step - loss: 0.2290 - val_loss: 0.1796\n",
      "Epoch 569/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2150 - val_loss: 0.1609\n",
      "Epoch 570/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2016 - val_loss: 0.1652\n",
      "Epoch 571/1000\n",
      "37/37 [==============================] - 0s 953us/step - loss: 0.2004 - val_loss: 0.1676\n",
      "Epoch 572/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2319 - val_loss: 0.1965\n",
      "Epoch 573/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2328 - val_loss: 0.1813\n",
      "Epoch 574/1000\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.2350 - val_loss: 0.1823\n",
      "Epoch 575/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2126 - val_loss: 0.1713\n",
      "Epoch 576/1000\n",
      "37/37 [==============================] - 0s 957us/step - loss: 0.2085 - val_loss: 0.1671\n",
      "Epoch 577/1000\n",
      "37/37 [==============================] - 0s 729us/step - loss: 0.2143 - val_loss: 0.1613\n",
      "Epoch 578/1000\n",
      "37/37 [==============================] - 0s 689us/step - loss: 0.1884 - val_loss: 0.1558\n",
      "Epoch 579/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1995 - val_loss: 0.1543\n",
      "Epoch 580/1000\n",
      "37/37 [==============================] - 0s 701us/step - loss: 0.2223 - val_loss: 0.1813\n",
      "Epoch 581/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2029 - val_loss: 0.1580\n",
      "Epoch 582/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2006 - val_loss: 0.1581\n",
      "Epoch 583/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2346 - val_loss: 0.1700\n",
      "Epoch 584/1000\n",
      "37/37 [==============================] - 0s 932us/step - loss: 0.2229 - val_loss: 0.1639\n",
      "Epoch 585/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2233 - val_loss: 0.1666\n",
      "Epoch 586/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1989 - val_loss: 0.1591\n",
      "Epoch 587/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2637 - val_loss: 0.1652\n",
      "Epoch 588/1000\n",
      "37/37 [==============================] - 0s 919us/step - loss: 0.2261 - val_loss: 0.1835\n",
      "Epoch 589/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2272 - val_loss: 0.1743\n",
      "Epoch 590/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2361 - val_loss: 0.1654\n",
      "Epoch 591/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2138 - val_loss: 0.1583\n",
      "Epoch 592/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2378 - val_loss: 0.1746\n",
      "Epoch 593/1000\n",
      "37/37 [==============================] - 0s 892us/step - loss: 0.2139 - val_loss: 0.1712\n",
      "Epoch 594/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2226 - val_loss: 0.1698\n",
      "Epoch 595/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2463 - val_loss: 0.1721\n",
      "Epoch 596/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2302 - val_loss: 0.1754\n",
      "Epoch 597/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1929 - val_loss: 0.1664\n",
      "Epoch 598/1000\n",
      "37/37 [==============================] - 0s 922us/step - loss: 0.2123 - val_loss: 0.1519\n",
      "Epoch 599/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1958 - val_loss: 0.1448\n",
      "Epoch 600/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1938 - val_loss: 0.1630\n",
      "Epoch 601/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1857 - val_loss: 0.1521\n",
      "Epoch 602/1000\n",
      "37/37 [==============================] - 0s 904us/step - loss: 0.2265 - val_loss: 0.1644\n",
      "Epoch 603/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2063 - val_loss: 0.1544\n",
      "Epoch 604/1000\n",
      "37/37 [==============================] - 0s 987us/step - loss: 0.1995 - val_loss: 0.1451\n",
      "Epoch 605/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1982 - val_loss: 0.1618\n",
      "Epoch 606/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1841 - val_loss: 0.1583\n",
      "Epoch 607/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2069 - val_loss: 0.1655\n",
      "Epoch 608/1000\n",
      "37/37 [==============================] - 0s 637us/step - loss: 0.2414 - val_loss: 0.1777\n",
      "Epoch 609/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2340 - val_loss: 0.1757\n",
      "Epoch 610/1000\n",
      "37/37 [==============================] - 0s 720us/step - loss: 0.2068 - val_loss: 0.1449\n",
      "Epoch 611/1000\n",
      "37/37 [==============================] - 0s 954us/step - loss: 0.2068 - val_loss: 0.1641\n",
      "Epoch 612/1000\n",
      "37/37 [==============================] - 0s 927us/step - loss: 0.1864 - val_loss: 0.1573\n",
      "Epoch 613/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2346 - val_loss: 0.1856\n",
      "Epoch 614/1000\n",
      "37/37 [==============================] - 0s 854us/step - loss: 0.2683 - val_loss: 0.1603\n",
      "Epoch 615/1000\n",
      "37/37 [==============================] - 0s 987us/step - loss: 0.2162 - val_loss: 0.1743\n",
      "Epoch 616/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2396 - val_loss: 0.1756\n",
      "Epoch 617/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2445 - val_loss: 0.1737\n",
      "Epoch 618/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2066 - val_loss: 0.1561\n",
      "Epoch 619/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2269 - val_loss: 0.1618\n",
      "Epoch 620/1000\n",
      "37/37 [==============================] - 0s 887us/step - loss: 0.2125 - val_loss: 0.1541\n",
      "Epoch 621/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1733 - val_loss: 0.1475\n",
      "Epoch 622/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1911 - val_loss: 0.1511\n",
      "Epoch 623/1000\n",
      "37/37 [==============================] - 0s 898us/step - loss: 0.1958 - val_loss: 0.1500\n",
      "Epoch 624/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1980 - val_loss: 0.1529\n",
      "Epoch 625/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2131 - val_loss: 0.1822\n",
      "Epoch 626/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2236 - val_loss: 0.1589\n",
      "Epoch 627/1000\n",
      "37/37 [==============================] - 0s 937us/step - loss: 0.2340 - val_loss: 0.1569\n",
      "Epoch 628/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2073 - val_loss: 0.1582\n",
      "Epoch 629/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2448 - val_loss: 0.1615\n",
      "Epoch 630/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2062 - val_loss: 0.1636\n",
      "Epoch 631/1000\n",
      "37/37 [==============================] - 0s 708us/step - loss: 0.2795 - val_loss: 0.1779\n",
      "Epoch 632/1000\n",
      "37/37 [==============================] - 0s 994us/step - loss: 0.2355 - val_loss: 0.1610\n",
      "Epoch 633/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2342 - val_loss: 0.1619\n",
      "Epoch 634/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2278 - val_loss: 0.1595\n",
      "Epoch 635/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2259 - val_loss: 0.1707\n",
      "Epoch 636/1000\n",
      "37/37 [==============================] - 0s 950us/step - loss: 0.2125 - val_loss: 0.1679\n",
      "Epoch 637/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2347 - val_loss: 0.1574\n",
      "Epoch 638/1000\n",
      "37/37 [==============================] - 0s 882us/step - loss: 0.2487 - val_loss: 0.1594\n",
      "Epoch 639/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2272 - val_loss: 0.1868\n",
      "Epoch 640/1000\n",
      "37/37 [==============================] - 0s 871us/step - loss: 0.2435 - val_loss: 0.1682\n",
      "Epoch 641/1000\n",
      "37/37 [==============================] - 0s 830us/step - loss: 0.1981 - val_loss: 0.1480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 642/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1881 - val_loss: 0.1648\n",
      "Epoch 643/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2395 - val_loss: 0.1897\n",
      "Epoch 644/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2459 - val_loss: 0.1564\n",
      "Epoch 645/1000\n",
      "37/37 [==============================] - 0s 921us/step - loss: 0.2202 - val_loss: 0.1498\n",
      "Epoch 646/1000\n",
      "37/37 [==============================] - 0s 650us/step - loss: 0.2326 - val_loss: 0.1695\n",
      "Epoch 647/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2208 - val_loss: 0.1529\n",
      "Epoch 648/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2236 - val_loss: 0.1480\n",
      "Epoch 649/1000\n",
      "37/37 [==============================] - 0s 649us/step - loss: 0.2415 - val_loss: 0.1633\n",
      "Epoch 650/1000\n",
      "37/37 [==============================] - 0s 955us/step - loss: 0.2214 - val_loss: 0.1769\n",
      "Epoch 651/1000\n",
      "37/37 [==============================] - 0s 826us/step - loss: 0.2433 - val_loss: 0.1722\n",
      "Epoch 652/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2233 - val_loss: 0.1562\n",
      "Epoch 653/1000\n",
      "37/37 [==============================] - 0s 819us/step - loss: 0.2368 - val_loss: 0.1518\n",
      "Epoch 654/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2280 - val_loss: 0.1957\n",
      "Epoch 655/1000\n",
      "37/37 [==============================] - 0s 973us/step - loss: 0.2410 - val_loss: 0.1767\n",
      "Epoch 656/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2166 - val_loss: 0.1518\n",
      "Epoch 657/1000\n",
      "37/37 [==============================] - 0s 920us/step - loss: 0.2311 - val_loss: 0.1570\n",
      "Epoch 658/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2605 - val_loss: 0.1924\n",
      "Epoch 659/1000\n",
      "37/37 [==============================] - 0s 970us/step - loss: 0.2258 - val_loss: 0.1773\n",
      "Epoch 660/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2290 - val_loss: 0.1826\n",
      "Epoch 661/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1997 - val_loss: 0.1718\n",
      "Epoch 662/1000\n",
      "37/37 [==============================] - 0s 828us/step - loss: 0.2106 - val_loss: 0.1815\n",
      "Epoch 663/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1963 - val_loss: 0.1746\n",
      "Epoch 664/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2549 - val_loss: 0.1629\n",
      "Epoch 665/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2127 - val_loss: 0.1605\n",
      "Epoch 666/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2030 - val_loss: 0.1608\n",
      "Epoch 667/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.1973\n",
      "Epoch 668/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2341 - val_loss: 0.1587\n",
      "Epoch 669/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2454 - val_loss: 0.1603\n",
      "Epoch 670/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2391 - val_loss: 0.1763\n",
      "Epoch 671/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2055 - val_loss: 0.1752\n",
      "Epoch 672/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.1878\n",
      "Epoch 673/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2447 - val_loss: 0.1778\n",
      "Epoch 674/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2299 - val_loss: 0.1788\n",
      "Epoch 675/1000\n",
      "37/37 [==============================] - 0s 820us/step - loss: 0.2200 - val_loss: 0.1710\n",
      "Epoch 676/1000\n",
      "37/37 [==============================] - 0s 900us/step - loss: 0.2283 - val_loss: 0.1674\n",
      "Epoch 677/1000\n",
      "37/37 [==============================] - 0s 980us/step - loss: 0.2209 - val_loss: 0.1714\n",
      "Epoch 678/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2246 - val_loss: 0.1717\n",
      "Epoch 679/1000\n",
      "37/37 [==============================] - 0s 986us/step - loss: 0.2413 - val_loss: 0.1713\n",
      "Epoch 680/1000\n",
      "37/37 [==============================] - 0s 902us/step - loss: 0.2184 - val_loss: 0.1592\n",
      "Epoch 681/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2090 - val_loss: 0.1501\n",
      "Epoch 682/1000\n",
      "37/37 [==============================] - 0s 977us/step - loss: 0.2257 - val_loss: 0.1620\n",
      "Epoch 683/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2744 - val_loss: 0.1802\n",
      "Epoch 684/1000\n",
      "37/37 [==============================] - 0s 777us/step - loss: 0.2419 - val_loss: 0.1796\n",
      "Epoch 685/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2084 - val_loss: 0.1762\n",
      "Epoch 686/1000\n",
      "37/37 [==============================] - 0s 789us/step - loss: 0.2232 - val_loss: 0.1696\n",
      "Epoch 687/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2244 - val_loss: 0.1657\n",
      "Epoch 688/1000\n",
      "37/37 [==============================] - 0s 750us/step - loss: 0.2136 - val_loss: 0.1565\n",
      "Epoch 689/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2021 - val_loss: 0.1649\n",
      "Epoch 690/1000\n",
      "37/37 [==============================] - 0s 812us/step - loss: 0.2152 - val_loss: 0.1605\n",
      "Epoch 691/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2156 - val_loss: 0.1721\n",
      "Epoch 692/1000\n",
      "37/37 [==============================] - 0s 875us/step - loss: 0.2282 - val_loss: 0.1648\n",
      "Epoch 693/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2145 - val_loss: 0.1690\n",
      "Epoch 694/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2202 - val_loss: 0.1889\n",
      "Epoch 695/1000\n",
      "37/37 [==============================] - 0s 753us/step - loss: 0.2296 - val_loss: 0.1627\n",
      "Epoch 696/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2018 - val_loss: 0.1644\n",
      "Epoch 697/1000\n",
      "37/37 [==============================] - 0s 756us/step - loss: 0.1889 - val_loss: 0.1616\n",
      "Epoch 698/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2131 - val_loss: 0.1565\n",
      "Epoch 699/1000\n",
      "37/37 [==============================] - 0s 920us/step - loss: 0.2272 - val_loss: 0.1707\n",
      "Epoch 700/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2404 - val_loss: 0.1536\n",
      "Epoch 701/1000\n",
      "37/37 [==============================] - 0s 833us/step - loss: 0.2254 - val_loss: 0.1618\n",
      "Epoch 702/1000\n",
      "37/37 [==============================] - 0s 926us/step - loss: 0.2277 - val_loss: 0.1811\n",
      "Epoch 703/1000\n",
      "37/37 [==============================] - 0s 908us/step - loss: 0.2157 - val_loss: 0.1606\n",
      "Epoch 704/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2040 - val_loss: 0.1419\n",
      "Epoch 705/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1814 - val_loss: 0.1449\n",
      "Epoch 706/1000\n",
      "37/37 [==============================] - 0s 888us/step - loss: 0.2022 - val_loss: 0.1441\n",
      "Epoch 707/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1911 - val_loss: 0.1487\n",
      "Epoch 708/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2165 - val_loss: 0.1517\n",
      "Epoch 709/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2255 - val_loss: 0.1554\n",
      "Epoch 710/1000\n",
      "37/37 [==============================] - 0s 923us/step - loss: 0.2261 - val_loss: 0.1557\n",
      "Epoch 711/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.1832\n",
      "Epoch 712/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2404 - val_loss: 0.1847\n",
      "Epoch 713/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2061 - val_loss: 0.1819\n",
      "Epoch 714/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2090 - val_loss: 0.1799\n",
      "Epoch 715/1000\n",
      "37/37 [==============================] - 0s 681us/step - loss: 0.2152 - val_loss: 0.1586\n",
      "Epoch 716/1000\n",
      "37/37 [==============================] - 0s 925us/step - loss: 0.1984 - val_loss: 0.1480\n",
      "Epoch 717/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1740 - val_loss: 0.1351\n",
      "Epoch 718/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1869 - val_loss: 0.1470\n",
      "Epoch 719/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2082 - val_loss: 0.1587\n",
      "Epoch 720/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1746 - val_loss: 0.1452\n",
      "Epoch 721/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2099 - val_loss: 0.1800\n",
      "Epoch 722/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2122 - val_loss: 0.1480\n",
      "Epoch 723/1000\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.2142 - val_loss: 0.1770\n",
      "Epoch 724/1000\n",
      "37/37 [==============================] - 0s 931us/step - loss: 0.2094 - val_loss: 0.1813\n",
      "Epoch 725/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2209 - val_loss: 0.1549\n",
      "Epoch 726/1000\n",
      "37/37 [==============================] - 0s 818us/step - loss: 0.1897 - val_loss: 0.1594\n",
      "Epoch 727/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2367 - val_loss: 0.1552\n",
      "Epoch 728/1000\n",
      "37/37 [==============================] - 0s 907us/step - loss: 0.2234 - val_loss: 0.1608\n",
      "Epoch 729/1000\n",
      "37/37 [==============================] - 0s 953us/step - loss: 0.2217 - val_loss: 0.1501\n",
      "Epoch 730/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2456 - val_loss: 0.1593\n",
      "Epoch 731/1000\n",
      "37/37 [==============================] - 0s 718us/step - loss: 0.2001 - val_loss: 0.1513\n",
      "Epoch 732/1000\n",
      "37/37 [==============================] - 0s 974us/step - loss: 0.2087 - val_loss: 0.2203\n",
      "Epoch 733/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2360 - val_loss: 0.1885\n",
      "Epoch 734/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2468 - val_loss: 0.1554\n",
      "Epoch 735/1000\n",
      "37/37 [==============================] - 0s 661us/step - loss: 0.1998 - val_loss: 0.1490\n",
      "Epoch 736/1000\n",
      "37/37 [==============================] - 0s 878us/step - loss: 0.2691 - val_loss: 0.1783\n",
      "Epoch 737/1000\n",
      "37/37 [==============================] - 0s 968us/step - loss: 0.2434 - val_loss: 0.2067\n",
      "Epoch 738/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2360 - val_loss: 0.1847\n",
      "Epoch 739/1000\n",
      "37/37 [==============================] - 0s 786us/step - loss: 0.2361 - val_loss: 0.1847\n",
      "Epoch 740/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2081 - val_loss: 0.1742\n",
      "Epoch 741/1000\n",
      "37/37 [==============================] - 0s 995us/step - loss: 0.2273 - val_loss: 0.1776\n",
      "Epoch 742/1000\n",
      "37/37 [==============================] - 0s 895us/step - loss: 0.2060 - val_loss: 0.1713\n",
      "Epoch 743/1000\n",
      "37/37 [==============================] - 0s 911us/step - loss: 0.2193 - val_loss: 0.1645\n",
      "Epoch 744/1000\n",
      "37/37 [==============================] - 0s 908us/step - loss: 0.1989 - val_loss: 0.1517\n",
      "Epoch 745/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2043 - val_loss: 0.1515\n",
      "Epoch 746/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2444 - val_loss: 0.1669\n",
      "Epoch 747/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2118 - val_loss: 0.1660\n",
      "Epoch 748/1000\n",
      "37/37 [==============================] - 0s 897us/step - loss: 0.2054 - val_loss: 0.1512\n",
      "Epoch 749/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2139 - val_loss: 0.1936\n",
      "Epoch 750/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2143 - val_loss: 0.1930\n",
      "Epoch 751/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2159 - val_loss: 0.1611\n",
      "Epoch 752/1000\n",
      "37/37 [==============================] - 0s 749us/step - loss: 0.1989 - val_loss: 0.1610\n",
      "Epoch 753/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2129 - val_loss: 0.1630\n",
      "Epoch 754/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2019 - val_loss: 0.1477\n",
      "Epoch 755/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2037 - val_loss: 0.1504\n",
      "Epoch 756/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2003 - val_loss: 0.1433\n",
      "Epoch 757/1000\n",
      "37/37 [==============================] - 0s 662us/step - loss: 0.1836 - val_loss: 0.1411\n",
      "Epoch 758/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2025 - val_loss: 0.1424\n",
      "Epoch 759/1000\n",
      "37/37 [==============================] - 0s 974us/step - loss: 0.1828 - val_loss: 0.1391\n",
      "Epoch 760/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1893 - val_loss: 0.1369\n",
      "Epoch 761/1000\n",
      "37/37 [==============================] - 0s 694us/step - loss: 0.1856 - val_loss: 0.1424\n",
      "Epoch 762/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1969 - val_loss: 0.1408\n",
      "Epoch 763/1000\n",
      "37/37 [==============================] - 0s 828us/step - loss: 0.1982 - val_loss: 0.1312\n",
      "Epoch 764/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2033 - val_loss: 0.1561\n",
      "Epoch 765/1000\n",
      "37/37 [==============================] - 0s 755us/step - loss: 0.2444 - val_loss: 0.1715\n",
      "Epoch 766/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2123 - val_loss: 0.1523\n",
      "Epoch 767/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2028 - val_loss: 0.1534\n",
      "Epoch 768/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2035 - val_loss: 0.1576\n",
      "Epoch 769/1000\n",
      "37/37 [==============================] - 0s 850us/step - loss: 0.2205 - val_loss: 0.1537\n",
      "Epoch 770/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2581 - val_loss: 0.1772\n",
      "Epoch 771/1000\n",
      "37/37 [==============================] - 0s 922us/step - loss: 0.2386 - val_loss: 0.1851\n",
      "Epoch 772/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2124 - val_loss: 0.1683\n",
      "Epoch 773/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2077 - val_loss: 0.1742\n",
      "Epoch 774/1000\n",
      "37/37 [==============================] - 0s 906us/step - loss: 0.2264 - val_loss: 0.1578\n",
      "Epoch 775/1000\n",
      "37/37 [==============================] - 0s 832us/step - loss: 0.2323 - val_loss: 0.1658\n",
      "Epoch 776/1000\n",
      "37/37 [==============================] - 0s 937us/step - loss: 0.2230 - val_loss: 0.1836\n",
      "Epoch 777/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2282 - val_loss: 0.1646\n",
      "Epoch 778/1000\n",
      "37/37 [==============================] - 0s 997us/step - loss: 0.2191 - val_loss: 0.1685\n",
      "Epoch 779/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2308 - val_loss: 0.1700\n",
      "Epoch 780/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2434 - val_loss: 0.1608\n",
      "Epoch 781/1000\n",
      "37/37 [==============================] - 0s 955us/step - loss: 0.2083 - val_loss: 0.1590\n",
      "Epoch 782/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2100 - val_loss: 0.1554\n",
      "Epoch 783/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2164 - val_loss: 0.1504\n",
      "Epoch 784/1000\n",
      "37/37 [==============================] - 0s 902us/step - loss: 0.1964 - val_loss: 0.1913\n",
      "Epoch 785/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2042 - val_loss: 0.1458\n",
      "Epoch 786/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2049 - val_loss: 0.1519\n",
      "Epoch 787/1000\n",
      "37/37 [==============================] - 0s 805us/step - loss: 0.2043 - val_loss: 0.1434\n",
      "Epoch 788/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1803 - val_loss: 0.1462\n",
      "Epoch 789/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2201 - val_loss: 0.1570\n",
      "Epoch 790/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1987 - val_loss: 0.1503\n",
      "Epoch 791/1000\n",
      "37/37 [==============================] - 0s 874us/step - loss: 0.1873 - val_loss: 0.1435\n",
      "Epoch 792/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1770 - val_loss: 0.1424\n",
      "Epoch 793/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2150 - val_loss: 0.1598\n",
      "Epoch 794/1000\n",
      "37/37 [==============================] - 0s 893us/step - loss: 0.1924 - val_loss: 0.1690\n",
      "Epoch 795/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2048 - val_loss: 0.1497\n",
      "Epoch 796/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1905 - val_loss: 0.1571\n",
      "Epoch 797/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.1437\n",
      "Epoch 798/1000\n",
      "37/37 [==============================] - 0s 942us/step - loss: 0.1984 - val_loss: 0.1381\n",
      "Epoch 799/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2057 - val_loss: 0.1531\n",
      "Epoch 800/1000\n",
      "37/37 [==============================] - 0s 836us/step - loss: 0.2015 - val_loss: 0.1331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2219 - val_loss: 0.1394\n",
      "Epoch 802/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2640 - val_loss: 0.1926\n",
      "Epoch 803/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2292 - val_loss: 0.1555\n",
      "Epoch 804/1000\n",
      "37/37 [==============================] - 0s 687us/step - loss: 0.2207 - val_loss: 0.1565\n",
      "Epoch 805/1000\n",
      "37/37 [==============================] - 0s 775us/step - loss: 0.2278 - val_loss: 0.1684\n",
      "Epoch 806/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2393 - val_loss: 0.1864\n",
      "Epoch 807/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2135 - val_loss: 0.1838\n",
      "Epoch 808/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2244 - val_loss: 0.1565\n",
      "Epoch 809/1000\n",
      "37/37 [==============================] - 0s 995us/step - loss: 0.1933 - val_loss: 0.1499\n",
      "Epoch 810/1000\n",
      "37/37 [==============================] - 0s 896us/step - loss: 0.2333 - val_loss: 0.1620\n",
      "Epoch 811/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2159 - val_loss: 0.1520\n",
      "Epoch 812/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2168 - val_loss: 0.1705\n",
      "Epoch 813/1000\n",
      "37/37 [==============================] - 0s 668us/step - loss: 0.2541 - val_loss: 0.1866\n",
      "Epoch 814/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2305 - val_loss: 0.1704\n",
      "Epoch 815/1000\n",
      "37/37 [==============================] - 0s 746us/step - loss: 0.2227 - val_loss: 0.1670\n",
      "Epoch 816/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2209 - val_loss: 0.1681\n",
      "Epoch 817/1000\n",
      "37/37 [==============================] - 0s 820us/step - loss: 0.2518 - val_loss: 0.1981\n",
      "Epoch 818/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2470 - val_loss: 0.1839\n",
      "Epoch 819/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2202 - val_loss: 0.1649\n",
      "Epoch 820/1000\n",
      "37/37 [==============================] - 0s 761us/step - loss: 0.2228 - val_loss: 0.1520\n",
      "Epoch 821/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2049 - val_loss: 0.1519\n",
      "Epoch 822/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2092 - val_loss: 0.1628\n",
      "Epoch 823/1000\n",
      "37/37 [==============================] - 0s 773us/step - loss: 0.2034 - val_loss: 0.1566\n",
      "Epoch 824/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2001 - val_loss: 0.1459\n",
      "Epoch 825/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1815 - val_loss: 0.1364\n",
      "Epoch 826/1000\n",
      "37/37 [==============================] - 0s 707us/step - loss: 0.1904 - val_loss: 0.1356\n",
      "Epoch 827/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2190 - val_loss: 0.1583\n",
      "Epoch 828/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2072 - val_loss: 0.1565\n",
      "Epoch 829/1000\n",
      "37/37 [==============================] - 0s 989us/step - loss: 0.1853 - val_loss: 0.1617\n",
      "Epoch 830/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2231 - val_loss: 0.1516\n",
      "Epoch 831/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2128 - val_loss: 0.1777\n",
      "Epoch 832/1000\n",
      "37/37 [==============================] - 0s 735us/step - loss: 0.2168 - val_loss: 0.1958\n",
      "Epoch 833/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2399 - val_loss: 0.1562\n",
      "Epoch 834/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2019 - val_loss: 0.1792\n",
      "Epoch 835/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1996 - val_loss: 0.1672\n",
      "Epoch 836/1000\n",
      "37/37 [==============================] - 0s 820us/step - loss: 0.1945 - val_loss: 0.1532\n",
      "Epoch 837/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2281 - val_loss: 0.1535\n",
      "Epoch 838/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2185 - val_loss: 0.1507\n",
      "Epoch 839/1000\n",
      "37/37 [==============================] - 0s 847us/step - loss: 0.2064 - val_loss: 0.1666\n",
      "Epoch 840/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2175 - val_loss: 0.1520\n",
      "Epoch 841/1000\n",
      "37/37 [==============================] - 0s 882us/step - loss: 0.2080 - val_loss: 0.1519\n",
      "Epoch 842/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1967 - val_loss: 0.1450\n",
      "Epoch 843/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2449 - val_loss: 0.1534\n",
      "Epoch 844/1000\n",
      "37/37 [==============================] - 0s 840us/step - loss: 0.2324 - val_loss: 0.1923\n",
      "Epoch 845/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2196 - val_loss: 0.1780\n",
      "Epoch 846/1000\n",
      "37/37 [==============================] - 0s 944us/step - loss: 0.2206 - val_loss: 0.1680\n",
      "Epoch 847/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1983 - val_loss: 0.1496\n",
      "Epoch 848/1000\n",
      "37/37 [==============================] - 0s 766us/step - loss: 0.2314 - val_loss: 0.1587\n",
      "Epoch 849/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2019 - val_loss: 0.1648\n",
      "Epoch 850/1000\n",
      "37/37 [==============================] - 0s 952us/step - loss: 0.2219 - val_loss: 0.1645\n",
      "Epoch 851/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2076 - val_loss: 0.1767\n",
      "Epoch 852/1000\n",
      "37/37 [==============================] - 0s 801us/step - loss: 0.2105 - val_loss: 0.1519\n",
      "Epoch 853/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2137 - val_loss: 0.1871\n",
      "Epoch 854/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2279 - val_loss: 0.1703\n",
      "Epoch 855/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1987 - val_loss: 0.1707\n",
      "Epoch 856/1000\n",
      "37/37 [==============================] - 0s 920us/step - loss: 0.2349 - val_loss: 0.1659\n",
      "Epoch 857/1000\n",
      "37/37 [==============================] - 0s 932us/step - loss: 0.2585 - val_loss: 0.2019\n",
      "Epoch 858/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2208 - val_loss: 0.1788\n",
      "Epoch 859/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2103 - val_loss: 0.1733\n",
      "Epoch 860/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2074 - val_loss: 0.1784\n",
      "Epoch 861/1000\n",
      "37/37 [==============================] - 0s 894us/step - loss: 0.2183 - val_loss: 0.1499\n",
      "Epoch 862/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1996 - val_loss: 0.1603\n",
      "Epoch 863/1000\n",
      "37/37 [==============================] - 0s 877us/step - loss: 0.2191 - val_loss: 0.1562\n",
      "Epoch 864/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2317 - val_loss: 0.1627\n",
      "Epoch 865/1000\n",
      "37/37 [==============================] - 0s 836us/step - loss: 0.2056 - val_loss: 0.1532\n",
      "Epoch 866/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2243 - val_loss: 0.1708\n",
      "Epoch 867/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2161 - val_loss: 0.1622\n",
      "Epoch 868/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2202 - val_loss: 0.1697\n",
      "Epoch 869/1000\n",
      "37/37 [==============================] - 0s 873us/step - loss: 0.2274 - val_loss: 0.1901\n",
      "Epoch 870/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2085 - val_loss: 0.1699\n",
      "Epoch 871/1000\n",
      "37/37 [==============================] - 0s 963us/step - loss: 0.2090 - val_loss: 0.1746\n",
      "Epoch 872/1000\n",
      "37/37 [==============================] - 0s 877us/step - loss: 0.2189 - val_loss: 0.1540\n",
      "Epoch 873/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2048 - val_loss: 0.1553\n",
      "Epoch 874/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2118 - val_loss: 0.1585\n",
      "Epoch 875/1000\n",
      "37/37 [==============================] - 0s 899us/step - loss: 0.2043 - val_loss: 0.1649\n",
      "Epoch 876/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1991 - val_loss: 0.1425\n",
      "Epoch 877/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1887 - val_loss: 0.1524\n",
      "Epoch 878/1000\n",
      "37/37 [==============================] - 0s 702us/step - loss: 0.1879 - val_loss: 0.1611\n",
      "Epoch 879/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2079 - val_loss: 0.1499\n",
      "Epoch 880/1000\n",
      "37/37 [==============================] - 0s 981us/step - loss: 0.1761 - val_loss: 0.1517\n",
      "Epoch 881/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2042 - val_loss: 0.1493\n",
      "Epoch 882/1000\n",
      "37/37 [==============================] - 0s 791us/step - loss: 0.1990 - val_loss: 0.1656\n",
      "Epoch 883/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2154 - val_loss: 0.1554\n",
      "Epoch 884/1000\n",
      "37/37 [==============================] - 0s 937us/step - loss: 0.2451 - val_loss: 0.1528\n",
      "Epoch 885/1000\n",
      "37/37 [==============================] - 0s 887us/step - loss: 0.2282 - val_loss: 0.1574\n",
      "Epoch 886/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2328 - val_loss: 0.1636\n",
      "Epoch 887/1000\n",
      "37/37 [==============================] - 0s 689us/step - loss: 0.2113 - val_loss: 0.1614\n",
      "Epoch 888/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2057 - val_loss: 0.1531\n",
      "Epoch 889/1000\n",
      "37/37 [==============================] - 0s 909us/step - loss: 0.2263 - val_loss: 0.1567\n",
      "Epoch 890/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2186 - val_loss: 0.1780\n",
      "Epoch 891/1000\n",
      "37/37 [==============================] - 0s 769us/step - loss: 0.2297 - val_loss: 0.1387\n",
      "Epoch 892/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2083 - val_loss: 0.1470\n",
      "Epoch 893/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1814 - val_loss: 0.1435\n",
      "Epoch 894/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2531 - val_loss: 0.1617\n",
      "Epoch 895/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1957 - val_loss: 0.1602\n",
      "Epoch 896/1000\n",
      "37/37 [==============================] - 0s 784us/step - loss: 0.2119 - val_loss: 0.1501\n",
      "Epoch 897/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1905 - val_loss: 0.1665\n",
      "Epoch 898/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2105 - val_loss: 0.1660\n",
      "Epoch 899/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2127 - val_loss: 0.1774\n",
      "Epoch 900/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2167 - val_loss: 0.1851\n",
      "Epoch 901/1000\n",
      "37/37 [==============================] - 0s 786us/step - loss: 0.2062 - val_loss: 0.1496\n",
      "Epoch 902/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2031 - val_loss: 0.1537\n",
      "Epoch 903/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1614 - val_loss: 0.1572\n",
      "Epoch 904/1000\n",
      "37/37 [==============================] - 0s 678us/step - loss: 0.1838 - val_loss: 0.1297\n",
      "Epoch 905/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2101 - val_loss: 0.1578\n",
      "Epoch 906/1000\n",
      "37/37 [==============================] - 0s 854us/step - loss: 0.2660 - val_loss: 0.1376\n",
      "Epoch 907/1000\n",
      "37/37 [==============================] - 0s 618us/step - loss: 0.2345 - val_loss: 0.1721\n",
      "Epoch 908/1000\n",
      "37/37 [==============================] - 0s 934us/step - loss: 0.2113 - val_loss: 0.1500\n",
      "Epoch 909/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2046 - val_loss: 0.1614\n",
      "Epoch 910/1000\n",
      "37/37 [==============================] - 0s 885us/step - loss: 0.1995 - val_loss: 0.1453\n",
      "Epoch 911/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1896 - val_loss: 0.1418\n",
      "Epoch 912/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1895 - val_loss: 0.1469\n",
      "Epoch 913/1000\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.1740 - val_loss: 0.1481\n",
      "Epoch 914/1000\n",
      "37/37 [==============================] - 0s 931us/step - loss: 0.2435 - val_loss: 0.1523\n",
      "Epoch 915/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2417 - val_loss: 0.1791\n",
      "Epoch 916/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2085 - val_loss: 0.1459\n",
      "Epoch 917/1000\n",
      "37/37 [==============================] - 0s 827us/step - loss: 0.1927 - val_loss: 0.1429\n",
      "Epoch 918/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2232 - val_loss: 0.1833\n",
      "Epoch 919/1000\n",
      "37/37 [==============================] - 0s 869us/step - loss: 0.2493 - val_loss: 0.2020\n",
      "Epoch 920/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2511 - val_loss: 0.1828\n",
      "Epoch 921/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2296 - val_loss: 0.1533\n",
      "Epoch 922/1000\n",
      "37/37 [==============================] - 0s 872us/step - loss: 0.1954 - val_loss: 0.1519\n",
      "Epoch 923/1000\n",
      "37/37 [==============================] - 0s 979us/step - loss: 0.1956 - val_loss: 0.2001\n",
      "Epoch 924/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2346 - val_loss: 0.1953\n",
      "Epoch 925/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1998 - val_loss: 0.1689\n",
      "Epoch 926/1000\n",
      "37/37 [==============================] - 0s 949us/step - loss: 0.2037 - val_loss: 0.1744\n",
      "Epoch 927/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2281 - val_loss: 0.1637\n",
      "Epoch 928/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2168 - val_loss: 0.1658\n",
      "Epoch 929/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2319 - val_loss: 0.1667\n",
      "Epoch 930/1000\n",
      "37/37 [==============================] - 0s 757us/step - loss: 0.2021 - val_loss: 0.1444\n",
      "Epoch 931/1000\n",
      "37/37 [==============================] - 0s 951us/step - loss: 0.1846 - val_loss: 0.1483\n",
      "Epoch 932/1000\n",
      "37/37 [==============================] - 0s 987us/step - loss: 0.1881 - val_loss: 0.1449\n",
      "Epoch 933/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1916 - val_loss: 0.1480\n",
      "Epoch 934/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1724 - val_loss: 0.1529\n",
      "Epoch 935/1000\n",
      "37/37 [==============================] - 0s 911us/step - loss: 0.2152 - val_loss: 0.1683\n",
      "Epoch 936/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2163 - val_loss: 0.1587\n",
      "Epoch 937/1000\n",
      "37/37 [==============================] - 0s 876us/step - loss: 0.1931 - val_loss: 0.1651\n",
      "Epoch 938/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2354 - val_loss: 0.1707\n",
      "Epoch 939/1000\n",
      "37/37 [==============================] - 0s 795us/step - loss: 0.2073 - val_loss: 0.1568\n",
      "Epoch 940/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1969 - val_loss: 0.1486\n",
      "Epoch 941/1000\n",
      "37/37 [==============================] - 0s 856us/step - loss: 0.1922 - val_loss: 0.1420\n",
      "Epoch 942/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2034 - val_loss: 0.1568\n",
      "Epoch 943/1000\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.2124 - val_loss: 0.1568\n",
      "Epoch 944/1000\n",
      "37/37 [==============================] - 0s 936us/step - loss: 0.1969 - val_loss: 0.1441\n",
      "Epoch 945/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1914 - val_loss: 0.1409\n",
      "Epoch 946/1000\n",
      "37/37 [==============================] - 0s 993us/step - loss: 0.1924 - val_loss: 0.1374\n",
      "Epoch 947/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1971 - val_loss: 0.1421\n",
      "Epoch 948/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2070 - val_loss: 0.1363\n",
      "Epoch 949/1000\n",
      "37/37 [==============================] - 0s 908us/step - loss: 0.2042 - val_loss: 0.1604\n",
      "Epoch 950/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2379 - val_loss: 0.1585\n",
      "Epoch 951/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1970 - val_loss: 0.1427\n",
      "Epoch 952/1000\n",
      "37/37 [==============================] - 0s 752us/step - loss: 0.2078 - val_loss: 0.1528\n",
      "Epoch 953/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2081 - val_loss: 0.1469\n",
      "Epoch 954/1000\n",
      "37/37 [==============================] - 0s 882us/step - loss: 0.2239 - val_loss: 0.1609\n",
      "Epoch 955/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2134 - val_loss: 0.1601\n",
      "Epoch 956/1000\n",
      "37/37 [==============================] - 0s 826us/step - loss: 0.2031 - val_loss: 0.1639\n",
      "Epoch 957/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2320 - val_loss: 0.1585\n",
      "Epoch 958/1000\n",
      "37/37 [==============================] - 0s 935us/step - loss: 0.2079 - val_loss: 0.1415\n",
      "Epoch 959/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 949us/step - loss: 0.1954 - val_loss: 0.1651\n",
      "Epoch 960/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1951 - val_loss: 0.1391\n",
      "Epoch 961/1000\n",
      "37/37 [==============================] - 0s 684us/step - loss: 0.1994 - val_loss: 0.1640\n",
      "Epoch 962/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2069 - val_loss: 0.1571\n",
      "Epoch 963/1000\n",
      "37/37 [==============================] - 0s 966us/step - loss: 0.2317 - val_loss: 0.1757\n",
      "Epoch 964/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2267 - val_loss: 0.1406\n",
      "Epoch 965/1000\n",
      "37/37 [==============================] - 0s 851us/step - loss: 0.2084 - val_loss: 0.1437\n",
      "Epoch 966/1000\n",
      "37/37 [==============================] - 0s 968us/step - loss: 0.1819 - val_loss: 0.1360\n",
      "Epoch 967/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2345 - val_loss: 0.1564\n",
      "Epoch 968/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2124 - val_loss: 0.1550\n",
      "Epoch 969/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2259 - val_loss: 0.1587\n",
      "Epoch 970/1000\n",
      "37/37 [==============================] - 0s 901us/step - loss: 0.2343 - val_loss: 0.1794\n",
      "Epoch 971/1000\n",
      "37/37 [==============================] - 0s 935us/step - loss: 0.2398 - val_loss: 0.1528\n",
      "Epoch 972/1000\n",
      "37/37 [==============================] - 0s 964us/step - loss: 0.2024 - val_loss: 0.1501\n",
      "Epoch 973/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2236 - val_loss: 0.1607\n",
      "Epoch 974/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2107 - val_loss: 0.1500\n",
      "Epoch 975/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2041 - val_loss: 0.1643\n",
      "Epoch 976/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1973 - val_loss: 0.1423\n",
      "Epoch 977/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.1524\n",
      "Epoch 978/1000\n",
      "37/37 [==============================] - 0s 809us/step - loss: 0.1841 - val_loss: 0.1463\n",
      "Epoch 979/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2213 - val_loss: 0.1656\n",
      "Epoch 980/1000\n",
      "37/37 [==============================] - 0s 826us/step - loss: 0.2868 - val_loss: 0.1983\n",
      "Epoch 981/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2301 - val_loss: 0.1662\n",
      "Epoch 982/1000\n",
      "37/37 [==============================] - 0s 796us/step - loss: 0.2122 - val_loss: 0.1424\n",
      "Epoch 983/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1918 - val_loss: 0.1416\n",
      "Epoch 984/1000\n",
      "37/37 [==============================] - 0s 914us/step - loss: 0.2006 - val_loss: 0.1644\n",
      "Epoch 985/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1855 - val_loss: 0.1653\n",
      "Epoch 986/1000\n",
      "37/37 [==============================] - 0s 902us/step - loss: 0.2137 - val_loss: 0.1549\n",
      "Epoch 987/1000\n",
      "37/37 [==============================] - 0s 901us/step - loss: 0.2061 - val_loss: 0.1575\n",
      "Epoch 988/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2026 - val_loss: 0.1506\n",
      "Epoch 989/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1908 - val_loss: 0.1527\n",
      "Epoch 990/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1955 - val_loss: 0.1494\n",
      "Epoch 991/1000\n",
      "37/37 [==============================] - 0s 921us/step - loss: 0.1972 - val_loss: 0.1487\n",
      "Epoch 992/1000\n",
      "37/37 [==============================] - 0s 901us/step - loss: 0.1945 - val_loss: 0.1396\n",
      "Epoch 993/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1946 - val_loss: 0.1547\n",
      "Epoch 994/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2067 - val_loss: 0.1470\n",
      "Epoch 995/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2175 - val_loss: 0.1554\n",
      "Epoch 996/1000\n",
      "37/37 [==============================] - 0s 894us/step - loss: 0.2094 - val_loss: 0.1600\n",
      "Epoch 997/1000\n",
      "37/37 [==============================] - 0s 905us/step - loss: 0.1772 - val_loss: 0.1365\n",
      "Epoch 998/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.1375\n",
      "Epoch 999/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1762 - val_loss: 0.1383\n",
      "Epoch 1000/1000\n",
      "37/37 [==============================] - 0s 671us/step - loss: 0.1893 - val_loss: 0.1553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea039d7f40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create your df_loss dataframe as well as perform the plotting on how the history of loss changes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718059</td>\n",
       "      <td>0.679798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.718837</td>\n",
       "      <td>0.679083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.691726</td>\n",
       "      <td>0.676655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.681762</td>\n",
       "      <td>0.672290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.693473</td>\n",
       "      <td>0.671273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.278631</td>\n",
       "      <td>0.152485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.299812</td>\n",
       "      <td>0.173758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.314480</td>\n",
       "      <td>0.163088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.298464</td>\n",
       "      <td>0.173832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.265510</td>\n",
       "      <td>0.154427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss\n",
       "0    0.718059  0.679798\n",
       "1    0.718837  0.679083\n",
       "2    0.691726  0.676655\n",
       "3    0.681762  0.672290\n",
       "4    0.693473  0.671273\n",
       "..        ...       ...\n",
       "595  0.278631  0.152485\n",
       "596  0.299812  0.173758\n",
       "597  0.314480  0.163088\n",
       "598  0.298464  0.173832\n",
       "599  0.265510  0.154427\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.730121</td>\n",
       "      <td>0.689429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.713582</td>\n",
       "      <td>0.685280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.681286</td>\n",
       "      <td>0.680207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.699863</td>\n",
       "      <td>0.676180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.676043</td>\n",
       "      <td>0.671243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.209353</td>\n",
       "      <td>0.160007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.177216</td>\n",
       "      <td>0.136477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.169566</td>\n",
       "      <td>0.137550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.176221</td>\n",
       "      <td>0.138335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.189312</td>\n",
       "      <td>0.155275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss\n",
       "0    0.730121  0.689429\n",
       "1    0.713582  0.685280\n",
       "2    0.681286  0.680207\n",
       "3    0.699863  0.676180\n",
       "4    0.676043  0.671243\n",
       "..        ...       ...\n",
       "995  0.209353  0.160007\n",
       "996  0.177216  0.136477\n",
       "997  0.169566  0.137550\n",
       "998  0.176221  0.138335\n",
       "999  0.189312  0.155275\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABRbklEQVR4nO2dd3gU1drAfyebTU8IhITQE3pvAgoogoiADQsqKhbUa0Hs/VqvDXu5VxS7fjawNxBEVEAE6b13Qg0BUkk/3x9ndnd2dzbZwCabDef3PPvszJwzM+cs5J133vMWIaVEo9FoNKFPWLAHoNFoNJrAoAW6RqPR1BG0QNdoNJo6ghboGo1GU0fQAl2j0WjqCOHBunHDhg1lWlpasG6v0Wg0IcmSJUsOSimTrdqCJtDT0tJYvHhxsG6v0Wg0IYkQYoevNm1y0Wg0mjqCFugajUZTR9ACXaPRaOoIQbOhazSaE5OSkhIyMjIoLCwM9lBqNVFRUTRr1gy73e73OVqgazSaGiUjI4P4+HjS0tIQQgR7OLUSKSVZWVlkZGSQnp7u93na5KLRaGqUwsJCkpKStDCvACEESUlJVX6L0QJdo9HUOFqYV86x/EYhJ9BLy8r5acUe1u/LCfZQNBqNplYRcgL96yUZ3PbFMp6dtj7YQ9FoNCFKXFxcsIdQLYScQL+gZ1MAikrKgjwSjUajqV2EnECPsts4o0MK+cWlwR6KRqMJcaSU3HfffXTp0oWuXbsyZcoUAPbu3cvAgQPp0aMHXbp0Ye7cuZSVlXHttdc6+7766qtBHr03frktCiGGA68DNuA9KeVzHu33AVeartkRSJZSHgrgWJ3ER4WzJVMLdI0m1PnPT2tYuyew62GdmiTw+Hmd/er77bffsnz5clasWMHBgwfp06cPAwcO5PPPP2fYsGE8/PDDlJWVUVBQwPLly9m9ezerV68G4MiRIwEddyCoVEMXQtiAicAIoBNwuRCik7mPlPJFKWUPKWUP4CFgdnUJc4C4yHDyCrVA12g0x8dff/3F5Zdfjs1mo1GjRpx++uksWrSIPn368OGHH/LEE0+watUq4uPjadWqFVu3buW2225j+vTpJCQkBHv4XvijofcFNksptwIIISYDI4G1PvpfDnwRmOFZEx9lJ7dIC3SNJtTxV5OuLqSUlscHDhzInDlzmDp1KldddRX33XcfV199NStWrGDGjBlMnDiRL7/8kg8++KCGR1wx/tjQmwK7TPsZxjEvhBAxwHDgm+Mfmm/io8IpLi2nqFQvjGo0mmNn4MCBTJkyhbKyMjIzM5kzZw59+/Zlx44dpKSk8K9//Yvrr7+epUuXcvDgQcrLy7n44ot56qmnWLp0abCH74U/GrqVd7v1Yw3OA+b5MrcIIW4EbgRo0aKFXwO0Ii5SDTuvsJTIONsxX0ej0ZzYXHjhhcyfP5/u3bsjhOCFF14gNTWVjz/+mBdffBG73U5cXBz/93//x+7duxk7dizl5eUATJgwIcij90b4euVwdhCiH/CElHKYsf8QgJTSazZCiO+Ar6SUn1d24969e8tjLXDx7dIM7v5yBQB/3juItIaxx3QdjUZT86xbt46OHTsGexghgdVvJYRYIqXsbdXfH5PLIqCtECJdCBEBjAZ+9OwkhKgHnA78UOVRV5HEGFf2sbmbD1b37TQajSYkqNTkIqUsFUKMB2ag3BY/kFKuEULcbLRPMrpeCPwqpcyvttEapCW5NPLi0nJKysqx20LOpV6j0WgCil9+6FLKacA0j2OTPPY/Aj4K1MAqonmDGOf2Uz+v5amf1/LZDSfTNiWOlISomhiCRqPR1DpCT63Nz8I+72XiKXA7fOV7/9D32VlBGpRGo9EEn9AT6Jt/g9+fZmHLt3j9sm6MHZDm1nwgV1dB0Wg0JyahJ9C7Xwbnvkr0/iWMjNvA4+d1JjzM5Vm5dMfhIA5Oo9FogkfoCXSAHldCZD3442koyqVTE1cI7pZMtSa7NTOPtAenMk97wWg0mhOE0BTo4ZEw4nnYuwK+vo6Px3Rh0piTAHhxxgZmrdvPjDX7AZi17kAwR6rRaEKcinKnb9++nS5dutTgaComNAU6QI/L4ZxXYNNM6v90HcM7pXBKqwYAPPbDGnZkKU29SaL2etFoNCcGfrkt1lp6jwVZBlPvgTXf8vaYkbz/11b++/tmpq/ZB0BpecWRsBqNJoj88iDsWxXYa6Z2hRHP+Wx+4IEHaNmyJePGjQPgiSeeQAjBnDlzOHz4MCUlJTz99NOMHDmySrctLCzklltuYfHixYSHh/PKK68wePBg1qxZw9ixYykuLqa8vJxvvvmGJk2acOmll5KRkUFZWRmPPvool1122XFNG0JZQ3dw0nWQ0hl+fZR65HJW51QAjhSUAFCgszJqNBoTo0ePdhayAPjyyy8ZO3Ys3333HUuXLuWPP/7gnnvu8ZmJ0RcTJ04EYNWqVXzxxRdcc801FBYWMmnSJO644w6WL1/O4sWLadasGdOnT6dJkyasWLGC1atXM3z48IDMLbQ1dICwMLhgIrwzCF5Ip+MNf7g15xe7MjJuO5hPiwYx2MJ0xXGNplZQgSZdXfTs2ZMDBw6wZ88eMjMzqV+/Po0bN+auu+5izpw5hIWFsXv3bvbv309qaqrf1/3rr7+47bbbAOjQoQMtW7Zk48aN9OvXj2eeeYaMjAwuuugi2rZtS9euXbn33nt54IEHOPfccznttNMCMrfQ19ABmvSEM/8DgO3PZ2mZpCJJU+IjKTBK1e3PKWTwS3/y7LR1wRqlRqOpJYwaNYqvv/6aKVOmMHr0aD777DMyMzNZsmQJy5cvp1GjRhQWVi2mxZdGf8UVV/Djjz8SHR3NsGHD+P3332nXrh1Lliyha9euPPTQQzz55JOBmFYdEegAp94Jp9wK2+bw8y29WfboUGIjw8kvKuPnlXt46Ftlp/ty8a6Kr6PRaOo8o0ePZvLkyXz99deMGjWK7OxsUlJSsNvt/PHHH+zYsaPK1xw4cCCfffYZABs3bmTnzp20b9+erVu30qpVK26//XbOP/98Vq5cyZ49e4iJiWHMmDHce++9AcutHvomFzPpA2HBROL3zId2ZxETYaOguIzxny9zdsnVpes0mhOezp07k5ubS9OmTWncuDFXXnkl5513Hr1796ZHjx506NChytccN24cN998M127diU8PJyPPvqIyMhIpkyZwqeffordbic1NZXHHnuMRYsWcd999xEWFobdbuett94KyLwqzYdeXRxPPnSflBbB6z0gqTVc+zOj3vqbxRaRo1uePVvb0TWaIKHzoftPdeRDDx3CI6HvDbB9LhzcbCnMAV76dUMND0yj0Wiqn7ol0AF6jIGwcJj9PEMaF1l2eevPLRwt1vVINRqNf6xatYoePXq4fU4++eRgD8uLumVDB4hvBF0vhRWf8z5fsuWM5znvrzQKPAT46j3Z9ElrEKRBajQnNlJKhAgds2fXrl1Zvnx5jd7zWMzhdU9DBxj5BpyiosBab5/C2iddTvuPnKPsUWt2Z1NQXMqGfblBGaJGc6ISFRVFVlbWMQmsEwUpJVlZWURFVS11Sd1aFPXk7//Br4/AuH/IsLfgQG4RPZol0vaRXygzpQT45Pq+nNY2uXrHotFoACgpKSEjI6PKft4nGlFRUTRr1gy73e52vKJF0bpncjHTbTT89gQs+4Rmw56hWX0VcFTmkd/lj/WZWqBrNDWE3W4nPT092MOok9RNk4uDuGRoOwzWfG/ZPG5Qa9KSYpyZGTUajSaUqdsCHaBlf8jJgLxMr6YLejalQ2oC27VA12g0dYC6L9Cb9FTf31wH+e7Vi5omRtOyYQy7Dh31MsNoNBpNqFH3BXrTXup72xz4/SmQkot7NQMgNjKclg1iKS4rZ/bGA7w6cyPZBSWUlJUDUF4u2Z+jF240Gk1oULe9XBzsXAAfDFPbSW0pv3URZVJit4Xx9+aDXPHeP27drzy5Bc9c2JVXft3Af3/fzD//HkKjBF35SKPRBJ8TJ/TfFy1OgVv+VttZmwgrPIzdpqbesmGsV/cfl+8B4Ne1qi7pwTzriFONRqOpTfgl0IUQw4UQG4QQm4UQD/roM0gIsVwIsUYIMTuwwwwAjTrD5UaVkj2u7IuNE6KICHf/GZo3cHdv1PEPGo0mFKhUoAshbMBEYATQCbhcCNHJo08i8CZwvpSyM3BJ4IcaAFr2A3sszH0ZylQa3bAwQfP60c4uvVvW50Cu0sjLDUleWKLzvmg0mtqPPxp6X2CzlHKrlLIYmAx4Vk+9AvhWSrkTQEp5ILDDDBBR9eC812DHPFj2ifNwWpIyuwzvnMrp7ZI5mFdEflEpDscXzzwwGo1GUxvxR6A3BcxlfjKMY2baAfWFEH8KIZYIIa62upAQ4kYhxGIhxOLMTG+/8Bqh26WQ2BI2zXQeamkI9Eh7GD1b1Aeg8+MznJq5o4ydRqPR1Gb8EehWKdE8rcrhwEnAOcAw4FEhRDuvk6R8R0rZW0rZOzk5iKH2bYbAphmwewkA53RrDEBitJ3eafWd3fZmK5dFraFrNJpQwB+BngE0N+03A/ZY9JkupcyXUh4E5gDdAzPEamDwwxARCwsmAXBSy/r8cOsA7j6rPVF2G69e5j70fC3QNRpNCOCPQF8EtBVCpAshIoDRwI8efX4AThNChAshYoCTgXWBHWoAiW0InUbChmlQchSA7s0TqRetspoN79zYrftRbXLRaDQhQKUCXUpZCowHZqCE9JdSyjVCiJuFEDcbfdYB04GVwELgPSnl6uobdgDofCEU58Hqb7yaoiNsNE10eb4cyi/h0knzeWH6+pocoUaj0VSJEyNS1IqyUnhvCOxbBZdPhnZnuTVfMHEey3cd8Tpt+3Pn1NAANRqNxhsdKWqFLRyu/RkSm8O8172adc1RjUYTapy4Ah0gMh56XgU7/oJD29yaRvdV68AD2+nCFxqNJjQ4sQU6QPfL1ffa790OX9s/jfVPDeelUd1qfkwajUZzDNTtEnT+UK8pxKXCwc1uh4UQRNltziReGo1GU9vR0gogsQUc2WHZZAtzj6t6e/YWfli+uyZGpdFoNFVCC3SA+i19CnSAkT2aOLcn/LKeOyYvr4FBaTQaTdXQAh2gQSvIzoDcfZbNr1zag3O7NbZs02g0mtqCFugA3S5T34vet2y2hQn6pDXw61I3fbKYCybOC9TINBqNxm+0QAdIag0t+qtUAD6Ii3RfP5ZSsnTnYa9+M9bstwxI0mg0mupGC3QH7YfD/tVwZKdlc8P4SLf9z/7ZyUVv/s0fG2pn6neNRnPioQW6g3Yj1PfGGZbNjRLcBfravTkA7DiYX63D0mg0Gn/RAt1BwzaQ1AY2/GLZnJoQ5bZfaKQGmLpqL+XluuioRqMJPlqgm2k/ArbMshTqjtS6Dr5dpnzRF20/zK9rlXdMUakr/8vz09dzOL+4Gger0Wg07miBbua0eyA22dLbRQirwk2K3UcKyT5aws6sAuext/7cwsQ/Nvs8R6PRaAKNFuhmoutDpwtUEemyEq/m3+4+nadGdgbgzI4ptGsUB8DWzDzGf76Uoa/OcesfZbc5t4OVplij0Zw46FwunjTpCYveVd4uSa3dmtqkxNE6OZazuzYmKU4tkl4y6W9mrt3Pgdwir0s58sDc8ukSflm9T+dS12g01YrW0D1pkK6+D2+zbBZCOIU5QPdmiZbCHCD7qNLyf1ltHYGq0Wg0gUQLdE/qGwL904uh1FpQm2nXKN5n24KtWczdlOnczy/StUk1Gk31oU0unsQ1cm0f3g7J7SvsfmGvpggBJ7WsT05hKT+t2MP7fyntfu3eHK56f6Gzb1ZeMbGR+ifXaDTVg9bQPQkLg7NfUtuHt1fa3W4L45LezWmVHEeP5omc2rahz76ZeZVr/BqNRnOsaIFuRaeR6vuw75S6vigqKffZluUh0L9blsGFb+pEXhqNJjDo938rYpPBHuOXhu5JabkS6Gd1aoQtTLgtiB7MK+ZIQTEHcoto1yieu6asAKC8XBIW5tvPXaPRaPxBa+hWCAH1045JoA/rnMotg1rz4iXdue7UdLe2rLwiznvjL87y8FcvNEWYajQazbGiNXRfHKNAt9vCeGB4B8A7/8vBvCJ2HToKQJkp/0thSTkxEcc8Uo1GowH81NCFEMOFEBuEEJuFEA9atA8SQmQLIZYbn8cCP9QaJtEoS3ccEZ5NE6Pd9g+acrss2n7IuV1YojT075ftZmtm3jHfT6PRnNhUqqELIWzARGAokAEsEkL8KKVc69F1rpTy3GoYY3BIag3FeXBoq1fEqL942sUzDh91bo9+Z4Fz+2hJGcWl5dw5ZTlJsREseXTosY1Zo9Gc0PijofcFNkspt0opi4HJwMjqHVYtoMM5IGzw+WXwywNQdmxBQdf2TyMmwsaZHRuxwkcloyEvz+aWT5cAcKhAZ2jUaDTHhj8CvSmwy7SfYRzzpJ8QYoUQ4hchRGerCwkhbhRCLBZCLM7MzLTqUntIaAID74WsTfDPJNi/6pgu8/h5nVjx+FmkJcVU2G/WelX5KNpuc7Ovm+n99G9c++FCDum0vBqNxgJ/BLqVP52nxFkKtJRSdgf+B3xvdSEp5TtSyt5Syt7JyclVGmhQOGWca/sYFkhB5X6x28Lo1bK+X/0Lisu496sVlm0H84r4c0MmvZ6ayerd2cc0Ho1GU3fxR6BnAM1N+82APeYOUsocKWWesT0NsAshfIdMhgrRiTDkcbWdteW4LtUnrQEAtw9pW2nf75bt5pP52yvss84ogafRaDQO/BHoi4C2Qoh0IUQEMBr40dxBCJEqjAoQQoi+xnWzAj3YoHDa3RCXqhZHj4Pk+Eg2Pj2C8YPb0Co5lpsGtqqw/6M/rKmwPayCghsajebEpFKBLqUsBcYDM4B1wJdSyjVCiJuFEDcb3UYBq4UQK4D/AqNlXarokNTmuDV0gIjwMCLCw/j9nkFc0z+t0v79J8xy2stLytxTCviys2s0mhMXvwKLDDPKNI9jk0zbbwBvBHZotYikVrB+WuX9qnLJuMojifZkF/LhvG3cc1Z7Ppnvnlcmp9C7opJGozmx0aH//tCgNRQchJmPQ7nv5FtVITLcxorHzqq037aD+RSWlPHkz+5u/zmFOre6RqNxRwt0f2g1SH3Pew0y1wXssjGRquZo92b1fPbJyit2iyp1kHNUa+gajcYdncvFH5r0gP63w9//hbz90MjSzb7K2G1hfHNLf9qkxPHA1yu5sFdThnVOZWtmHme8PBuA+VuzqBdt9zpXC3SNRuOJ1tD9pdc16jvvQEAve1LL+tSLtjPpqpMY1jkVgESPTF3T17hS8L4+ugctGsTw86q9bNyf63W9LZl5WK1Hr8w4QpHO6qjR1Gm0QPeXuBT1HWCBbkVClO8Xp8SYCC7u1Yzi0nJu+Hgxz05bx/PT1wPw9+aDDHl5Nt8u3e12zo6sfM5/Yx5P/xw4c5FGo6l9aJOLv0TGQ3gU5Fe/QA+3+X7OpiXFcFLL+rz620byi0p5Z47yj+/eLJEXZijBvtkjY+NBo1LSJwt20D41njGntKymkWs0mmCiNXR/EUJp6dkZNXK710f34Jtb+vPBtb2dx9Y9OZyWSbHERYbzr9PSyTLldLn50yVszcwH4K0/t/DTij0sN5KBFZW6PHM+nLetRsav0WhqHq2hV4WWp8L6qVBaBOGR1XqrkT1c+c+eOK8TrZLjiI6wOY818ci17sltXywDYPtz55Bz1N3Fsai0jLzCUpLiqncOGo2mZtEaelXoOgqKsmHTzBq97bUD0hnYzj2ZWeN6FQt0ByVl5W4eMRK4+ZMlnPT0b4EcokajqQVogV4V0k+HmIaw7sfK+1YzKQku7Xrq7af67LfzUAFHjrpMM1sz8/ljg0pdXJHXS3ZBibOSkkajCQ20QK8KtnDlgx6AvC7HS8NYl0Bv3yieZy7sYtlvyMuzWbHLOtVutklzz8orYvpql3tk9yd/5ZoPFgZotBqNpibQAr2qJDaH7F2V96tmGsa7fNXDbWGc27UJZ3RIsew7ddVey+Ord2fz7VK1yHvnlOXc/OkSDuQUOhOB/bNNRaiWlJXz3tyt/Gryh9doNLUPLdCrSmJLFS1aUhjUYcREuK9n14ux88G1fbh7aDvnscWPnOlVqNrMdR8t5u4vV1BSVk5mrnJt3HownwPGNiiXx06PTefpqeu48ZMlAZ6FRqMJJFqgV5XEFup7+9zgjsMH5gIaSbERdGycUOk5H/+9neR4ZcLZfCCPfdmuh1Xvp3+jpEyn6tVoQgEt0KtKu2HQsB1MuQqO7Az2aCwZP7gNQzqkIISgR3Pfib8cPD3VFUH6yPerGfPePz77/r3lIKsydPk7jaY2ov3Qq0p0fbh8MvyvF6z7GfqNq/ycauKffw+xrFx077D2zu3OTZVAT4mPZGinRpzZsRFtG8Vx6vN/uJ2zab8ruvSohXdLhC2M4rJyrnhXCfvtz50TkDloNJrAoTX0YyGpNaR0goXvwMZfIUjFmRolRDlNJb44rU1Dxg9uww/jB/DMhV0Z3CGFJvWiGdqpEQ8M7+Dsty+n4jWB+rHuGR8vmDjPuS2lZPrqfRVWUcovKmVv9tEK76HRaI4PLdCPlbNfUt4un18CGwJbzSiQhNvCuHdYe7dApLAwwbtX9+bcbo3d+l7UsymTxvSyvM7V/dLc9h1pBQB+XLGHmz9dwkd/b2f5riPM3qj83FfsOsI0w8Pmsnfm02/C7wGYkUaj8YUW6MdK2gC4ZyPYY2DJR8EezTFRP9Y9TW+9GDspCVGWfVsnx7L+qeFexwtLynjwm1UAHMgp5IKJ85z+6yMnzmPcZ0sBWL07B1DafFm55GixDlrSaAKNFujHQ2wSnDIONv9WY0m7AklshI3L+zYnvWEsI7qkckGPpiREuUwrtwxqTd/0BoByk4yy27i4VzO3a3wwb5vT5v62kfkRoLjUulRfQXEZd3+5nI6PTQ/0dDSaEx4t0I+XXleBLIdlnwZ7JFVGCMGEi7rxx72DeGvMSXRvnkhCtGud/IHhHbDb1KKrY/E1xpQgTErpzPDoyZeLXcFXDhMMQG5hKT8s3+M8H1SaAUcwk0ajOXa0QD9e6qdB27Ng/ps1UvyiujFr6AD1jepJ4YZgt4W5vGre/HMLuw4VWF7nke9XO7fNKQRyCl3pBopKy5FS0v3JX7lzyvLjHrtGc6KjBXogGPKYysI4/41gj+S4ibLb3PafvqALDwzvQN80ZXoxl7d7ccYGZ3oAB29dab2o6uCwKYd7YUkZBYYtfepKtXg6ffU+Nh/IszxXo9FUjPZDDwSNjMRY815XQUc9xwR3PMdJq4axznzsiTER3DKotbOtMgfNk1slVdh+2TsLnNtjP1rk1X7zpyq9QEV+7lJKNu7Po31qfCWjgfJyyX9+WsO1A9JJbxhbaX+NJpTRGnogEAIGP6K2ZzwMi96DktD1uf793kHccWZby7ZyC5/7q0wl7RrERvD0BV2Islf+X2vZziMs23nEue/px15SVs5zv6wn7cGpZBx2mXamrtrLsNfm+JUsbH9uIR/P31FjicUO5Rez+0jo/ttrQhu/BLoQYrgQYoMQYrMQ4sEK+vURQpQJIUYFboghwun3weVToPAITL0HnkmFjMXBHlXAccjz+EjXy11cVDgfje3DxCuUuWXMKS2d21Vh5lqX0N20P5cHv1nFpNkqVfGSHYcpKSuntKyc7QfVQuySnYed/Q/kFroJfQdFJWqxNdOUcKw66TdhFgOe0/72muBQqUAXQtiAicAIoBNwuRCik49+zwMzAj3IkKH9cBj7i2t/5ZTgjaWacCjR5gpKcZHhDGqfwjmmQKVB7VO46fRWzv3Hz/P6L+PF10t2O7eHvjqHb5a6XEHvmLyctg//wnlvzCMhWi3cZhe4Flj7PjPLK50BQKFRxCMzr2YEepEPd02NpibwR0PvC2yWUm6VUhYDk4GRFv1uA74BQt/V43ho2R/u26LS7K6fBgWHKj8nhLhjSFvO6JDChIu7MnZAms9+tjDBQyM6sv25c9j49AjGDkivsLJSw7hIflu3v9L7r9ub4/Rx/2fbIbdFWiscGvqBnJoR6BpNMPFHoDcFzBUdMoxjToQQTYELgUkVXUgIcaMQYrEQYnFmZmZFXUOb2IZwwZuQsxsWGO6MhXUjQ2FqvSg+uLYPCVF2p096RTlcACLC1X+zzk28Mz+2b6QWNpM8olYrIrdQFb3edjCf1btzKsz+6CijV1MaukYTTPwR6N7p/LydHV4DHpBSVhjPLaV8R0rZW0rZOzk5uaKuoU/aqdBuOMx5EV5qC2/2g/K69TpuM4KNrBZKffHoue6ml69u6cdvd59eaWDR8M6pzu28olLX+Ut2cd4bfzn3PVMKOEwgNWVD12iCiT8CPQNobtpvBuzx6NMbmCyE2A6MAt4UQlwQiAGGNH3/5drO2Q2769Yi6ent1UP5tLYN/T7n+lPT+f2e0537CVF22qTE8dKl3b36vnZZD0Cl7nUENgHkmoKT1u3NcTtnZcYRt32Hhp59tKTCotgaTV3AH4G+CGgrhEgXQkQAowG3svdSynQpZZqUMg34Ghgnpfw+0IMNOVqf4doWNlj7Q/DGUg2c1LIBW549m5NaNqjSeZ7BSwC9WtQnLSkGgEjDRJMQHc6MOwcy5/7BCGEW6KXOPp7VlMx+7uC+SKm1dE1dp1KBLqUsBcajvFfWAV9KKdcIIW4WQtxc3QMMaYSAm/+CMd9A26Gw7sfKzwkxzKkA/MVKoAN8cG0fbj69NU3rq1S/CVF22qfGk1ovys3u98vqfaQkqDzwZm3dQbnJpq8FuuZEwi8/dCnlNCllOyllaynlM8axSVJKr0VQKeW1UsqvAz3QkCW1K7Q5E1oNViXrQjArY6DxFXTUKjmOB0d0wB6m2qNNicAu7d3crW+jeJXmd7+F98qCbVlO75dCU/WlmhTolXnfaDTVgY4UrSlanKy+t80J7jhqAdF2G+d3b8LnN5xs2d6jeSIA8ZGuRGGntm3IPUPbOffbGWH/5gXSj8b2AeCKd/9h0uytrMrIJt/UXpOeLpV5/mg01YHO5VJTpHZTeV7+nACtBkFCk2CPKGgIIfjv5T19tv9nZGcu6d2MFoZN3UG4zaV/NE6IctY5BagXbaddI1dul+enr+d5cKb/hZrV0EvLJeHWliWNptrQGnpNEWaD8/+nTC5/h35Wxuokym6jd5r3Qut1p6ZRz4gSjY6wOYU5wOJHzqRxPe9qS45F0waxEXz893YOmbI9VielWkPXBAEt0GuSFqeo3Olrf1BJUcpKIbdmkkbVBSLDbcy8eyDndG3MJSab+pkdG2G3hbl5wrifF0ZJWTmHC0oY8focPlmwI+BjKywp487Jy5z7pbpghyYIaIFe03S6AHIyYPH78FQSvNweyrw9NTTWpMRHMfHKXk5NHWDilS7zzUdj+9CuUZzbOUWl5c7o0v05RTz6/Wo3T5hAMHPtfr5f7grP8HSn1GhqAi3Qa5r2IyAqUWVkdJC1OWjDqQtEmozVg9qnMG5Qm0rPcQj4QOFIb+BAL4pqgoEW6DVNdCL863fofCEMm6COvTe0zqUFCCYN4yLd9j++ri9velRSOnJU2dJzCktYvP34E6h5CnRdI1UTDLRADwZJreGSj6DPDWq/OBc2THXvk7kBfrpDm2MqYOZdA/n1roFex83+6wDdmtbj7K6N2TbhbJ4c2RmAI0bq3TsnL2fUpPlutU6PhUib+5+SXhTVBAMt0INJeAQ8mgVxqbDyS/e2L6+GJR/B7qVBGVoo0LZRvJurooNeLRJ5wpR/vb6RyVEIQecmCQAcOaoE+IZ9ucDxp9f1lN96UVQTDLQferCxhavCGCu/gi1/KE8YezRkqUo97FnqCkrS+IUQgmsHpHN6+xT2ZRe6tdWLVsL9SIEyucRHqT+B/TmFtElxX0ytCqUeJjOtoWuCgdbQawP9xoMIg08ugGebwrPNoNwwAayte/lfaor0hrH0a+1etDoxRnnHOEwuCVFqf9Y6VZeltKzcMmw/t7CEt2dvcWreZeWS39bud9rKSz28Wjz3NZqaQAv02kDDtnDrP5DUBmSZsqkDtB0GO/+GvSuDO746RGK0nTChokYXbz/EQmNB9IN521i47RBtHv6F56avd/ZfuO0Qmw/kcu9XK5jwy3pu/GQJpWXlLN15mBv+bzG3fa58zz019BK9yK0JAlqg1xbqNYUb/4TWQ1zHhk+AMHudrE0aLMJtYTSuF03G4QJGTZrv1nbp22r/nTlb3Y6d+cocZqxR5fF+X3+Ab5ftduaImb5GBYZ5+p1rDV0TDLRAr01ExsNV38IjB+C+rcobJu1U2Pybq8/2v2DfquCNsQ7QrH40GYeP+myXEh75fpXPhc3sghKvYtDeNnStoWtqHi3QayPhkRBr2H5bD4bM9bB7CexcAB+dA5N8F1vWVE7zBjFsz8qvsM+nC3ayek+OZVtxWbm3QPfQyMd/vgyNpqbRAr220/MqiG8M754BHwxzHf9f7zpTeLqm6dWiPgfzKk/S9crMjc7tSFPgUPbREopK3MvZeXq11FQSMM3x8fgPq3nBtGYS6miBXtuJaQAnjXXtn/UM2CIgaxNsnhW8cYUwl/dt7rPt/uHtndtzNmY6t5sZVZQADuQUWmjox29iOVJQ7FaQI5Bov3hrPp6/gzf/3MK7c7ZSUlbuVZM21NACPRQYcAcMvE9VPep1Fdxn+Kh/PRaKC4I7thDEV1bG+KhwzuiQYtkWF+VKBjZ7Yyb7c1z+7QXFpU43SDNVrVrU48mZjHnvnyqd4w9bM/No8/Av/LjCs7Z7YNmbfZS0B6fy/bLd1XqfQGH+93lm2jpu+XQp578xjyEv/8lzv4Sm1q4Feihgj4IzHoGrv4eoehCVAE2M3CRbZqkgpA3TYcf8Ci+jsSYpNoIPr+3DtNtPIzXBO6c6QAdTROrhghKW7Tzi3B/6yhxeNplnHBSXlbNo+6Eqad2LdxzmcIDNNV8s3AnA/C0HA3pdTzbtzwPgqyW7qvU+gcLzLcvxRrYlM59Js7cEY0jHjRboocrYXyAsHP55G/7XC764DD4croW6nwwxNPEXRnXjm1v6M7hDCs0bxLil5XXQu2V9HjuvEz/fdiqTxqgH6d5sl5fM7iPWHjMrM7K5ZNJ8L22voLiUrZl5bsfM2Rl7PjWTzQfc263YmeXf25mjTF94WNX/3KWUPufniaNgeCAyTZaVy2rPWFlU4i7Qiz3MUqFYF1YL9FDFHgXJHWD7XPfjX18HE0+GH2+DYsOTY+4r8MHwmh9jLWbilb34895BXNq7OWkNY53HhRBcdUpL5/64Qa2ZclM/YiPD6dK0Hr1a1gesi1M7SDJyx6zYdQSAHR4eNQ9+s4ozXp7N1JV7naabox5a/C+r9lY4/rmbMhn44h9+mVEKitW1HflrqsIXC3cx4LnfnXOpCIchKxAem63/PY1Rk/4+/gtVgOdv7klNliwMFFqghzL9b1PfV36jPpH1IHePcnNc+n/wYlvVvusf2DkfcioWEicSUXabmyA348jICHD/8A5OzRMg0cgFYy5O7UmY0f+FGRsAlc53a2Ye0wwhvXavcoe89fOlXPSmElpHi92Fy2ZDgx/y8p/c/oW3C+S2g+ohsXBbls9xOHBc25G/xpO8olL+9mGOmb9VXb8yN09wCcgyKSkqLSP7GB4gZsxmreqgMoF+wEKg78sudHs7qyqH84urNbWyFuihTPfRcPd6aHum+lwxWZW4a2u4N5bkQ8lRyDYWqXZqc4w/+Fo0BZX3PC6y4px2NuP8YsNGe7SkjHP++xfjPluKlJL2Jnu8w5zhKdAPG4usWzLzLbXwmAg1hoKiyu3zDsFltXALcN9XK7ji3X+8EpmByzvG/FCr7D5l5ZJLJ82n+39+rfScYPJ1JbZ+q9/rlAmz6Dfh92O6X3m5pOdTM7n/6+pL5aEFeqiT0Ni13bI/XPkVXD7ZlULgjb6q5B0or5h1P6lappoKaRgXwWW9rd0bHQm+fOEp/A4XFDuF3Z8bM5lqYU4pKHH/N8nMLWLhNt+FN6Ls6k83v7jyf0vHouxhHxq6440hr8hbgDn868P9EejGQ2n5riOsyFAxErXZDj3xj4oXPo/3DcOTLGOx+7tq9ALyS6ALIYYLITYIITYLIR60aB8phFgphFguhFgshNChjMEkLAxGvqG2s3fC0cOuth9vV7VMn6gHW2cHZ3whwOJHhvL8qG6WbQ0MG7kvPAV6limIaeyHi7z6f7Fwp9PO7WDd3hxnbhmAb5Zk8MrMjc787Y4FQ8/zrHA8TLLyii0XGh1vFPkW2r6jv82PBVUrE0ZhibV5obxcOoX9pwt2kPbg1ArNWIHGH7/8QAt0s6trdVHpv5IQwgZMBEYAnYDLhRCdPLrNArpLKXsA1wHvBXicmqqS0ATuWgv1WkB4FPS9SR0/atL6vrvZ+7zMDVBUuYfFiUxakrXtHcBuE1zbP83t2HpDCPvioW9Xsf1gxTbqe75awX9nbWLYa3MAl8udlRA8lF/M6t3ZXPzW36zYdcSpOR8tKWORRbk9h4XJqs6qQ0P3x+PE02wEvoViq39P47Ef1gDworHWcCivmH3ZhUyYtq7Se0kp3bT/AzmFpD041W9f+wLTw+eHWwdwWtuGfo/9WKkVAh3oC2yWUm6VUhYDk4GR5g5Syjzp+nVjgdr7nnUiUa8p3LUKHt4HZ78AY6e7t5cbf8A7/4EfxsP3t8LEvjDzsZofawjRsbGqepRkoalveuZsLj6pmXO/Mnu7g7u/XFGlMTgEupUN/fQX/uDc//3Fkh2HeenXDRwtLmN451QAvlqc4SV4wwyJblWGr8xwWfF06bPCSkM/clQtApqFo8N75JMFOwCX4CwoKeXh71bxtinbpS/Oe+MvTnvhD+f+rsPKhfO9uZWfC+6/W5TdRrmFacgxrpzCEl6Yvv64o3gr8owKFP4I9KaAefUgwzjmhhDiQiHEemAqSkv3Qghxo2GSWZyZmWnVRVMdOFSwlv3g8ilqIfXUuyD/ACx8Fz44C5Z9Ass/Vf3W/6xSDgIs+RhWfQ3b58FL7eCHW4Mzh1pE92b1AGiZFMO/z+7g1V4v2s6kMScB0K5RnLMqkj9MufEUrj81vcI+hSVlzgVXKxt6rklrn7vpIHuyC0mOV4Wzv1mawZ1TXF4z/SfMYpPh857joZFKKZ1Jxw7lVS6MzA+KFg1iALWweMfkZXT/z69OrbrPM79Znp9fVGb5lmDF6t05lhkzD/rpamj+3aLtNst0xw6BPmHaOt78cwszjFTJVeX56etJe3AqB3JdGnp5NfnY+yPQrVZDvEYjpfxOStkBuAB4yupCUsp3pJS9pZS9k5OTqzRQTYBoP1wtpA64Q+WEmXave/vINyFvP/x0u9Lcf7odvrkePjpbHV/2aXDGXYvo1zqJz244mdcu68mQjo0s+ySYhLiVJu+LZg1iuGVQa+49q53PPhmHCygqVcKzoLiMqSv3VuoK51hEBfh7i3JFzC8qZY/Js+W56evdzBg9n5rJP8bC7BM/rWVVhnUyuNzCEq75YCErTHlQUowHSPbREqatUoIwp7DUKzrTfL/8olIvTdlK8JnNPw5XTMdawkFj4XH+lizemeO+6Ll81xEm/KLMOe4aepilSWnbQfWgW7xdrUFVZuNfvy/H8jpv/anGcdD0UCyoppw9/gj0DMC83N8M8GmoklLOAVoLIbyNUpraQ3R9uGMlpJ3mfrztWep76f8pzd2Kn+6o3rHVcoQQDGjTkBZJMbROjmP7c+d49YkwsjNKKl5E/W5cfzeBHx8VTsO4SMaf0dbnOUt3HGHXIWViOJRfzK2fL3UrymFFtN3m3M4tLOWOycu8/KmPFJS4RYV6uu2t3est0Dfsy+XTBTuZvTGTBVtd9vkSQ7AdKSh23ntfdqGXuSf9oWnO7fyiUso8BHphqbfg22eyRfd4cqZxrurneHO5/N0FPDvNPUL3yncX8PbsreQVlbpr6BE2r2yZp7dLZsHWQ1z81t9sMWICdh1y/TaegnvzgTyGvzaXV40UEFJKXp250S2obM8RU/6faloA9kegLwLaCiHShRARwGjArdClEKKNMJx3hRC9gAig8ogHTXBJaAzX/gyPHYJGXeGclyEuGYY+Be1MkaUn36I09zZnqv0lH0GZ8ce+/HOttVvg8GW3h4URGW7z2S/KbuPLm/sxblBr5t4/2FnjtCLu/2YlXyx096GuLA1AVIT7GH5YvseZe8VMRWl/rfzzh702h+dN6WcdawaD2iUTJmD34aPUN9w892QfrTCYJ6+olL1H3BcOrbx49nikIpgwbZ1T8wbc3lbMdm/HQ3ZfdiEFhkB//5rexEfZuX94e1IToujaVJnTuhlmtSU7DuOQ3Q47ved1Aac5Ze5mFaCVmVfE67M2cfqLf1qOO98P76RjoVLjnpSyVAgxHpgB2IAPpJRrhBA3G+2TgIuBq4UQJcBR4DJZmx1QNe6E2eCWv1z7A25Xn5JCVVgjbYA63vNKVbT6y6tU9GnLAfD9Laqt00hVcWnZZ5C3D067p+bnEUTuGNLWzYuhe7N6jDmlBTee1pp/f6cqTL0+ugfxUeE0rx/D0FeVt0q0EbF6/3BvW/yse04nPiqcvs9UniZ5yuJdtEqOpZ0paMlM/Rjvt4TVe1wad2yEjfziMqevtNUCKRK+XpLBhT2bWgYajRvUmqv7pZFXVEJaUizfL9/NloP5JMZEsCe7kL1HCp22dStW7c52077BMI3EuffzNH14LqJuMHkVqbeObOZsPEhCtJ3DBSXszyl0Pigc4+nfuiEL/j2EG/9vMat2Z1v+XhmH3AX6rPUHGNElFbstjGzjbabQuG6exVrAbpPNP7+aNHS/VmuklNOAaR7HJpm2nweeD+zQNEHHHuUS5g5aD1a291lPKc8ZBxOawcXvww/j1P7Jt0CE7z/eusZdQ91t3uG2MJ6+oCsAT13QhQ37chjepbHXeVF239p762QlyRrGRfhVkGNCBSlfT2/nvWZlDqwZ3bcF7/+1zekz3+0J7yjPr5dksHD7IfKLSrmmf5qbn3xEeBj3DWtvaPEqY2WrhrFsOZDnFI47DxU4NV8rJi/0jtw8mF9EiyT3/0eVCcNz/+dSTg4XFHPxW2qcXZoq76R92YVOk0mMhxfShIu60iE1nrO7NubJn9e6te0yCeRpq/fx6PerGd2nObcMau20jztMRFb29tyiUpJiI8jKL6407cCxoiNFNVUjMh66XQq7FsDbA93bvrnetf1sYxWVWnIUplx1QmeBTG8Y6yXMHQpudAUC3UHDuMjjuv89Q9vRJDG6wj6X9VHLZFMW7eRZkx+4ueDHQsOHfY2h2ZsjWVPiI71MMi2TYtl9+KjTBLIlM8+nILOFCYrLyhncPpmmprFa+ec7BPrIHk0qnBO4R8c6kobtyyl02tBjPUxRSXGR3H1We691j8jwMDdz1BFje/KiXZz+4p9Ol0SHKcbhrfP+Nb3druP0TgqiDV2jcWfkROh7I9hjlKnl0SxIMhbxwkwaz8zHVKm8dT+q1L5rf4A9utYmuOzRkfbK/wQdLocAtw5u7aZtPzSiA1NuPIXzulsLt5sGtuK2Ib4XWAHm3j+YtinqbWDR9sNuC6wp8d754XcdOuoV0m/lyVM/JoLcolKncNu4P9cy+KhVw1jn9fqmJ7mZc7ZmWgl0dY1uzRK92j65vq/b/uF8l+nIIZBfnLGB12dtwm4TPuMEIkwlByffeIpbbIEV7xj+7w5Ti2POqfWi+OFW11tuxybqLcGfCN9jQQt0zbFx9ovw8F4Y9RHYwuG0u9XxMd9A+7PV9qGtrjwyAF9eDe8MUnZ4B/vXutL8nkC8f01vzuiQ4lar1Bcje6iwj+l3nsZ9wzrw8XUuoXXT6a05uVUSvY20vma6N0/kobM7OvfjfQiv5g1ifCYki4v0foNYsC2LxTsOux2zWvhtEKsWQx128R1ZBXyzNMOtz1tX9uL78QOcwU2tk2PdBPo2iyyPDu22ST31sDG7ZLZJcTe4Z+W7XAXN9vkjBSWkN4wl3Fb5739KqyQu7OkeeuMZReqKCyijtKycXGMNIiHKTqzpN3z6gi5ucwg0WqBrjg9Hjo8eV8AD26HVILjsUzjtXqifDtf9CjfNgfpproRhG4zlmKI8eKsfvO/DPbIOM6h9Ch9c26fCzI4ORp3UjKWPDqVDaoLPPlaFOTyv/MP4AV59OqS6FlHfu7q3V7sjq6MZKeGvTe7pdsNt3vNINGzn2UdLnOYRz4RjfdMbkBBl5yTjgZTe0F2gH8gpZNa6/RwtLmPiH5spLi0nr7iUCFsY0Ya5pFvTRNd47e7j/c9P7nZwM441Cl+8ell358MzJd7d7HXIItGZI49+bmGp04YeFxnu9hs6TDnVpaH7H8Km0VRGtKElhtlgyKPq4+AOI7R98pWw4gv1cbB/Nfz1mgp28kPAnYhUlhDMkYM9TEBqQhR7sgu9fspWyXFE2cMoLCnnx/EDKCwpp1WyKy9NjIU2Hubj32PXIXc3SbuFpmsec1xkOI3rRbHXFMh0bf80koz1gYlX9uLnFXtokxLnTBYGygS0aPtizuzYiN/W7ScmwkZBURmxkTZ6pzVgaKdGPHZuJ35csYcdWfleJqyKctA4Ujj44sKeLjNLksc6hlWq4e7NE/lkwQ6yj5Y4TS5xUeFuv2GsI+2xFuiaOkGnkSq1gJmoevDb4xDbUNniE5ur5GIan3w4to+bHbuNoW0+ObIL7VPjuWTSfMsQb0eIe2xkON2auWuoVtq4pzwf0iGFWesPsNMQ6I+d24knf15rKdDNaYaj7Tbqx0R4CXQHDeMiuXaASnngeDg5PEJARceCinKduXY/oB4S7xpvFbcObgNYp+vtm97AMhXxMCO/jT94Lp7uMPn9t06O5fpTW5FovCUt2XGYIwUlRNnDsNvCiDWeBaNOakaUPQwhcPrBBxot0DU1S5dRkLUZZj8PXS+BjudBh3Nh0mnw9xuQuQ7im8A9hqfF1tlKwDdo5X0tKU9YjX5w+xS3/U5NEpj/0BmkJkSxyAhVtzLnOCIirRYDPYVW6+RY+rVKcjv2/Khu9H76N6dAdwjtiHDve5k19Ci7jaQ4D88RHwvCjmdDcnykU6A7Enp5mno8sZpz6+RYVu/OdtOK7zyzLe1TrX32K7tueJhwi6gd0aUxV5zcwvnQuOerFc7xg3JhXfLImSRE2xFCcHbXxqT7qJZ1vGgbuqZmCQuDwf9W9vYL31Yae5gNul2ihDmoMnqbZ8H8ifB/58MXV3hfZ8Mv8J9EFfikAaBxvWiEEM6KSOMGtfbZN9ZCoHv6ZN81tB1hYYJVT7jWOBwmgwO5RcRHhTufp1YaeqP4KGcis4LiMq9gnQgfC5KO3OtmZdsh2I/Ff7tJvWive99SwW9TGZ5upA63TM91DPMidFJcpPM3mnhFLy7qVbHXzLGiBbomOETXV4LcQa9rICIe7Ibm8ulFMOPfajtzHexeqiotlRTCxl/hi9Gqbets2DbX/a//BKdejJ3tz51jmTjMYTeOsfB/9zzm8JGPN6UjMHuUIF2ug+dbuE2GhQkmXKSKhDSMj/DKBx7pwwffsb5aUcKx+Q+d4bPNkx4tEp1vJP86LZ3vxvWvMB2DLyZe0Ys3r+xFSoK7QHc8ZFIT3F08q5JlM1Bok4umdhDTQC2cRtVT/uu7l0CTHqpu6ofnwLuDrc/b8AvM+g/0vg66XwHN+7i3F+XBhKYw6kPoclG1T6O289kNJ7MlM89ppzbjuShqFcVqNj0kJ0TSOjmObRPO9umt06lJArPvG0TjetG0S4knOsLGgZwi1u7NqUBDV9e648y2zFy7n+yjJcw1mVoa14uicb2KA6VAmVq2ZOZzcnqS042wU5MEerbwdvH0h3O6qeCwmWv3s9KUebLEWJeoF2Nn4cNDuO+rlczemEmcFuiaE5pYw147/Fn34xdOUjljii0qKWUYJd0Wf6A+d65WNncHuUb9zl8f1QIdZdduENvAss1TwJpF9ISLunqZaRxujpW5XrY0Kjyd2akRZ3ZqxJGCYiXQffjgO7xCkuMjeeOKXuzIyufxH9fw9+YsisvKvVwIffHWmJNoEBtBRHgYRwy/8VYNK3ZV9IeLejV11gUd3ac5dw11BW6lxEfRvXkiszdm+hUFHGi0yUVT++l0Pty/DR7YAX1uUMdSuxqNHqaW17rAXlP1n1LjNf+ot5eDxh1PwWz+ZS/v28LLrNKs/rHl6kmMiaB/a9/ZtR0+7Y5Q/ZZJsXw0ti/X9Fd+3ikJ3tGrlveJtjvt3Y6HRHry8S9GDjCN/bmLu3lF0zoWQ4stimZUN1pD14QG4RHq40gx0O822PwbrPrSu++qr6Bxd7XtqI9aUgDlZe52e02FVGYD9qVhHy8O4euZG92x6Fg/pvIUw+CeMvjzf53Mnxsy/UpPXOn4wgTfjevvswB2suHNU1RNCbgqQgt0TWjR5wblo97xPGVvdwj0k65VedpB5Yw541EIj3Q30yz/DHpdXdMjDinmP3QG4WFhLNt52DJXSk3QvlE8czcddPp1O3DY9P01ZZj7dWuWGND5VGSHdwQhFZb6XtStLrRA14QWtnBlggFoO1R9J7aE815Xn42/wueXqMIbTXpAkSs3NhmLtECvBMdi41kVBN18fF3faquJCXD/8A4Map9C9+aJbscd5esqSjlsxsqVsiZwPEi0hq7RVIUwm/JnN7+atz4DwqPg5zvVfqKyu1I/Xbk+ao4bq9zqgSQiPIxT2/q2sQfDHbAqtGsUz5kdU7hjiO+6sNWFXhTVhDbR9ZXLowNbODQ0pYs9skN9txmicsaYMz1qQopr+6cxdkAaY40UAb7o4aHZ1zQR4WG8d00fulZQzKO60AJdU/foMkrZ18962nXszP+ob52PPWSJjQzn8fM6W0a5mpl84ymsePzEy+AJWqBr6iKn3gkP7oR+413HIuNUjpi8/UEblqZmiLLbLNMJnwhoga6pu3gGvMQ3gtx9wRmLRlMD1O7VBY3meLn5L8gyiiHHpUJ2RsX9NZoQRmvomrpNalfofIHajm8EObuh4FDgk3mVlagcNAU6IlUTPLRA15w4tBygUgC8kK5ywwSSTTNh3uvwWjdY8FZgr63R+IkW6JoTh84XucrkrfgCPrkI/v6ff+dKCUd2+m4PNxJGFefC9AePb5wazTGiBbrmxMEWDuOXwIgX1P6WWfDrI3BgvctUUlpsbWdf+jG81tV3cJKnCae0yLqfRlON+CXQhRDDhRAbhBCbhRBe6ocQ4kohxErj87cQonvgh6rRBIDYJOh9vfuxN0+GF1rBJxfC08nwamfIO+DeZ51RB9XXomqJe9FkvfgaIuTug4Xv1pkCKZUKdCGEDZgIjAA6AZcLITp5dNsGnC6l7AY8BbwT6IFqNAHDFg7N+noclLDld9fu/tWw6TeVE+bwdsjPVMdLjmKJp0D/X69AjVZTncx8HKbdC++dqbJxhjj+uC32BTZLKbcCCCEmAyOBtY4OUsq/Tf0XANVTME+jCRRXfQvb5sBki3qloLR1M3FGObcCH0WKPQU6BKaIdcZiFfVqTmegCRw2QwTuXgwHN6pMnlE1H7IfKPwxuTQFdpn2M4xjvrge+MWqQQhxoxBisRBicWZmpv+j1GgCTWQ8tB3m2m96ErQ9C04Zp5J7eeKIMM03/b81Z3IsthDoBVnHP873hsAbvY//OhprzG9cvz4Kz7WAQ9uCN57jxB8N3UrFsDQ4CSEGowT6qVbtUsp3MMwxvXv3rhtGK03oYguHG/9UGRnNCb66XQqzX4AN07zPyTc09L0r4O2BcNF70O0Sl2AY8jjEpyq3yOxdEOs7a6CmFpC7Hxp1USa2zTPVsb3LoUHFCcBqK/5o6BmAqUgjzYA9np2EEN2A94CRUsoAqCYaTQ3QpKe7MHccu/wLOGms2hdhKi9Mo64qe+Oa72HXQtU260n1XZIPYXY47W5o1FkdC2FN74Qhbz8ktVFRxA52LQrZADF/BPoioK0QIl0IEQGMBtxykAohWgDfAldJKTcGfpgaTRA462kYOREeOwTDnoH0gcru/tU1MOcl1afYMLuUHAW7UWOzYXuITVFFq63441l4pnGd8awIafL2q/URZ41aYMFEFXyW72O95FgoLqiRB3ylAl1KWQqMB2YA64AvpZRrhBA3CyFuNro9BiQBbwohlgshFlfbiDWamiIyDnqOcS1sdjzX1ZZnJPk6elhpc8X5EGEIdHuUMttkLHJVOnYgJcx+Xi2iWi2kVoWSQv/7lpdXrf/xIKUqB3gsWm5Rbs358BcXQFGOSgnRuJt3+7Y5gbvXl1fDf3tU+0PcLz90KeU0KWU7KWVrKeUzxrFJUspJxvYNUsr6Usoexkev4mjqHk1Pct9vf476ztpiaOjRrrak1lBaCDvmwS8PwPNpKmjpP4muPoU56vvz0bDqa+/7VfTHv2shPNMItvzh39i/vUH1rwm2zIKf7oDfn668rycTmsGHZx//GA6sU7VlK8Kx0B2XCq0Ge7dnLDr+cThw2Od9ub0GCB0pqtH4S3ikWkADSGgKI55T2zvnK+EQEefq26CV+v74XPhnktLkc3a7X++VDirydOMv8I1HsBNAWbFr21O475invjf/Vvm4y0ph9Tdquzi/8v7Hy7a5xsYxaqO7/XjBf3sgvNzRd/ubpyituCKcAr0RpJ0K/W+DVENTj6wHu/7xb7xVoZp/f50+V6OpCrfMUyYBKZWAD4+GmY+qtnYjXP2SO3ife9BieeldC83Qgdn0UFoItkgIc+hgfvq3F+YoDw4HufvU20N1UHBIzefwdrXvr/AqLVIadYpnvGIF7F1R5eF54ciNH99ImdXOeloFFx1Yq96Y5r0GeZkQF4AaqmHhUF6qHuwRsS7zXIDRGrpGU1XCI5WdXAjod6vreD1TeEZ8Ktyxwt17wiFYW5/h333MAv39ofDO6a59h12/MpvsB8PhQ9ODxjOlQSDZ+qdLmAPkeDnDWTP1bjW3zHWuY4GK2iwt9t1mNrk4CLOpBdJ2w9X+b49Dzl6VyO14frswQ3ee2AeebazSLVcDWqBrNMfDkEdd9UqFx59T/TS1sOrAYSc/4xHv6wibEj5SwoyH4dOLoTDb1b5vFexbCZkb1L40FlsLslTY+sFN1uM7sMZ937GY6y+lxcoW7c9i3s757vv+VodymGgO76j6uZUJxuI83215+9XvHpPk3dayHzQ/RT2El3+m1gXmvuzfmKwI8zCGVJNbpBboGs3x4ghCiU/1brvsU+jzL7V9YK1yaUywCLSWZSr/y/96wfw3lG189nPe/Y4YQdtFhqBaP1Ut3v3+lH9jrWoJvrkvK1v0pl8r7+uZXjh3b+XnFGYr335QgVjO40d8n1NW6to+erji61dk9sndD3EpJjOWBw3SlWnH8dtmrq/4Xmbm/Rfe7OfaFzb39kBEEVugBbpGc7x0PB9GfQj9b/duS+kIJ13r2r9ptnuukIH3u7azd8Ghra79VV95Xy/feO0vMjxkHH7wBzdD9m7v/mbsMS6zz4758O1NSjjmG8Kl4JDynXdo4wWHXA8VK/u/J55CqjivYjNFwSF40ZSjxmyucXgAWWEW9uZ7Wr1FVCTQ8/a5cvRYEZficd9s635Swrqf3NM/zHxUPcAdD58wLdA1mtBACOhyEdh8VJqPTnRt26NVrphul8FV38EZD0OfG1Rb+7NVDdTmp/i+V36mSve60COh6YE18GonZXvOWGLtBpk+ULk7LvsUPhwOKyfDdzfBi61g6r0qmObnu1zC25z64NdHvG3i+9e6C9GCLLUw3PwUFVkL8FIFScU+vQjKTOsEjtqvoDxMfKUgNpsrHG8ceZnKJdRz3pVq6BUIdPObAMDRI67t2S/Cd0bVq4ObYMoY+OIy72s47PRaoGs0dYS4VOhwLlw3Q+0LARe941ocddiOO56vFuRGeUSYmm3z+Zkq3asvdvwNc1+CH8Z7B+i06KeE9Q+mhdzVhgBc9K7rmCPgySHAGhvlDbI2u/psngVv9YNf7lea6bc3qbeLxOZw/QzXoiKoB4HVIueeZe77ZjfB3x5XeemfTvU2Ex01CfRPLlA2eMebjWe1KF829B9vh/2rvLVwM/U8TGMFh9RvuuAt+ONpWPG5EvoOoW0ViJS7Tz2oPOevBbpGE6LYwmH0Z9DCh+adZuSya224MHrmlokxJfgymzAi4lSKAbOXxoG1SmMsPeoddNT2LP/G67BLF2Sp/DTnv2EcP+Lq49CmF74DP45X2j64FhjNmu8rHb0FrZXtuzgPEjwyb5ce9RaUnguKs5+HGf9W2/mZsM/kpmnW0EsKVcRsWSks/T+wRaiIXl+cfDOM/sK1X5StzjPPZf8qd+HsNLEYb2v7Vqh1kaMeY9YCXaOpo/S/HR7Y4VpUNUecAox4HtoMVcnBVk5xHW8/Au7bBPdugAd3Kp/4rM1w2MgZYrbBRyUqe35EfOXjKTikTBdLP1YC2lGH1SyEwyNc285AIlyph5NaQ2SC67iniciXH7nj4WbG0zbuEI5dRqnv7XPdg5EmDXBtOwR6WamKlJ35qGGDl8rvPH2g9ThAmUk6nA3Dn4dmfdQxz/w8e5a758jP26/uWW543/zztnv/Bq2Vv72jBm2A0QJdowk2YWHudnZPElvCmK/hvNfcj0eZzomqB4ktlDZbbmiJq0325P7jlamnQZr39Yc/B/ebEkcdPawiVwuylPB0CPSN02HjDLWIanYXNAs0R0BVmA3O9yjAvW+Va3vvSuu5Wr3FLPvEVQIQXBr6ea9BfY80t5657B2Lxo6H0fw3YL/hymnlrmjFKTe71gQOrHVv27fKtagMyrxkTl1g9oyJrg9jp8G4+TDgDv/uXUW0QNdoaiN3robLPlPmFEdkZ7PeLk0RvLW8+i1dAiTdFIQ0fgmcZtjdHQKw5xi4fIpawOx9nTLz3GL4kZu9TcqKVWSjCFOLpJ9fCm+f5vKyAZdP/D0boZ2paIhn5Z/pD8GSj5UQzNrsSpXQ/hyXK6dVkqztc2HKlbB7CTxRT+2H2dX5joeNg+YepQUzNyozi9nE8X/nq2/Pcysi0ZRBvIMpSdv+Ne7X3vWPyqduRbvh1q6tAUSH/ms0tZHE5upjzvAIcPWPMO915U7oaZppf7bLX/zsl1RUIqgAJ0dkacN26juhGbQfrj4OGnVSJpn5b7iONe6uznUIbVA5acz2dFC5T+I9PEbMbx2tBsPWP5QwdtCgNfxrjXKnPLwdFr4NqRXUl19hmJs2/aps9EKoIK2tf8Lf/zXm197d5v7PW+pjhb8aOkATo0asCIPGPWC98caQtVk98Bq0Ut8zH3Od0+ZM9SkpUHnzHYun1YgW6BpNKBERA6fcogTgKePc23qOgZ/vVNvJ7aD39Uobtpn+zAfcrmzpvtIPRCe6zBSjPnAv0wdKmO1d7u2XHmshHM0moV5XKYFuJr6xS+gnt4NzjEjMW+ar1Ar/7ene3ywQo42F4zZD1Ce+MRzaot5S/MVz8bkihIC7jdQE5rWJgoMqivT0B9SYpj/gaivMUf9Wu4ysjbnVL9C1yUWjCTWiE+Git70Fks0ON82FMUZmxXNfgRtmuveJqgddR/kWZmatP7W7K3VB7+vUA2PYs2p/21xV6eciw93RbApy4PB0OfUu6HwRnPGoe7unRu+gUSdXtkoza793bSc0cW/rN049EOqZvGRa9IN/73VP+jV+sUpyBlXT0B33TGiiFmMTmrrPp++NkNrFtZ/aFc59VW0ntlDfjgdlNaI1dI2mLmFlg64KDrv80CehYRvXcYdwckRDluQrd8rOFypXwZ5jvK8VEQOPZLo8Ygbeq8w//7wNGQuVVu0PrYcoLdhMq9Ot+5rfCtoOVWMYN1/Z3kEJ/HvWKx/4iFj/7u9JvaZw91oVnfv7U9D3JlU71mb67a/5yWWjj0tRD7UuFx/b/aqAFugajcbF2S/Bz3crjdyKiBhl+z60RZXls9ndM056YnZvBPV2UJSrBHqPKyoeyx0rlH09LkWV7cvbryohgbJNW9G8r7J3D37Y3ax0wVvKh9werT5thlR8b39o2AbuWut6W4gyuWmaHyxCwJlPHP/9/EDIINU17N27t1y8WFeq02hCjiO7VDKx+mnHfo3SYm9h7w8OTfvxI66F3trEtrnK06jvv6rtFkKIJb6qwmkNXaPRVA2zC9+xcizCHODST9TDpDYKc4D009QnSGiBrtFoQodO5wd7BLUa7eWi0Wg0dQQt0DUajaaOoAW6RqPR1BG0QNdoNJo6gl8CXQgxXAixQQixWQjxoEV7ByHEfCFEkRCiguz7Go1Go6kuKvVyEULYgInAUCADWCSE+FFKac4jeQi4HbigOgap0Wg0msrxR0PvC2yWUm6VUhYDk4GR5g5SygNSykVAidUFNBqNRlP9+CPQmwK7TPsZxrEqI4S4UQixWAixODMz81guodFoNBof+BNYZBWSdUz5AqSU7wDvAAghMoUQO47lOkBD4GClvUIDPZfaiZ5L7aOuzAOOby4+cwT7I9AzAHOsbzNgzzEOxImUMvlYzxVCLPaVyyDU0HOpnei51D7qyjyg+ubij8llEdBWCJEuhIgARgM/BnogGo1Gozk+KtXQpZSlQojxwAzABnwgpVwjhLjZaJ8khEgFFgMJQLkQ4k6gk5Qyx9d1NRqNRhNY/ErOJaWcBkzzODbJtL0PZYqpKd6pwXtVN3outRM9l9pHXZkHVNNcgpYPXaPRaDSBRYf+azQaTR1BC3SNRqOpI4ScQK8sr0xtQwjxgRDigBBitelYAyHETCHEJuO7vqntIWNuG4QQw4Izam+EEM2FEH8IIdYJIdYIIe4wjofiXKKEEAuFECuMufzHOB5yc3EghLAJIZYJIX429kNyLkKI7UKIVUKI5UKIxcaxkJuLECJRCPG1EGK98TfTr0bmIaUMmQ/Ky2YL0AqIAFagvGmCPrYKxjwQ6AWsNh17AXjQ2H4QeN7Y7mTMKRJIN+ZqC/YcjLE1BnoZ2/HARmO8oTgXAcQZ23bgH+CUUJyLaU53A58DP4fq/zFjfNuBhh7HQm4uwMfADcZ2BJBYE/MINQ290rwytQ0p5RxU8jIzI1H/4BjfF5iOT5ZSFkkptwGbUXMOOlLKvVLKpcZ2LrAOlQIiFOcipZR5xq7d+EhCcC4AQohmwDnAe6bDITkXH4TUXIQQCShF7n0AKWWxlPIINTCPUBPoAcsrE2QaSSn3ghKUQIpxPCTmJ4RIA3qiNNuQnItholgOHABmSilDdi7Aa8D9QLnpWKjORQK/CiGWCCFuNI6F2lxaAZnAh4YZ7D0hRCw1MI9QE+gByytTS6n18xNCxAHfAHfKigPHavVcpJRlUsoeqPiJvkKILhV0r7VzEUKcCxyQUi7x9xSLY7ViLgYDpJS9gBHArUKIgRX0ra1zCUeZWd+SUvYE8lEmFl8EbB6hJtCrJa9MENgvhGgMYHwfMI7X6vkJIewoYf6ZlPJb43BIzsWB8Sr8JzCc0JzLAOB8IcR2lAnyDCHEp4TmXJBS7jG+DwDfoUwPoTaXDCDDeOsD+Bol4Kt9HqEm0OtKXpkfgWuM7WuAH0zHRwshIoUQ6UBbYGEQxueFEEKgbILrpJSvmJpCcS7JQohEYzsaOBNYTwjORUr5kJSymZQyDfX38LuUcgwhOBchRKwQIt6xDZwFrCbE5iJV5PwuIUR749AQYC01MY9grwYfw+rx2SgPiy3Aw8Eejx/j/QLYiyr+kQFcDyQBs4BNxncDU/+HjbltAEYEe/ymcZ2Keg1cCSw3PmeH6Fy6AcuMuawGHjOOh9xcPOY1CJeXS8jNBWV7XmF81jj+vkN0Lj1Q+a1WAt8D9WtiHjr0X6PRaOoIoWZy0Wg0Go0PtEDXaDSaOoIW6BqNRlNH0AJdo9Fo6ghaoGs0Gk0dQQt0jUajqSNoga7RaDR1hP8Hn03K3tqucfEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model with the early stopping\n",
    "#### 3.5 Now this time include the early stopping in\n",
    "- Re-run the cell with your model defined in it and come back here again!\n",
    "- Make sure to use epochs, verbose, validation_data, and callbacks \n",
    "- Plot loss vs epoch\n",
    "- **Note: no need to include the batch_size your data is small enough that we don't need it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "38/38 [==============================] - 3s 11ms/step - loss: 0.7478 - val_loss: 0.6508\n",
      "Epoch 2/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.7074 - val_loss: 0.6370\n",
      "Epoch 3/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6747 - val_loss: 0.6255\n",
      "Epoch 4/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6897 - val_loss: 0.6256\n",
      "Epoch 5/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6802 - val_loss: 0.6220\n",
      "Epoch 6/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6675 - val_loss: 0.6104\n",
      "Epoch 7/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6728 - val_loss: 0.6059\n",
      "Epoch 8/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.6928 - val_loss: 0.6041\n",
      "Epoch 9/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6778 - val_loss: 0.5996\n",
      "Epoch 10/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6559 - val_loss: 0.5968\n",
      "Epoch 11/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6881 - val_loss: 0.6009\n",
      "Epoch 12/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6329 - val_loss: 0.5965\n",
      "Epoch 13/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6234 - val_loss: 0.5890\n",
      "Epoch 14/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6265 - val_loss: 0.5848\n",
      "Epoch 15/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6445 - val_loss: 0.5811\n",
      "Epoch 16/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6559 - val_loss: 0.5782\n",
      "Epoch 17/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6515 - val_loss: 0.5786\n",
      "Epoch 18/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6307 - val_loss: 0.5746\n",
      "Epoch 19/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6241 - val_loss: 0.5738\n",
      "Epoch 20/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6318 - val_loss: 0.5755\n",
      "Epoch 21/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6255 - val_loss: 0.5775\n",
      "Epoch 22/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6263 - val_loss: 0.5760\n",
      "Epoch 23/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6162 - val_loss: 0.5739\n",
      "Epoch 24/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6214 - val_loss: 0.5687\n",
      "Epoch 25/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6047 - val_loss: 0.5668\n",
      "Epoch 26/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6149 - val_loss: 0.5636\n",
      "Epoch 27/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6078 - val_loss: 0.5608\n",
      "Epoch 28/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6003 - val_loss: 0.5604\n",
      "Epoch 29/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6206 - val_loss: 0.5595\n",
      "Epoch 30/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6047 - val_loss: 0.5544\n",
      "Epoch 31/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6007 - val_loss: 0.5598\n",
      "Epoch 32/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6038 - val_loss: 0.5565\n",
      "Epoch 33/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6022 - val_loss: 0.5532\n",
      "Epoch 34/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6168 - val_loss: 0.5550\n",
      "Epoch 35/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5936 - val_loss: 0.5564\n",
      "Epoch 36/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6004 - val_loss: 0.5515\n",
      "Epoch 37/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5966 - val_loss: 0.5497\n",
      "Epoch 38/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5845 - val_loss: 0.5450\n",
      "Epoch 39/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5815 - val_loss: 0.5390\n",
      "Epoch 40/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5723 - val_loss: 0.5372\n",
      "Epoch 41/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5960 - val_loss: 0.5417\n",
      "Epoch 42/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5805 - val_loss: 0.5401\n",
      "Epoch 43/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5754 - val_loss: 0.5385\n",
      "Epoch 44/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5782 - val_loss: 0.5353\n",
      "Epoch 45/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5814 - val_loss: 0.5364\n",
      "Epoch 46/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5803 - val_loss: 0.5343\n",
      "Epoch 47/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5839 - val_loss: 0.5328\n",
      "Epoch 48/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5819 - val_loss: 0.5323\n",
      "Epoch 49/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5868 - val_loss: 0.5285\n",
      "Epoch 50/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5711 - val_loss: 0.5281\n",
      "Epoch 51/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5594 - val_loss: 0.5265\n",
      "Epoch 52/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5658 - val_loss: 0.5229\n",
      "Epoch 53/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5699 - val_loss: 0.5187\n",
      "Epoch 54/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5821 - val_loss: 0.5190\n",
      "Epoch 55/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5636 - val_loss: 0.5172\n",
      "Epoch 56/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5674 - val_loss: 0.5111\n",
      "Epoch 57/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5589 - val_loss: 0.5084\n",
      "Epoch 58/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5694 - val_loss: 0.5108\n",
      "Epoch 59/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5559 - val_loss: 0.5026\n",
      "Epoch 60/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5625 - val_loss: 0.4941\n",
      "Epoch 61/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.5611 - val_loss: 0.4944\n",
      "Epoch 62/600\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.5389 - val_loss: 0.4921\n",
      "Epoch 63/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5355 - val_loss: 0.4862\n",
      "Epoch 64/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5644 - val_loss: 0.4817\n",
      "Epoch 65/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5416 - val_loss: 0.4766\n",
      "Epoch 66/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5308 - val_loss: 0.4645\n",
      "Epoch 67/600\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.5492 - val_loss: 0.4692\n",
      "Epoch 68/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5276 - val_loss: 0.4607\n",
      "Epoch 69/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5310 - val_loss: 0.4579\n",
      "Epoch 70/600\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5180 - val_loss: 0.4484\n",
      "Epoch 71/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5250 - val_loss: 0.4440\n",
      "Epoch 72/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5172 - val_loss: 0.4396\n",
      "Epoch 73/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5200 - val_loss: 0.4406\n",
      "Epoch 74/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5192 - val_loss: 0.4406\n",
      "Epoch 75/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5227 - val_loss: 0.4374\n",
      "Epoch 76/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5173 - val_loss: 0.4347\n",
      "Epoch 77/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5278 - val_loss: 0.4345\n",
      "Epoch 78/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5133 - val_loss: 0.4301\n",
      "Epoch 79/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5164 - val_loss: 0.4220\n",
      "Epoch 80/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4988 - val_loss: 0.4168\n",
      "Epoch 81/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4966 - val_loss: 0.4162\n",
      "Epoch 82/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5092 - val_loss: 0.4032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5063 - val_loss: 0.4057\n",
      "Epoch 84/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4840 - val_loss: 0.4026\n",
      "Epoch 85/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4871 - val_loss: 0.3975\n",
      "Epoch 86/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4966 - val_loss: 0.3914\n",
      "Epoch 87/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4730 - val_loss: 0.3891\n",
      "Epoch 88/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4919 - val_loss: 0.3833\n",
      "Epoch 89/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5027 - val_loss: 0.3836\n",
      "Epoch 90/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4782 - val_loss: 0.3805\n",
      "Epoch 91/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4937 - val_loss: 0.3886\n",
      "Epoch 92/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4816 - val_loss: 0.3807\n",
      "Epoch 93/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4736 - val_loss: 0.3782\n",
      "Epoch 94/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4771 - val_loss: 0.3749\n",
      "Epoch 95/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4824 - val_loss: 0.3698\n",
      "Epoch 96/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4736 - val_loss: 0.3743\n",
      "Epoch 97/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4717 - val_loss: 0.3649\n",
      "Epoch 98/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4850 - val_loss: 0.3712\n",
      "Epoch 99/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4989 - val_loss: 0.3703\n",
      "Epoch 100/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4611 - val_loss: 0.3616\n",
      "Epoch 101/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4749 - val_loss: 0.3590\n",
      "Epoch 102/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4425 - val_loss: 0.3595\n",
      "Epoch 103/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4730 - val_loss: 0.3584\n",
      "Epoch 104/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4583 - val_loss: 0.3601\n",
      "Epoch 105/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4720 - val_loss: 0.3511\n",
      "Epoch 106/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4501 - val_loss: 0.3537\n",
      "Epoch 107/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4612 - val_loss: 0.3547\n",
      "Epoch 108/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4565 - val_loss: 0.3600\n",
      "Epoch 109/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4491 - val_loss: 0.3518\n",
      "Epoch 110/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4416 - val_loss: 0.3531\n",
      "Epoch 111/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4416 - val_loss: 0.3510\n",
      "Epoch 112/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4615 - val_loss: 0.3502\n",
      "Epoch 113/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4605 - val_loss: 0.3512\n",
      "Epoch 114/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4462 - val_loss: 0.3431\n",
      "Epoch 115/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4486 - val_loss: 0.3398\n",
      "Epoch 116/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4380 - val_loss: 0.3447\n",
      "Epoch 117/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4423 - val_loss: 0.3458\n",
      "Epoch 118/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4541 - val_loss: 0.3389\n",
      "Epoch 119/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4181 - val_loss: 0.3345\n",
      "Epoch 120/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4230 - val_loss: 0.3343\n",
      "Epoch 121/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4169 - val_loss: 0.3329\n",
      "Epoch 122/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4285 - val_loss: 0.3276\n",
      "Epoch 123/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4221 - val_loss: 0.3255\n",
      "Epoch 124/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4161 - val_loss: 0.3309\n",
      "Epoch 125/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4305 - val_loss: 0.3280\n",
      "Epoch 126/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4349 - val_loss: 0.3328\n",
      "Epoch 127/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4206 - val_loss: 0.3235\n",
      "Epoch 128/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4201 - val_loss: 0.3190\n",
      "Epoch 129/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4179 - val_loss: 0.3182\n",
      "Epoch 130/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4169 - val_loss: 0.3204\n",
      "Epoch 131/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4106 - val_loss: 0.3186\n",
      "Epoch 132/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4215 - val_loss: 0.3202\n",
      "Epoch 133/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4195 - val_loss: 0.3179\n",
      "Epoch 134/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4463 - val_loss: 0.3133\n",
      "Epoch 135/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3905 - val_loss: 0.3112\n",
      "Epoch 136/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4187 - val_loss: 0.3088\n",
      "Epoch 137/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4437 - val_loss: 0.3089\n",
      "Epoch 138/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4117 - val_loss: 0.3088\n",
      "Epoch 139/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4110 - val_loss: 0.3083\n",
      "Epoch 140/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4262 - val_loss: 0.3153\n",
      "Epoch 141/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4172 - val_loss: 0.3197\n",
      "Epoch 142/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4116 - val_loss: 0.3203\n",
      "Epoch 143/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4176 - val_loss: 0.3059\n",
      "Epoch 144/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4114 - val_loss: 0.3149\n",
      "Epoch 145/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4103 - val_loss: 0.3009\n",
      "Epoch 146/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3965 - val_loss: 0.3013\n",
      "Epoch 147/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3818 - val_loss: 0.2934\n",
      "Epoch 148/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3916 - val_loss: 0.2962\n",
      "Epoch 149/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4041 - val_loss: 0.2926\n",
      "Epoch 150/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3925 - val_loss: 0.2891\n",
      "Epoch 151/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4337 - val_loss: 0.3202\n",
      "Epoch 152/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4024 - val_loss: 0.2960\n",
      "Epoch 153/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3973 - val_loss: 0.2922\n",
      "Epoch 154/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3793 - val_loss: 0.2841\n",
      "Epoch 155/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3766 - val_loss: 0.2888\n",
      "Epoch 156/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4458 - val_loss: 0.2958\n",
      "Epoch 157/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4063 - val_loss: 0.2850\n",
      "Epoch 158/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3805 - val_loss: 0.2838\n",
      "Epoch 159/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3675 - val_loss: 0.2762\n",
      "Epoch 160/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3710 - val_loss: 0.2775\n",
      "Epoch 161/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3580 - val_loss: 0.2716\n",
      "Epoch 162/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3629 - val_loss: 0.2671\n",
      "Epoch 163/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3957 - val_loss: 0.2685\n",
      "Epoch 164/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3711 - val_loss: 0.2663\n",
      "Epoch 165/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3800 - val_loss: 0.2694\n",
      "Epoch 166/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3655 - val_loss: 0.2617\n",
      "Epoch 167/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3734 - val_loss: 0.2621\n",
      "Epoch 168/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3743 - val_loss: 0.2600\n",
      "Epoch 169/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3718 - val_loss: 0.2507\n",
      "Epoch 170/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3623 - val_loss: 0.2575\n",
      "Epoch 171/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3592 - val_loss: 0.2487\n",
      "Epoch 172/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3834 - val_loss: 0.2685\n",
      "Epoch 173/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3776 - val_loss: 0.2461\n",
      "Epoch 174/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3727 - val_loss: 0.2538\n",
      "Epoch 175/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3509 - val_loss: 0.2499\n",
      "Epoch 176/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3497 - val_loss: 0.2436\n",
      "Epoch 177/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3670 - val_loss: 0.2410\n",
      "Epoch 178/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3463 - val_loss: 0.2519\n",
      "Epoch 179/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3454 - val_loss: 0.2346\n",
      "Epoch 180/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3430 - val_loss: 0.2374\n",
      "Epoch 181/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3486 - val_loss: 0.2413\n",
      "Epoch 182/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3566 - val_loss: 0.2402\n",
      "Epoch 183/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3284 - val_loss: 0.2297\n",
      "Epoch 184/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3494 - val_loss: 0.2319\n",
      "Epoch 185/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3600 - val_loss: 0.2264\n",
      "Epoch 186/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3672 - val_loss: 0.2328\n",
      "Epoch 187/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3400 - val_loss: 0.2356\n",
      "Epoch 188/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3558 - val_loss: 0.2293\n",
      "Epoch 189/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3401 - val_loss: 0.2237\n",
      "Epoch 190/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3577 - val_loss: 0.2261\n",
      "Epoch 191/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3336 - val_loss: 0.2288\n",
      "Epoch 192/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3407 - val_loss: 0.2150\n",
      "Epoch 193/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3213 - val_loss: 0.2171\n",
      "Epoch 194/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3346 - val_loss: 0.2116\n",
      "Epoch 195/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3171 - val_loss: 0.2196\n",
      "Epoch 196/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3197 - val_loss: 0.2113\n",
      "Epoch 197/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3313 - val_loss: 0.2191\n",
      "Epoch 198/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3491 - val_loss: 0.2263\n",
      "Epoch 199/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3328 - val_loss: 0.2151\n",
      "Epoch 200/600\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.3342 - val_loss: 0.2094\n",
      "Epoch 201/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3291 - val_loss: 0.2075\n",
      "Epoch 202/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3311 - val_loss: 0.2071\n",
      "Epoch 203/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3175 - val_loss: 0.2095\n",
      "Epoch 204/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3019 - val_loss: 0.2111\n",
      "Epoch 205/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3127 - val_loss: 0.2083\n",
      "Epoch 206/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3022 - val_loss: 0.2060\n",
      "Epoch 207/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3953 - val_loss: 0.2118\n",
      "Epoch 208/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3263 - val_loss: 0.1998\n",
      "Epoch 209/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3167 - val_loss: 0.2118\n",
      "Epoch 210/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3018 - val_loss: 0.1971\n",
      "Epoch 211/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3229 - val_loss: 0.2132\n",
      "Epoch 212/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3244 - val_loss: 0.2039\n",
      "Epoch 213/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3252 - val_loss: 0.1943\n",
      "Epoch 214/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3110 - val_loss: 0.1932\n",
      "Epoch 215/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3307 - val_loss: 0.2025\n",
      "Epoch 216/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3298 - val_loss: 0.1975\n",
      "Epoch 217/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3162 - val_loss: 0.1925\n",
      "Epoch 218/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3250 - val_loss: 0.2040\n",
      "Epoch 219/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3058 - val_loss: 0.1939\n",
      "Epoch 220/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3305 - val_loss: 0.2117\n",
      "Epoch 221/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3025 - val_loss: 0.1908\n",
      "Epoch 222/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3075 - val_loss: 0.1873\n",
      "Epoch 223/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3034 - val_loss: 0.2041\n",
      "Epoch 224/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2911 - val_loss: 0.1911\n",
      "Epoch 225/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3069 - val_loss: 0.1892\n",
      "Epoch 226/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3187 - val_loss: 0.1893\n",
      "Epoch 227/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3142 - val_loss: 0.1960\n",
      "Epoch 228/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3173 - val_loss: 0.2071\n",
      "Epoch 229/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3116 - val_loss: 0.1846\n",
      "Epoch 230/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2831 - val_loss: 0.1789\n",
      "Epoch 231/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2807 - val_loss: 0.1761\n",
      "Epoch 232/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2880 - val_loss: 0.1775\n",
      "Epoch 233/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3383 - val_loss: 0.1995\n",
      "Epoch 234/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3199 - val_loss: 0.1963\n",
      "Epoch 235/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2983 - val_loss: 0.1856\n",
      "Epoch 236/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2845 - val_loss: 0.1685\n",
      "Epoch 237/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2968 - val_loss: 0.1722\n",
      "Epoch 238/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2764 - val_loss: 0.1739\n",
      "Epoch 239/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3387 - val_loss: 0.1927\n",
      "Epoch 240/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2940 - val_loss: 0.1856\n",
      "Epoch 241/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3043 - val_loss: 0.1722\n",
      "Epoch 242/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3067 - val_loss: 0.1734\n",
      "Epoch 243/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2848 - val_loss: 0.1918\n",
      "Epoch 244/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3351 - val_loss: 0.2491\n",
      "Epoch 245/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3347 - val_loss: 0.2178\n",
      "Epoch 246/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3368 - val_loss: 0.2308\n",
      "Epoch 247/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3205 - val_loss: 0.2101\n",
      "Epoch 248/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3002 - val_loss: 0.1925\n",
      "Epoch 249/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2905 - val_loss: 0.1839\n",
      "Epoch 250/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2865 - val_loss: 0.1723\n",
      "Epoch 251/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2910 - val_loss: 0.1713\n",
      "Epoch 252/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2962 - val_loss: 0.1669\n",
      "Epoch 253/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3155 - val_loss: 0.1704\n",
      "Epoch 254/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2579 - val_loss: 0.1670\n",
      "Epoch 255/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2736 - val_loss: 0.1637\n",
      "Epoch 256/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2967 - val_loss: 0.1784\n",
      "Epoch 257/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3070 - val_loss: 0.1682\n",
      "Epoch 258/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2769 - val_loss: 0.1603\n",
      "Epoch 259/600\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.2903 - val_loss: 0.1588\n",
      "Epoch 260/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2567 - val_loss: 0.1643\n",
      "Epoch 261/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2805 - val_loss: 0.1675\n",
      "Epoch 262/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2792 - val_loss: 0.1595\n",
      "Epoch 263/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2920 - val_loss: 0.1694\n",
      "Epoch 264/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2754 - val_loss: 0.1607\n",
      "Epoch 265/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2618 - val_loss: 0.1612\n",
      "Epoch 266/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2740 - val_loss: 0.1671\n",
      "Epoch 267/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2911 - val_loss: 0.1530\n",
      "Epoch 268/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2738 - val_loss: 0.1681\n",
      "Epoch 269/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2791 - val_loss: 0.1756\n",
      "Epoch 270/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3846 - val_loss: 0.1831\n",
      "Epoch 271/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2780 - val_loss: 0.1744\n",
      "Epoch 272/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2845 - val_loss: 0.1710\n",
      "Epoch 273/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2843 - val_loss: 0.1642\n",
      "Epoch 274/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2794 - val_loss: 0.1733\n",
      "Epoch 275/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2730 - val_loss: 0.1682\n",
      "Epoch 276/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3085 - val_loss: 0.1535\n",
      "Epoch 277/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2734 - val_loss: 0.1525\n",
      "Epoch 278/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2777 - val_loss: 0.1579\n",
      "Epoch 279/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2826 - val_loss: 0.1564\n",
      "Epoch 280/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2529 - val_loss: 0.1507\n",
      "Epoch 281/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2611 - val_loss: 0.1678\n",
      "Epoch 282/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2636 - val_loss: 0.1555\n",
      "Epoch 283/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2629 - val_loss: 0.1589\n",
      "Epoch 284/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2803 - val_loss: 0.1662\n",
      "Epoch 285/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2652 - val_loss: 0.1569\n",
      "Epoch 286/600\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2534 - val_loss: 0.1941\n",
      "Epoch 287/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3808 - val_loss: 0.1929\n",
      "Epoch 288/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2775 - val_loss: 0.1789\n",
      "Epoch 289/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2761 - val_loss: 0.1742\n",
      "Epoch 290/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2794 - val_loss: 0.1675\n",
      "Epoch 291/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2879 - val_loss: 0.1655\n",
      "Epoch 292/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4326 - val_loss: 0.2161\n",
      "Epoch 293/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3197 - val_loss: 0.1988\n",
      "Epoch 294/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2989 - val_loss: 0.1800\n",
      "Epoch 295/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2906 - val_loss: 0.1717\n",
      "Epoch 296/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2716 - val_loss: 0.1505\n",
      "Epoch 297/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2457 - val_loss: 0.1505\n",
      "Epoch 298/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2562 - val_loss: 0.1540\n",
      "Epoch 299/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2709 - val_loss: 0.1514\n",
      "Epoch 300/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2646 - val_loss: 0.1487\n",
      "Epoch 301/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2443 - val_loss: 0.1542\n",
      "Epoch 302/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2561 - val_loss: 0.1514\n",
      "Epoch 303/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2616 - val_loss: 0.1495\n",
      "Epoch 304/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2488 - val_loss: 0.1415\n",
      "Epoch 305/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2553 - val_loss: 0.1628\n",
      "Epoch 306/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2772 - val_loss: 0.1580\n",
      "Epoch 307/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2381 - val_loss: 0.1501\n",
      "Epoch 308/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2508 - val_loss: 0.1485\n",
      "Epoch 309/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2511 - val_loss: 0.1481\n",
      "Epoch 310/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2641 - val_loss: 0.1410\n",
      "Epoch 311/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2797 - val_loss: 0.1848\n",
      "Epoch 312/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2934 - val_loss: 0.1509\n",
      "Epoch 313/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2448 - val_loss: 0.1452\n",
      "Epoch 314/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2464 - val_loss: 0.1617\n",
      "Epoch 315/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2461 - val_loss: 0.1528\n",
      "Epoch 316/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2524 - val_loss: 0.1437\n",
      "Epoch 317/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2762 - val_loss: 0.1541\n",
      "Epoch 318/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2809 - val_loss: 0.1683\n",
      "Epoch 319/600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2469 - val_loss: 0.1436\n",
      "Epoch 320/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2720 - val_loss: 0.1464\n",
      "Epoch 321/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2281 - val_loss: 0.1478\n",
      "Epoch 322/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2472 - val_loss: 0.1391\n",
      "Epoch 323/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2557 - val_loss: 0.1490\n",
      "Epoch 324/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2633 - val_loss: 0.1402\n",
      "Epoch 325/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2448 - val_loss: 0.1361\n",
      "Epoch 326/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2287 - val_loss: 0.1573\n",
      "Epoch 327/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2324 - val_loss: 0.1358\n",
      "Epoch 328/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2199 - val_loss: 0.1367\n",
      "Epoch 329/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2423 - val_loss: 0.1360\n",
      "Epoch 330/600\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2424 - val_loss: 0.1511\n",
      "Epoch 331/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2491 - val_loss: 0.1530\n",
      "Epoch 332/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2888 - val_loss: 0.1618\n",
      "Epoch 333/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2715 - val_loss: 0.1509\n",
      "Epoch 334/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2443 - val_loss: 0.1408\n",
      "Epoch 335/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2398 - val_loss: 0.1383\n",
      "Epoch 336/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2843 - val_loss: 0.1719\n",
      "Epoch 337/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2606 - val_loss: 0.1434\n",
      "Epoch 338/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2471 - val_loss: 0.1442\n",
      "Epoch 339/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2449 - val_loss: 0.1342\n",
      "Epoch 340/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2387 - val_loss: 0.1353\n",
      "Epoch 341/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2250 - val_loss: 0.1364\n",
      "Epoch 342/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2327 - val_loss: 0.1398\n",
      "Epoch 343/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2428 - val_loss: 0.1353\n",
      "Epoch 344/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2732 - val_loss: 0.1450\n",
      "Epoch 345/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2540 - val_loss: 0.1489\n",
      "Epoch 346/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2449 - val_loss: 0.1336\n",
      "Epoch 347/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2269 - val_loss: 0.1319\n",
      "Epoch 348/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2274 - val_loss: 0.1396\n",
      "Epoch 349/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3138 - val_loss: 0.1597\n",
      "Epoch 350/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.1534\n",
      "Epoch 351/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2522 - val_loss: 0.1360\n",
      "Epoch 352/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2410 - val_loss: 0.1475\n",
      "Epoch 353/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2551 - val_loss: 0.1566\n",
      "Epoch 354/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2530 - val_loss: 0.1336\n",
      "Epoch 355/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2865 - val_loss: 0.1951\n",
      "Epoch 356/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2814 - val_loss: 0.2000\n",
      "Epoch 357/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2650 - val_loss: 0.1603\n",
      "Epoch 358/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2688 - val_loss: 0.1615\n",
      "Epoch 359/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2537 - val_loss: 0.1541\n",
      "Epoch 360/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2644 - val_loss: 0.1652\n",
      "Epoch 361/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2727 - val_loss: 0.1566\n",
      "Epoch 362/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2567 - val_loss: 0.1546\n",
      "Epoch 363/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2788 - val_loss: 0.1927\n",
      "Epoch 364/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2821 - val_loss: 0.1636\n",
      "Epoch 365/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2689 - val_loss: 0.1722\n",
      "Epoch 366/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2655 - val_loss: 0.1507\n",
      "Epoch 367/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2486 - val_loss: 0.1415\n",
      "Epoch 368/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2389 - val_loss: 0.1417\n",
      "Epoch 369/600\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2390 - val_loss: 0.1552\n",
      "Epoch 370/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3049 - val_loss: 0.1845\n",
      "Epoch 371/600\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2992 - val_loss: 0.1806\n",
      "Epoch 372/600\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2879 - val_loss: 0.1799\n",
      "Epoch 372: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93e4f08520>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scld_X_train, y=y_train, \n",
    "          epochs = 600, \n",
    "          verbose=1, \n",
    "          batch_size = 31,\n",
    "          callbacks= [early_stop], \n",
    "          validation_data=(scld_X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7127 - val_loss: 0.6797\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6874 - val_loss: 0.6696\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6763 - val_loss: 0.6631\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6706 - val_loss: 0.6588\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6727 - val_loss: 0.6548\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6736 - val_loss: 0.6519\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6684 - val_loss: 0.6488\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6635 - val_loss: 0.6456\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6585 - val_loss: 0.6398\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6516 - val_loss: 0.6337\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6345 - val_loss: 0.6265\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6363 - val_loss: 0.6236\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6366 - val_loss: 0.6210\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6308 - val_loss: 0.6165\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6305 - val_loss: 0.6128\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 0.6097\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6319 - val_loss: 0.6082\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6253 - val_loss: 0.6061\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6233 - val_loss: 0.6062\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6028\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6200 - val_loss: 0.6017\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6150 - val_loss: 0.5979\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6084 - val_loss: 0.5948\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5934 - val_loss: 0.5917\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.5882\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6183 - val_loss: 0.5874\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5671 - val_loss: 0.5812\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5748 - val_loss: 0.5782\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.5798\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5682 - val_loss: 0.5771\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 854us/step - loss: 0.5772 - val_loss: 0.5726\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 925us/step - loss: 0.5867 - val_loss: 0.5721\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5627 - val_loss: 0.5660\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5779 - val_loss: 0.5633\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 771us/step - loss: 0.5811 - val_loss: 0.5619\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5667 - val_loss: 0.5568\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5550 - val_loss: 0.5518\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5610 - val_loss: 0.5505\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5497 - val_loss: 0.5439\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5597 - val_loss: 0.5432\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5463 - val_loss: 0.5361\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5497 - val_loss: 0.5330\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5499 - val_loss: 0.5305\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5473 - val_loss: 0.5292\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5522 - val_loss: 0.5206\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5563 - val_loss: 0.5217\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5525 - val_loss: 0.5181\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 0.5088\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5388 - val_loss: 0.5003\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 0.4951\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.4913\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 0.4910\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5134 - val_loss: 0.4756\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5302 - val_loss: 0.4765\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 0.4734\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5034 - val_loss: 0.4637\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4949 - val_loss: 0.4619\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5030 - val_loss: 0.4513\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4996 - val_loss: 0.4567\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5136 - val_loss: 0.4466\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4939 - val_loss: 0.4484\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.4467\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.4500\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4894 - val_loss: 0.4426\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5043 - val_loss: 0.4461\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 0.4379\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5000 - val_loss: 0.4404\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5095 - val_loss: 0.4333\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4907 - val_loss: 0.4352\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.4306\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4260\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4800 - val_loss: 0.4261\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4650 - val_loss: 0.4251\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4830 - val_loss: 0.4248\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4831 - val_loss: 0.4233\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 878us/step - loss: 0.4838 - val_loss: 0.4181\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4735 - val_loss: 0.4249\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.4190\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4601 - val_loss: 0.4145\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4786 - val_loss: 0.4130\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4161\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4660 - val_loss: 0.4125\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4438 - val_loss: 0.4044\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4761 - val_loss: 0.4106\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4590 - val_loss: 0.4070\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.4000\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4607 - val_loss: 0.4154\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4124\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4596 - val_loss: 0.4085\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4511 - val_loss: 0.4054\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4433 - val_loss: 0.4069\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.3951\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4454 - val_loss: 0.3970\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.3988\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4374 - val_loss: 0.3980\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 812us/step - loss: 0.4439 - val_loss: 0.3910\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.3994\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.3872\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4537 - val_loss: 0.3888\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 926us/step - loss: 0.4515 - val_loss: 0.3927\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 894us/step - loss: 0.4234 - val_loss: 0.3897\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.3838\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.3832\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.3918\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.3906\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.3868\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4419 - val_loss: 0.3896\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.3828\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.3807\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 816us/step - loss: 0.4305 - val_loss: 0.3743\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 933us/step - loss: 0.4052 - val_loss: 0.3750\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4434 - val_loss: 0.3748\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.3731\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4288 - val_loss: 0.3744\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4232 - val_loss: 0.3749\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.3718\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.3797\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.3703\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.3723\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.3696\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.3682\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.3662\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 0.3805\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4089 - val_loss: 0.3650\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.3704\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.3701\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.3606\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.3752\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.3551\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.3616\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3573\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.3608\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.3620\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.3550\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.3630\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.3588\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.3623\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.3512\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.3557\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.3508\n",
      "Epoch 141/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.3502\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3540\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4046 - val_loss: 0.3520\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.3478\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - 0s 925us/step - loss: 0.3860 - val_loss: 0.3496\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - 0s 936us/step - loss: 0.3942 - val_loss: 0.3482\n",
      "Epoch 147/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.3441\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.3495\n",
      "Epoch 149/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.3401\n",
      "Epoch 150/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3447\n",
      "Epoch 151/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3449\n",
      "Epoch 152/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4086 - val_loss: 0.3455\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3381\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.3443\n",
      "Epoch 155/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3422\n",
      "Epoch 156/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3375\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.3390\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.3348\n",
      "Epoch 159/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.3329\n",
      "Epoch 160/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3335\n",
      "Epoch 161/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.3384\n",
      "Epoch 162/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3327\n",
      "Epoch 163/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3337\n",
      "Epoch 164/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3268\n",
      "Epoch 165/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.3244\n",
      "Epoch 166/1000\n",
      "37/37 [==============================] - 0s 834us/step - loss: 0.3697 - val_loss: 0.3172\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.3245\n",
      "Epoch 168/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3253\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3245\n",
      "Epoch 170/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3218\n",
      "Epoch 171/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3175\n",
      "Epoch 172/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3263\n",
      "Epoch 173/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3245\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3316\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3167\n",
      "Epoch 176/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3195\n",
      "Epoch 177/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3109\n",
      "Epoch 178/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.3109\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.3181\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3135\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.3090\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3150\n",
      "Epoch 183/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3228\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3040\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3066\n",
      "Epoch 186/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3085\n",
      "Epoch 187/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3061\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3021\n",
      "Epoch 189/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.3054\n",
      "Epoch 190/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3282\n",
      "Epoch 191/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.3179\n",
      "Epoch 192/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3073\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3174\n",
      "Epoch 194/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.3161\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.3009\n",
      "Epoch 196/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.3082\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.2952\n",
      "Epoch 198/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3273 - val_loss: 0.3033\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.2984\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.3025\n",
      "Epoch 201/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.2908\n",
      "Epoch 202/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.2982\n",
      "Epoch 203/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.2934\n",
      "Epoch 204/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.2927\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3403 - val_loss: 0.2938\n",
      "Epoch 206/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.3025\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.2896\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.2800\n",
      "Epoch 209/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3201 - val_loss: 0.2795\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3030\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3111\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.3056\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3020\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3018\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.2780\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.2940\n",
      "Epoch 217/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.2816\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.2652\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3058 - val_loss: 0.2739\n",
      "Epoch 220/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.2668\n",
      "Epoch 221/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.2747\n",
      "Epoch 222/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.2773\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.2675\n",
      "Epoch 224/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.2660\n",
      "Epoch 225/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3293 - val_loss: 0.2639\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.2637\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.2672\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.2664\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.2560\n",
      "Epoch 230/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.2530\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.2626\n",
      "Epoch 232/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.2743\n",
      "Epoch 233/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.2464\n",
      "Epoch 234/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2886 - val_loss: 0.2529\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.2340\n",
      "Epoch 236/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.2526\n",
      "Epoch 237/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.2471\n",
      "Epoch 238/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3040 - val_loss: 0.2344\n",
      "Epoch 239/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.2321\n",
      "Epoch 240/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2908 - val_loss: 0.2416\n",
      "Epoch 241/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.2370\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.2267\n",
      "Epoch 243/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.2531\n",
      "Epoch 244/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.2497\n",
      "Epoch 245/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.2458\n",
      "Epoch 246/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.2508\n",
      "Epoch 247/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.2391\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.2312\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.2269\n",
      "Epoch 250/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2683 - val_loss: 0.2290\n",
      "Epoch 251/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.2257\n",
      "Epoch 252/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.2182\n",
      "Epoch 253/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.2309\n",
      "Epoch 254/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.2268\n",
      "Epoch 255/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2849 - val_loss: 0.2123\n",
      "Epoch 256/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2724 - val_loss: 0.2343\n",
      "Epoch 257/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.2459\n",
      "Epoch 258/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.2121\n",
      "Epoch 259/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3144 - val_loss: 0.2260\n",
      "Epoch 260/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2755 - val_loss: 0.2171\n",
      "Epoch 261/1000\n",
      "37/37 [==============================] - 0s 926us/step - loss: 0.2875 - val_loss: 0.2152\n",
      "Epoch 262/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2726 - val_loss: 0.2139\n",
      "Epoch 263/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 0.2233\n",
      "Epoch 264/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.2333\n",
      "Epoch 265/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 0.2065\n",
      "Epoch 266/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.2388\n",
      "Epoch 267/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.2132\n",
      "Epoch 268/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.2504\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.2244\n",
      "Epoch 270/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.2335\n",
      "Epoch 271/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.2452\n",
      "Epoch 272/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.2130\n",
      "Epoch 273/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2690 - val_loss: 0.2075\n",
      "Epoch 274/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2600 - val_loss: 0.2184\n",
      "Epoch 275/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.2088\n",
      "Epoch 276/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2721 - val_loss: 0.2199\n",
      "Epoch 277/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2593 - val_loss: 0.1990\n",
      "Epoch 278/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.2031\n",
      "Epoch 279/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2561 - val_loss: 0.2774\n",
      "Epoch 280/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.2191\n",
      "Epoch 281/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.2236\n",
      "Epoch 282/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.2160\n",
      "Epoch 283/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.2251\n",
      "Epoch 284/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2522 - val_loss: 0.2111\n",
      "Epoch 285/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.2145\n",
      "Epoch 286/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.2223\n",
      "Epoch 287/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2624 - val_loss: 0.2175\n",
      "Epoch 288/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2647 - val_loss: 0.2293\n",
      "Epoch 289/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2874 - val_loss: 0.1938\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2738 - val_loss: 0.2407\n",
      "Epoch 291/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.2294\n",
      "Epoch 292/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2694 - val_loss: 0.2132\n",
      "Epoch 293/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.2040\n",
      "Epoch 294/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2777 - val_loss: 0.1977\n",
      "Epoch 295/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2498 - val_loss: 0.1859\n",
      "Epoch 296/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2625 - val_loss: 0.1972\n",
      "Epoch 297/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2511 - val_loss: 0.1950\n",
      "Epoch 298/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2642 - val_loss: 0.1979\n",
      "Epoch 299/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2742 - val_loss: 0.1996\n",
      "Epoch 300/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.1953\n",
      "Epoch 301/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2466 - val_loss: 0.1942\n",
      "Epoch 302/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.2059\n",
      "Epoch 303/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.2141\n",
      "Epoch 304/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.1923\n",
      "Epoch 305/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.2090\n",
      "Epoch 306/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2753 - val_loss: 0.2131\n",
      "Epoch 307/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2771 - val_loss: 0.1961\n",
      "Epoch 308/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.2008\n",
      "Epoch 309/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2630 - val_loss: 0.1898\n",
      "Epoch 310/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2548 - val_loss: 0.1877\n",
      "Epoch 311/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2434 - val_loss: 0.1769\n",
      "Epoch 312/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2772 - val_loss: 0.1872\n",
      "Epoch 313/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.2205\n",
      "Epoch 314/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.1896\n",
      "Epoch 315/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2476 - val_loss: 0.1817\n",
      "Epoch 316/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2627 - val_loss: 0.1762\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2568 - val_loss: 0.1757\n",
      "Epoch 318/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2324 - val_loss: 0.1746\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2307 - val_loss: 0.1846\n",
      "Epoch 320/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2562 - val_loss: 0.1772\n",
      "Epoch 321/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2613 - val_loss: 0.1773\n",
      "Epoch 322/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2498 - val_loss: 0.1630\n",
      "Epoch 323/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2679 - val_loss: 0.2172\n",
      "Epoch 324/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.2081\n",
      "Epoch 325/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.2102\n",
      "Epoch 326/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2604 - val_loss: 0.1950\n",
      "Epoch 327/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2656 - val_loss: 0.1863\n",
      "Epoch 328/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2692 - val_loss: 0.1787\n",
      "Epoch 329/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2623 - val_loss: 0.2018\n",
      "Epoch 330/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.1708\n",
      "Epoch 331/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2473 - val_loss: 0.1800\n",
      "Epoch 332/1000\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.2484 - val_loss: 0.1720\n",
      "Epoch 333/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2664 - val_loss: 0.1851\n",
      "Epoch 334/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2544 - val_loss: 0.1830\n",
      "Epoch 335/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2707 - val_loss: 0.1851\n",
      "Epoch 336/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2714 - val_loss: 0.1716\n",
      "Epoch 337/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2762 - val_loss: 0.1732\n",
      "Epoch 338/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2579 - val_loss: 0.2004\n",
      "Epoch 339/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.1850\n",
      "Epoch 340/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2733 - val_loss: 0.1782\n",
      "Epoch 341/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2443 - val_loss: 0.1835\n",
      "Epoch 342/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2479 - val_loss: 0.1639\n",
      "Epoch 343/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2457 - val_loss: 0.2042\n",
      "Epoch 344/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2704 - val_loss: 0.1892\n",
      "Epoch 345/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2649 - val_loss: 0.1671\n",
      "Epoch 346/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2338 - val_loss: 0.1894\n",
      "Epoch 347/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2586 - val_loss: 0.1830\n",
      "Epoch 347: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea068f0550>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df1 = pd.DataFrame(model.history.history)\n",
    "loss_df1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your model!\n",
    "#### 3.6 Perfomr your evaluation on your test! Remember your test MUST be unseen data to your model!\n",
    "\n",
    "- If you got to an error print your pred and see how it looks like! What should you do? Round the?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = np.round(model.predict(scld_X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119   7]\n",
      " [ 12 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       126\n",
      "           1       0.94      0.90      0.92       120\n",
      "\n",
      "    accuracy                           0.92       246\n",
      "   macro avg       0.92      0.92      0.92       246\n",
      "weighted avg       0.92      0.92      0.92       246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126   2]\n",
      " [ 10 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       128\n",
      "           1       0.98      0.92      0.95       118\n",
      "\n",
      "    accuracy                           0.95       246\n",
      "   macro avg       0.95      0.95      0.95       246\n",
      "weighted avg       0.95      0.95      0.95       246\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Act 4 Happy with the model? Save it!\n",
    "#### 4.1 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ANN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model('ANN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 for the data point below:\n",
    "- Perform the scaling\n",
    "- Predict the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave as it is\n",
    "cols= ['F70', 'F160', 'F250', 'F350', 'F500', 'F21', 'F22', 'F24', 'F870', 'F1100', 'DFWHM250']\n",
    "new_datapoint = [100*np.random.randn() for i in cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale your data point and call it new_datapoint_scld\n",
    "\n",
    "Hint: Do you have to reshape your data point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datapoint_scld = scal.transform(np.array(new_datapoint).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the perdiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = loaded_model.predict(new_datapoint_scld)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
